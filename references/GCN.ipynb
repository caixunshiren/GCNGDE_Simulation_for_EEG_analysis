{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credit: Benjamin Chang, University of Toronto, https://github.com/lolzballs\n",
    "import torch\n",
    "import torch.autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=False):\n",
    "        super(GCN, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.Tensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ',' \\\n",
    "               + str(self.out_features) + ')'\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / self.weight.size(1) ** 1/2\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "    \n",
    "    # H, feature matrix\n",
    "    # A, precomputed adj matrix\n",
    "    def forward(self, H, A):\n",
    "        n = torch.mm(A, torch.mm(H, self.weight))\n",
    "        if self.bias is not None:\n",
    "            return n + self.bias\n",
    "        else:\n",
    "            return n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n-layer GCN Network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, in_features, body_features, out_features, n_layers, activation, bias=False):\n",
    "        super(Net, self).__init__()\n",
    "        assert(n_layers >= 2)\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.head = GCN(in_features, body_features, bias)\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(n_layers - 2):\n",
    "            self.layers.append(GCN(body_features, body_features, bias))\n",
    "        self.tail = GCN(body_features, out_features, bias)\n",
    "\n",
    "    def forward(self, x, A):\n",
    "        x = self.activation(self.head(x, A))\n",
    "        for layer in self.layers:\n",
    "            x = self.activation(layer(x, A))\n",
    "        x = self.tail(x, A)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_A(data):\n",
    "    adj = torch.eye(data.num_nodes, data.num_nodes)\n",
    "    adj[data.edge_index[0,:], data.edge_index[1,:]] += 1\n",
    "    deg = adj.sum(dim=1) ** (-1/2)\n",
    "    D = torch.diag(deg)\n",
    "    return D.mm(adj).mm(D)\n",
    "\n",
    "# def create_A(data, mask=slice(None)):\n",
    "#     adj = torch.eye(data.num_nodes, data.num_nodes)\n",
    "#     adj[data.edge_index[0,:], data.edge_index[1,:]] += 1\n",
    "\n",
    "#     masked = adj[mask,:][:,mask]\n",
    "#     deg = masked.sum(dim=1) ** (-0.5)\n",
    "#     D = torch.diag(deg)\n",
    "#     return D.mm(masked).mm(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_accuracy(pred, labels, mask):\n",
    "    return (pred.argmax(dim=1) == labels)[mask].sum().item() / mask.sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 10556], test_mask=[2708], train_mask=[2708], val_mask=[2708], x=[2708, 1433], y=[2708])\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training samples:  140\n",
      "validation samples:  500\n",
      "test samples:  1000\n"
     ]
    }
   ],
   "source": [
    "A = create_A(data)\n",
    "\n",
    "train_labels = torch.where(data.train_mask, data.y, torch.tensor(-100))\n",
    "val_labels = torch.where(data.val_mask, data.y, torch.tensor(-100))\n",
    "test_labels = torch.where(data.test_mask, data.y, torch.tensor(-100))\n",
    "\n",
    "print('training samples: ', data.train_mask.sum().item())\n",
    "print('validation samples: ', data.val_mask.sum().item())\n",
    "print('test samples: ', data.test_mask.sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708])\n",
      "torch.Size([2708])\n",
      "torch.Size([2708, 1433])\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.shape)\n",
    "print(data.train_mask.shape)\n",
    "print(data.x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'features': 1433, 'body': 64, 'classes': 7, 'num_epochs': 2000, 'learning_rate': 0.01, 'weight_decay': 0.005}\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'features': dataset.num_features,\n",
    "    'body': 64,\n",
    "    'classes': dataset.num_classes,\n",
    "    'num_epochs': 2000,\n",
    "    'learning_rate': 1e-2,\n",
    "    'weight_decay': 5e-3\n",
    "}\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: \ttrain loss 1.9471932649612427\tacc 0.142857\tval loss 1.9459331035614014\tacc 0.072000\n",
      "2: \ttrain loss 1.9465835094451904\tacc 0.142857\tval loss 1.9463955163955688\tacc 0.072000\n",
      "3: \ttrain loss 1.945975661277771\tacc 0.142857\tval loss 1.9473267793655396\tacc 0.114000\n",
      "4: \ttrain loss 1.9454419612884521\tacc 0.135714\tval loss 1.9484270811080933\tacc 0.122000\n",
      "5: \ttrain loss 1.9449105262756348\tacc 0.135714\tval loss 1.9494330883026123\tacc 0.154000\n",
      "6: \ttrain loss 1.9443680047988892\tacc 0.164286\tval loss 1.950026512145996\tacc 0.162000\n",
      "7: \ttrain loss 1.9438023567199707\tacc 0.142857\tval loss 1.9501606225967407\tacc 0.162000\n",
      "8: \ttrain loss 1.9432144165039062\tacc 0.142857\tval loss 1.9497679471969604\tacc 0.122000\n",
      "9: \ttrain loss 1.942678451538086\tacc 0.142857\tval loss 1.9489516019821167\tacc 0.122000\n",
      "10: \ttrain loss 1.9422454833984375\tacc 0.142857\tval loss 1.948244571685791\tacc 0.122000\n",
      "11: \ttrain loss 1.9418559074401855\tacc 0.142857\tval loss 1.9478813409805298\tacc 0.122000\n",
      "12: \ttrain loss 1.9414736032485962\tacc 0.142857\tval loss 1.9477696418762207\tacc 0.124000\n",
      "13: \ttrain loss 1.9411263465881348\tacc 0.142857\tval loss 1.9478306770324707\tacc 0.122000\n",
      "14: \ttrain loss 1.940820336341858\tacc 0.142857\tval loss 1.9478002786636353\tacc 0.120000\n",
      "15: \ttrain loss 1.9404926300048828\tacc 0.142857\tval loss 1.94733464717865\tacc 0.120000\n",
      "16: \ttrain loss 1.9400758743286133\tacc 0.150000\tval loss 1.946436882019043\tacc 0.128000\n",
      "17: \ttrain loss 1.939570426940918\tacc 0.121429\tval loss 1.9454597234725952\tacc 0.140000\n",
      "18: \ttrain loss 1.9390376806259155\tacc 0.114286\tval loss 1.9447530508041382\tacc 0.138000\n",
      "19: \ttrain loss 1.9385402202606201\tacc 0.121429\tval loss 1.9443721771240234\tacc 0.162000\n",
      "20: \ttrain loss 1.9380979537963867\tacc 0.135714\tval loss 1.9442118406295776\tacc 0.150000\n",
      "21: \ttrain loss 1.9376991987228394\tacc 0.128571\tval loss 1.9442839622497559\tacc 0.124000\n",
      "22: \ttrain loss 1.9373493194580078\tacc 0.150000\tval loss 1.9446356296539307\tacc 0.118000\n",
      "23: \ttrain loss 1.937036395072937\tacc 0.150000\tval loss 1.9449958801269531\tacc 0.108000\n",
      "24: \ttrain loss 1.936702847480774\tacc 0.150000\tval loss 1.9447897672653198\tacc 0.106000\n",
      "25: \ttrain loss 1.9363161325454712\tacc 0.142857\tval loss 1.9437986612319946\tacc 0.126000\n",
      "26: \ttrain loss 1.9358965158462524\tacc 0.142857\tval loss 1.942478060722351\tacc 0.168000\n",
      "27: \ttrain loss 1.9354876279830933\tacc 0.142857\tval loss 1.9415239095687866\tacc 0.170000\n",
      "28: \ttrain loss 1.9350982904434204\tacc 0.128571\tval loss 1.9413355588912964\tacc 0.170000\n",
      "29: \ttrain loss 1.9347279071807861\tacc 0.135714\tval loss 1.9418898820877075\tacc 0.124000\n",
      "30: \ttrain loss 1.9344003200531006\tacc 0.142857\tval loss 1.942894697189331\tacc 0.112000\n",
      "31: \ttrain loss 1.9341133832931519\tacc 0.135714\tval loss 1.943575382232666\tacc 0.110000\n",
      "32: \ttrain loss 1.933809518814087\tacc 0.135714\tval loss 1.943050742149353\tacc 0.106000\n",
      "33: \ttrain loss 1.9334583282470703\tacc 0.135714\tval loss 1.9415251016616821\tacc 0.130000\n",
      "34: \ttrain loss 1.9331015348434448\tacc 0.135714\tval loss 1.9403154850006104\tacc 0.162000\n",
      "35: \ttrain loss 1.9327774047851562\tacc 0.164286\tval loss 1.940263032913208\tacc 0.170000\n",
      "36: \ttrain loss 1.9324703216552734\tacc 0.157143\tval loss 1.9409762620925903\tacc 0.138000\n",
      "37: \ttrain loss 1.9321728944778442\tacc 0.164286\tval loss 1.9417849779129028\tacc 0.110000\n",
      "38: \ttrain loss 1.9319039583206177\tacc 0.150000\tval loss 1.9420157670974731\tacc 0.110000\n",
      "39: \ttrain loss 1.9316388368606567\tacc 0.142857\tval loss 1.94130277633667\tacc 0.110000\n",
      "40: \ttrain loss 1.931342601776123\tacc 0.142857\tval loss 1.9404454231262207\tacc 0.136000\n",
      "41: \ttrain loss 1.9310297966003418\tacc 0.150000\tval loss 1.940316081047058\tacc 0.140000\n",
      "42: \ttrain loss 1.9307392835617065\tacc 0.171429\tval loss 1.9404510259628296\tacc 0.152000\n",
      "43: \ttrain loss 1.9304918050765991\tacc 0.171429\tval loss 1.9405434131622314\tacc 0.150000\n",
      "44: \ttrain loss 1.9302668571472168\tacc 0.157143\tval loss 1.940687656402588\tacc 0.138000\n",
      "45: \ttrain loss 1.9300289154052734\tacc 0.178571\tval loss 1.9406179189682007\tacc 0.120000\n",
      "46: \ttrain loss 1.9297642707824707\tacc 0.178571\tval loss 1.94058096408844\tacc 0.118000\n",
      "47: \ttrain loss 1.9294919967651367\tacc 0.178571\tval loss 1.940413236618042\tacc 0.134000\n",
      "48: \ttrain loss 1.9292447566986084\tacc 0.171429\tval loss 1.9399877786636353\tacc 0.146000\n",
      "49: \ttrain loss 1.9290342330932617\tacc 0.171429\tval loss 1.9401359558105469\tacc 0.142000\n",
      "50: \ttrain loss 1.9288330078125\tacc 0.150000\tval loss 1.9403576850891113\tacc 0.148000\n",
      "51: \ttrain loss 1.9286154508590698\tacc 0.164286\tval loss 1.9404420852661133\tacc 0.142000\n",
      "52: \ttrain loss 1.9283841848373413\tacc 0.164286\tval loss 1.9401003122329712\tacc 0.138000\n",
      "53: \ttrain loss 1.928165316581726\tacc 0.157143\tval loss 1.9398256540298462\tacc 0.134000\n",
      "54: \ttrain loss 1.9279687404632568\tacc 0.171429\tval loss 1.9402461051940918\tacc 0.130000\n",
      "55: \ttrain loss 1.9277793169021606\tacc 0.157143\tval loss 1.940305233001709\tacc 0.138000\n",
      "56: \ttrain loss 1.927585482597351\tacc 0.164286\tval loss 1.9402858018875122\tacc 0.168000\n",
      "57: \ttrain loss 1.927394986152649\tacc 0.178571\tval loss 1.9395205974578857\tacc 0.162000\n",
      "58: \ttrain loss 1.9272199869155884\tacc 0.171429\tval loss 1.9403398036956787\tacc 0.166000\n",
      "59: \ttrain loss 1.927037239074707\tacc 0.171429\tval loss 1.9398263692855835\tacc 0.142000\n",
      "60: \ttrain loss 1.9268704652786255\tacc 0.164286\tval loss 1.940650224685669\tacc 0.142000\n",
      "61: \ttrain loss 1.9266912937164307\tacc 0.164286\tval loss 1.939669132232666\tacc 0.160000\n",
      "62: \ttrain loss 1.9265294075012207\tacc 0.171429\tval loss 1.9398829936981201\tacc 0.162000\n",
      "63: \ttrain loss 1.9263737201690674\tacc 0.164286\tval loss 1.9404913187026978\tacc 0.160000\n",
      "64: \ttrain loss 1.9262222051620483\tacc 0.164286\tval loss 1.939697504043579\tacc 0.154000\n",
      "65: \ttrain loss 1.9260755777359009\tacc 0.157143\tval loss 1.9401668310165405\tacc 0.150000\n",
      "66: \ttrain loss 1.9259138107299805\tacc 0.164286\tval loss 1.9400428533554077\tacc 0.154000\n",
      "67: \ttrain loss 1.9257677793502808\tacc 0.171429\tval loss 1.9398183822631836\tacc 0.150000\n",
      "68: \ttrain loss 1.9256393909454346\tacc 0.164286\tval loss 1.9404338598251343\tacc 0.160000\n",
      "69: \ttrain loss 1.925506830215454\tacc 0.150000\tval loss 1.939801812171936\tacc 0.172000\n",
      "70: \ttrain loss 1.9253711700439453\tacc 0.164286\tval loss 1.9398057460784912\tacc 0.174000\n",
      "71: \ttrain loss 1.9252324104309082\tacc 0.164286\tval loss 1.940098762512207\tacc 0.152000\n",
      "72: \ttrain loss 1.9251080751419067\tacc 0.157143\tval loss 1.9398810863494873\tacc 0.152000\n",
      "73: \ttrain loss 1.9249964952468872\tacc 0.157143\tval loss 1.9402962923049927\tacc 0.164000\n",
      "74: \ttrain loss 1.9248725175857544\tacc 0.157143\tval loss 1.939646601676941\tacc 0.174000\n",
      "75: \ttrain loss 1.9247517585754395\tacc 0.157143\tval loss 1.9396207332611084\tacc 0.168000\n",
      "76: \ttrain loss 1.9246381521224976\tacc 0.164286\tval loss 1.9402624368667603\tacc 0.162000\n",
      "77: \ttrain loss 1.9245328903198242\tacc 0.150000\tval loss 1.9397238492965698\tacc 0.164000\n",
      "78: \ttrain loss 1.924430251121521\tacc 0.150000\tval loss 1.9398707151412964\tacc 0.170000\n",
      "79: \ttrain loss 1.9243144989013672\tacc 0.157143\tval loss 1.9396944046020508\tacc 0.162000\n",
      "80: \ttrain loss 1.9242122173309326\tacc 0.150000\tval loss 1.9397138357162476\tacc 0.164000\n",
      "81: \ttrain loss 1.9241241216659546\tacc 0.150000\tval loss 1.939943790435791\tacc 0.164000\n",
      "82: \ttrain loss 1.9240270853042603\tacc 0.164286\tval loss 1.9395332336425781\tacc 0.162000\n",
      "83: \ttrain loss 1.9239267110824585\tacc 0.157143\tval loss 1.9398167133331299\tacc 0.162000\n",
      "84: \ttrain loss 1.923833966255188\tacc 0.164286\tval loss 1.9395155906677246\tacc 0.170000\n",
      "85: \ttrain loss 1.9237550497055054\tacc 0.142857\tval loss 1.939785361289978\tacc 0.172000\n",
      "86: \ttrain loss 1.923667311668396\tacc 0.157143\tval loss 1.9395452737808228\tacc 0.170000\n",
      "87: \ttrain loss 1.9235800504684448\tacc 0.142857\tval loss 1.9394704103469849\tacc 0.170000\n",
      "88: \ttrain loss 1.9235005378723145\tacc 0.142857\tval loss 1.939766526222229\tacc 0.168000\n",
      "89: \ttrain loss 1.9234226942062378\tacc 0.157143\tval loss 1.939354658126831\tacc 0.170000\n",
      "90: \ttrain loss 1.923348307609558\tacc 0.142857\tval loss 1.9396541118621826\tacc 0.168000\n",
      "91: \ttrain loss 1.923272728919983\tacc 0.157143\tval loss 1.9392842054367065\tacc 0.168000\n",
      "92: \ttrain loss 1.9232033491134644\tacc 0.142857\tval loss 1.9397143125534058\tacc 0.164000\n",
      "93: \ttrain loss 1.9231312274932861\tacc 0.157143\tval loss 1.939193606376648\tacc 0.170000\n",
      "94: \ttrain loss 1.923065423965454\tacc 0.142857\tval loss 1.9396727085113525\tacc 0.166000\n",
      "95: \ttrain loss 1.9229997396469116\tacc 0.164286\tval loss 1.9391602277755737\tacc 0.162000\n",
      "96: \ttrain loss 1.9229387044906616\tacc 0.150000\tval loss 1.9395949840545654\tacc 0.164000\n",
      "97: \ttrain loss 1.9228733777999878\tacc 0.164286\tval loss 1.9391738176345825\tacc 0.166000\n",
      "98: \ttrain loss 1.922814965248108\tacc 0.150000\tval loss 1.9395184516906738\tacc 0.160000\n",
      "99: \ttrain loss 1.9227571487426758\tacc 0.164286\tval loss 1.9392619132995605\tacc 0.166000\n",
      "100: \ttrain loss 1.922701120376587\tacc 0.150000\tval loss 1.939286231994629\tacc 0.168000\n",
      "101: \ttrain loss 1.9226449728012085\tacc 0.164286\tval loss 1.9393357038497925\tacc 0.166000\n",
      "102: \ttrain loss 1.9225927591323853\tacc 0.150000\tval loss 1.9393116235733032\tacc 0.166000\n",
      "103: \ttrain loss 1.922542691230774\tacc 0.150000\tval loss 1.9392638206481934\tacc 0.168000\n",
      "104: \ttrain loss 1.9224905967712402\tacc 0.157143\tval loss 1.9392032623291016\tacc 0.164000\n",
      "105: \ttrain loss 1.9224426746368408\tacc 0.150000\tval loss 1.9393470287322998\tacc 0.164000\n",
      "106: \ttrain loss 1.9223988056182861\tacc 0.164286\tval loss 1.9391227960586548\tacc 0.166000\n",
      "107: \ttrain loss 1.9223511219024658\tacc 0.142857\tval loss 1.9393845796585083\tacc 0.164000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108: \ttrain loss 1.922305941581726\tacc 0.171429\tval loss 1.9389420747756958\tacc 0.162000\n",
      "109: \ttrain loss 1.922268271446228\tacc 0.150000\tval loss 1.9396083354949951\tacc 0.166000\n",
      "110: \ttrain loss 1.9222261905670166\tacc 0.171429\tval loss 1.93868088722229\tacc 0.162000\n",
      "111: \ttrain loss 1.9221888780593872\tacc 0.150000\tval loss 1.9396535158157349\tacc 0.166000\n",
      "112: \ttrain loss 1.9221512079238892\tacc 0.178571\tval loss 1.9389125108718872\tacc 0.164000\n",
      "113: \ttrain loss 1.9221110343933105\tacc 0.157143\tval loss 1.9390881061553955\tacc 0.168000\n",
      "114: \ttrain loss 1.9220715761184692\tacc 0.171429\tval loss 1.9394906759262085\tacc 0.166000\n",
      "115: \ttrain loss 1.922031283378601\tacc 0.171429\tval loss 1.9386820793151855\tacc 0.166000\n",
      "116: \ttrain loss 1.9220038652420044\tacc 0.142857\tval loss 1.939483404159546\tacc 0.164000\n",
      "117: \ttrain loss 1.9219681024551392\tacc 0.171429\tval loss 1.9390493631362915\tacc 0.162000\n",
      "118: \ttrain loss 1.9219368696212769\tacc 0.164286\tval loss 1.9388737678527832\tacc 0.170000\n",
      "119: \ttrain loss 1.921901822090149\tacc 0.157143\tval loss 1.9395006895065308\tacc 0.164000\n",
      "120: \ttrain loss 1.9218708276748657\tacc 0.171429\tval loss 1.9387377500534058\tacc 0.164000\n",
      "121: \ttrain loss 1.9218488931655884\tacc 0.164286\tval loss 1.9392718076705933\tacc 0.164000\n",
      "122: \ttrain loss 1.9218095541000366\tacc 0.171429\tval loss 1.9390827417373657\tacc 0.160000\n",
      "123: \ttrain loss 1.9217910766601562\tacc 0.142857\tval loss 1.9389317035675049\tacc 0.164000\n",
      "124: \ttrain loss 1.9217568635940552\tacc 0.150000\tval loss 1.9392554759979248\tacc 0.160000\n",
      "125: \ttrain loss 1.921731948852539\tacc 0.171429\tval loss 1.9388848543167114\tacc 0.162000\n",
      "126: \ttrain loss 1.9217145442962646\tacc 0.157143\tval loss 1.9391686916351318\tacc 0.162000\n",
      "127: \ttrain loss 1.9216771125793457\tacc 0.157143\tval loss 1.9389554262161255\tacc 0.166000\n",
      "128: \ttrain loss 1.921665072441101\tacc 0.157143\tval loss 1.9391204118728638\tacc 0.160000\n",
      "129: \ttrain loss 1.921633243560791\tacc 0.150000\tval loss 1.9389293193817139\tacc 0.164000\n",
      "130: \ttrain loss 1.9216164350509644\tacc 0.164286\tval loss 1.9391180276870728\tacc 0.162000\n",
      "131: \ttrain loss 1.9215940237045288\tacc 0.157143\tval loss 1.9389504194259644\tacc 0.166000\n",
      "132: \ttrain loss 1.92156982421875\tacc 0.150000\tval loss 1.9390085935592651\tacc 0.166000\n",
      "133: \ttrain loss 1.9215527772903442\tacc 0.164286\tval loss 1.939077377319336\tacc 0.160000\n",
      "134: \ttrain loss 1.921531081199646\tacc 0.157143\tval loss 1.9388575553894043\tacc 0.166000\n",
      "135: \ttrain loss 1.921514868736267\tacc 0.178571\tval loss 1.9391601085662842\tacc 0.160000\n",
      "136: \ttrain loss 1.9214916229248047\tacc 0.157143\tval loss 1.9387966394424438\tacc 0.170000\n",
      "137: \ttrain loss 1.92147958278656\tacc 0.150000\tval loss 1.939180612564087\tacc 0.164000\n",
      "138: \ttrain loss 1.9214547872543335\tacc 0.164286\tval loss 1.9387458562850952\tacc 0.162000\n",
      "139: \ttrain loss 1.921448826789856\tacc 0.150000\tval loss 1.9392294883728027\tacc 0.162000\n",
      "140: \ttrain loss 1.9214187860488892\tacc 0.157143\tval loss 1.938637137413025\tacc 0.166000\n",
      "141: \ttrain loss 1.9214198589324951\tacc 0.150000\tval loss 1.9393831491470337\tacc 0.162000\n",
      "142: \ttrain loss 1.921384572982788\tacc 0.150000\tval loss 1.9383844137191772\tacc 0.164000\n",
      "143: \ttrain loss 1.9213954210281372\tacc 0.157143\tval loss 1.939700961112976\tacc 0.156000\n",
      "144: \ttrain loss 1.921350359916687\tacc 0.157143\tval loss 1.9379717111587524\tacc 0.180000\n",
      "145: \ttrain loss 1.9213799238204956\tacc 0.164286\tval loss 1.9401735067367554\tacc 0.156000\n",
      "146: \ttrain loss 1.9213123321533203\tacc 0.157143\tval loss 1.9374617338180542\tacc 0.188000\n",
      "147: \ttrain loss 1.9213793277740479\tacc 0.164286\tval loss 1.9405953884124756\tacc 0.158000\n",
      "148: \ttrain loss 1.921272873878479\tacc 0.171429\tval loss 1.937293291091919\tacc 0.190000\n",
      "149: \ttrain loss 1.9213759899139404\tacc 0.171429\tval loss 1.9403197765350342\tacc 0.162000\n",
      "150: \ttrain loss 1.9212465286254883\tacc 0.185714\tval loss 1.9380027055740356\tacc 0.182000\n",
      "151: \ttrain loss 1.921321988105774\tacc 0.157143\tval loss 1.9392677545547485\tacc 0.162000\n",
      "152: \ttrain loss 1.9212565422058105\tacc 0.164286\tval loss 1.9391505718231201\tacc 0.164000\n",
      "153: \ttrain loss 1.9212422370910645\tacc 0.157143\tval loss 1.9381524324417114\tacc 0.180000\n",
      "154: \ttrain loss 1.9212877750396729\tacc 0.157143\tval loss 1.9400649070739746\tacc 0.164000\n",
      "155: \ttrain loss 1.921201229095459\tacc 0.171429\tval loss 1.937648892402649\tacc 0.184000\n",
      "156: \ttrain loss 1.9212738275527954\tacc 0.157143\tval loss 1.9399064779281616\tacc 0.158000\n",
      "157: \ttrain loss 1.9211965799331665\tacc 0.171429\tval loss 1.9384838342666626\tacc 0.166000\n",
      "158: \ttrain loss 1.9212182760238647\tacc 0.157143\tval loss 1.9386496543884277\tacc 0.166000\n",
      "159: \ttrain loss 1.9212117195129395\tacc 0.150000\tval loss 1.9396729469299316\tacc 0.164000\n",
      "160: \ttrain loss 1.9211722612380981\tacc 0.150000\tval loss 1.9378899335861206\tacc 0.168000\n",
      "161: \ttrain loss 1.9212201833724976\tacc 0.157143\tval loss 1.9398472309112549\tacc 0.160000\n",
      "162: \ttrain loss 1.921151041984558\tacc 0.157143\tval loss 1.9382251501083374\tacc 0.166000\n",
      "163: \ttrain loss 1.9211928844451904\tacc 0.157143\tval loss 1.9391512870788574\tacc 0.164000\n",
      "164: \ttrain loss 1.9211541414260864\tacc 0.157143\tval loss 1.9390662908554077\tacc 0.168000\n",
      "165: \ttrain loss 1.9211504459381104\tacc 0.178571\tval loss 1.9383373260498047\tacc 0.166000\n",
      "166: \ttrain loss 1.9211654663085938\tacc 0.150000\tval loss 1.939652442932129\tacc 0.164000\n",
      "167: \ttrain loss 1.9211225509643555\tacc 0.164286\tval loss 1.9381191730499268\tacc 0.166000\n",
      "168: \ttrain loss 1.9211606979370117\tacc 0.157143\tval loss 1.939441442489624\tacc 0.162000\n",
      "169: \ttrain loss 1.9211112260818481\tacc 0.157143\tval loss 1.9386426210403442\tacc 0.170000\n",
      "170: \ttrain loss 1.921138048171997\tacc 0.157143\tval loss 1.938805103302002\tacc 0.166000\n",
      "171: \ttrain loss 1.9211128950119019\tacc 0.150000\tval loss 1.939162254333496\tacc 0.164000\n",
      "172: \ttrain loss 1.921108365058899\tacc 0.178571\tval loss 1.9384938478469849\tacc 0.166000\n",
      "173: \ttrain loss 1.9211194515228271\tacc 0.150000\tval loss 1.9392691850662231\tacc 0.166000\n",
      "174: \ttrain loss 1.921086072921753\tacc 0.164286\tval loss 1.9385055303573608\tacc 0.166000\n",
      "175: \ttrain loss 1.9211159944534302\tacc 0.150000\tval loss 1.939189076423645\tacc 0.164000\n",
      "176: \ttrain loss 1.9210765361785889\tacc 0.157143\tval loss 1.9386245012283325\tacc 0.168000\n",
      "177: \ttrain loss 1.9210996627807617\tacc 0.157143\tval loss 1.9390188455581665\tacc 0.164000\n",
      "178: \ttrain loss 1.921075701713562\tacc 0.150000\tval loss 1.93882155418396\tacc 0.168000\n",
      "179: \ttrain loss 1.9210799932479858\tacc 0.164286\tval loss 1.9388173818588257\tacc 0.162000\n",
      "180: \ttrain loss 1.9210771322250366\tacc 0.150000\tval loss 1.938986897468567\tacc 0.166000\n",
      "181: \ttrain loss 1.9210643768310547\tacc 0.164286\tval loss 1.93868887424469\tacc 0.162000\n",
      "182: \ttrain loss 1.921075463294983\tacc 0.150000\tval loss 1.939080834388733\tacc 0.166000\n",
      "183: \ttrain loss 1.921053171157837\tacc 0.178571\tval loss 1.9386119842529297\tacc 0.162000\n",
      "184: \ttrain loss 1.9210686683654785\tacc 0.150000\tval loss 1.9391276836395264\tacc 0.166000\n",
      "185: \ttrain loss 1.921047329902649\tacc 0.178571\tval loss 1.938607931137085\tacc 0.164000\n",
      "186: \ttrain loss 1.9210578203201294\tacc 0.150000\tval loss 1.939064383506775\tacc 0.166000\n",
      "187: \ttrain loss 1.9210436344146729\tacc 0.164286\tval loss 1.9387286901474\tacc 0.164000\n",
      "188: \ttrain loss 1.9210479259490967\tacc 0.150000\tval loss 1.9389060735702515\tacc 0.166000\n",
      "189: \ttrain loss 1.9210397005081177\tacc 0.164286\tval loss 1.9388808012008667\tacc 0.164000\n",
      "190: \ttrain loss 1.9210394620895386\tacc 0.164286\tval loss 1.9387844800949097\tacc 0.164000\n",
      "191: \ttrain loss 1.9210360050201416\tacc 0.150000\tval loss 1.9389547109603882\tacc 0.164000\n",
      "192: \ttrain loss 1.9210320711135864\tacc 0.164286\tval loss 1.9387482404708862\tacc 0.162000\n",
      "193: \ttrain loss 1.9210325479507446\tacc 0.150000\tval loss 1.9389582872390747\tacc 0.164000\n",
      "194: \ttrain loss 1.9210257530212402\tacc 0.178571\tval loss 1.9387621879577637\tacc 0.160000\n",
      "195: \ttrain loss 1.921028733253479\tacc 0.150000\tval loss 1.9389278888702393\tacc 0.162000\n",
      "196: \ttrain loss 1.9210209846496582\tacc 0.178571\tval loss 1.93880295753479\tacc 0.160000\n",
      "197: \ttrain loss 1.9210237264633179\tacc 0.164286\tval loss 1.938876748085022\tacc 0.162000\n",
      "198: \ttrain loss 1.921018123626709\tacc 0.178571\tval loss 1.9388567209243774\tacc 0.160000\n",
      "199: \ttrain loss 1.9210187196731567\tacc 0.164286\tval loss 1.9388233423233032\tacc 0.162000\n",
      "200: \ttrain loss 1.9210189580917358\tacc 0.178571\tval loss 1.938903570175171\tacc 0.160000\n",
      "201: \ttrain loss 1.9210110902786255\tacc 0.157143\tval loss 1.9387762546539307\tacc 0.160000\n",
      "202: \ttrain loss 1.921021580696106\tacc 0.171429\tval loss 1.9389654397964478\tacc 0.162000\n",
      "203: \ttrain loss 1.9209989309310913\tacc 0.157143\tval loss 1.938656210899353\tacc 0.160000\n",
      "204: \ttrain loss 1.9210275411605835\tacc 0.178571\tval loss 1.939199447631836\tacc 0.162000\n",
      "205: \ttrain loss 1.9209799766540527\tacc 0.157143\tval loss 1.938248872756958\tacc 0.174000\n",
      "206: \ttrain loss 1.9210455417633057\tacc 0.164286\tval loss 1.9398411512374878\tacc 0.166000\n",
      "207: \ttrain loss 1.9209576845169067\tacc 0.171429\tval loss 1.9373784065246582\tacc 0.180000\n",
      "208: \ttrain loss 1.9210909605026245\tacc 0.171429\tval loss 1.9409035444259644\tacc 0.162000\n",
      "209: \ttrain loss 1.920937180519104\tacc 0.185714\tval loss 1.936445951461792\tacc 0.184000\n",
      "210: \ttrain loss 1.921148419380188\tacc 0.164286\tval loss 1.9412742853164673\tacc 0.164000\n",
      "211: \ttrain loss 1.9209294319152832\tacc 0.178571\tval loss 1.9370979070663452\tacc 0.168000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212: \ttrain loss 1.9210989475250244\tacc 0.171429\tval loss 1.939563274383545\tacc 0.162000\n",
      "213: \ttrain loss 1.9209657907485962\tacc 0.157143\tval loss 1.9392752647399902\tacc 0.166000\n",
      "214: \ttrain loss 1.9209741353988647\tacc 0.178571\tval loss 1.9375724792480469\tacc 0.164000\n",
      "215: \ttrain loss 1.9210702180862427\tacc 0.171429\tval loss 1.940535306930542\tacc 0.166000\n",
      "216: \ttrain loss 1.9209344387054443\tacc 0.171429\tval loss 1.9374321699142456\tacc 0.180000\n",
      "217: \ttrain loss 1.9210612773895264\tacc 0.164286\tval loss 1.939461350440979\tacc 0.160000\n",
      "218: \ttrain loss 1.9209721088409424\tacc 0.157143\tval loss 1.939320683479309\tacc 0.162000\n",
      "219: \ttrain loss 1.9209684133529663\tacc 0.178571\tval loss 1.9375821352005005\tacc 0.178000\n",
      "220: \ttrain loss 1.9210479259490967\tacc 0.164286\tval loss 1.9402620792388916\tacc 0.166000\n",
      "221: \ttrain loss 1.9209429025650024\tacc 0.178571\tval loss 1.9380437135696411\tacc 0.164000\n",
      "222: \ttrain loss 1.9210237264633179\tacc 0.178571\tval loss 1.9387348890304565\tacc 0.158000\n",
      "223: \ttrain loss 1.9209834337234497\tacc 0.171429\tval loss 1.9396966695785522\tacc 0.166000\n",
      "224: \ttrain loss 1.920960545539856\tacc 0.178571\tval loss 1.937827706336975\tacc 0.162000\n",
      "225: \ttrain loss 1.9210312366485596\tacc 0.164286\tval loss 1.9395349025726318\tacc 0.162000\n",
      "226: \ttrain loss 1.9209487438201904\tacc 0.150000\tval loss 1.9387444257736206\tacc 0.160000\n",
      "227: \ttrain loss 1.920998454093933\tacc 0.178571\tval loss 1.938459873199463\tacc 0.160000\n",
      "228: \ttrain loss 1.9209908246994019\tacc 0.150000\tval loss 1.9394625425338745\tacc 0.166000\n",
      "229: \ttrain loss 1.920953631401062\tacc 0.171429\tval loss 1.9383008480072021\tacc 0.160000\n",
      "230: \ttrain loss 1.9210126399993896\tacc 0.164286\tval loss 1.9391160011291504\tacc 0.160000\n",
      "231: \ttrain loss 1.9209568500518799\tacc 0.157143\tval loss 1.9389146566390991\tacc 0.158000\n",
      "232: \ttrain loss 1.9209810495376587\tacc 0.178571\tval loss 1.938521146774292\tacc 0.160000\n",
      "233: \ttrain loss 1.9209895133972168\tacc 0.157143\tval loss 1.9392226934432983\tacc 0.162000\n",
      "234: \ttrain loss 1.9209529161453247\tacc 0.164286\tval loss 1.9385837316513062\tacc 0.162000\n",
      "235: \ttrain loss 1.9209970235824585\tacc 0.171429\tval loss 1.9389092922210693\tacc 0.158000\n",
      "236: \ttrain loss 1.920960783958435\tacc 0.157143\tval loss 1.9389102458953857\tacc 0.160000\n",
      "237: \ttrain loss 1.9209721088409424\tacc 0.178571\tval loss 1.9387201070785522\tacc 0.160000\n",
      "238: \ttrain loss 1.9209825992584229\tacc 0.150000\tval loss 1.9389609098434448\tacc 0.162000\n",
      "239: \ttrain loss 1.9209529161453247\tacc 0.150000\tval loss 1.9387047290802002\tacc 0.160000\n",
      "240: \ttrain loss 1.920986294746399\tacc 0.178571\tval loss 1.9389939308166504\tacc 0.160000\n",
      "241: \ttrain loss 1.9209610223770142\tacc 0.157143\tval loss 1.9387065172195435\tacc 0.164000\n",
      "242: \ttrain loss 1.920966625213623\tacc 0.164286\tval loss 1.938858151435852\tacc 0.158000\n",
      "243: \ttrain loss 1.9209752082824707\tacc 0.150000\tval loss 1.938980221748352\tacc 0.162000\n",
      "244: \ttrain loss 1.9209544658660889\tacc 0.157143\tval loss 1.9385770559310913\tacc 0.164000\n",
      "245: \ttrain loss 1.9209771156311035\tacc 0.171429\tval loss 1.9390934705734253\tacc 0.158000\n",
      "246: \ttrain loss 1.9209586381912231\tacc 0.157143\tval loss 1.9387127161026\tacc 0.164000\n",
      "247: \ttrain loss 1.920965552330017\tacc 0.157143\tval loss 1.9387809038162231\tacc 0.164000\n",
      "248: \ttrain loss 1.9209668636322021\tacc 0.157143\tval loss 1.9390326738357544\tacc 0.160000\n",
      "249: \ttrain loss 1.920955777168274\tacc 0.157143\tval loss 1.9386019706726074\tacc 0.162000\n",
      "250: \ttrain loss 1.9209712743759155\tacc 0.157143\tval loss 1.939021348953247\tacc 0.162000\n",
      "251: \ttrain loss 1.9209544658660889\tacc 0.157143\tval loss 1.9387617111206055\tacc 0.164000\n",
      "252: \ttrain loss 1.920965313911438\tacc 0.157143\tval loss 1.9388010501861572\tacc 0.166000\n",
      "253: \ttrain loss 1.9209600687026978\tacc 0.157143\tval loss 1.9389612674713135\tacc 0.160000\n",
      "254: \ttrain loss 1.920956015586853\tacc 0.150000\tval loss 1.938679814338684\tacc 0.162000\n",
      "255: \ttrain loss 1.920965552330017\tacc 0.157143\tval loss 1.9389756917953491\tacc 0.162000\n",
      "256: \ttrain loss 1.920952320098877\tacc 0.150000\tval loss 1.9387664794921875\tacc 0.164000\n",
      "257: \ttrain loss 1.9209638833999634\tacc 0.157143\tval loss 1.9388344287872314\tacc 0.166000\n",
      "258: \ttrain loss 1.9209539890289307\tacc 0.157143\tval loss 1.9388937950134277\tacc 0.160000\n",
      "259: \ttrain loss 1.920958161354065\tacc 0.150000\tval loss 1.9387738704681396\tacc 0.162000\n",
      "260: \ttrain loss 1.9209586381912231\tacc 0.164286\tval loss 1.9388823509216309\tacc 0.164000\n",
      "261: \ttrain loss 1.9209513664245605\tacc 0.150000\tval loss 1.9388153553009033\tacc 0.162000\n",
      "262: \ttrain loss 1.920961618423462\tacc 0.157143\tval loss 1.9388633966445923\tacc 0.166000\n",
      "263: \ttrain loss 1.9209492206573486\tacc 0.164286\tval loss 1.938791036605835\tacc 0.162000\n",
      "264: \ttrain loss 1.920959234237671\tacc 0.150000\tval loss 1.9389057159423828\tacc 0.164000\n",
      "265: \ttrain loss 1.9209520816802979\tacc 0.164286\tval loss 1.9387770891189575\tacc 0.162000\n",
      "266: \ttrain loss 1.920953392982483\tacc 0.150000\tval loss 1.9388586282730103\tacc 0.164000\n",
      "267: \ttrain loss 1.920955777168274\tacc 0.164286\tval loss 1.9388771057128906\tacc 0.166000\n",
      "268: \ttrain loss 1.9209487438201904\tacc 0.157143\tval loss 1.9387459754943848\tacc 0.164000\n",
      "269: \ttrain loss 1.920957326889038\tacc 0.150000\tval loss 1.9389556646347046\tacc 0.164000\n",
      "270: \ttrain loss 1.9209481477737427\tacc 0.164286\tval loss 1.9387273788452148\tacc 0.164000\n",
      "271: \ttrain loss 1.920955777168274\tacc 0.150000\tval loss 1.9389138221740723\tacc 0.162000\n",
      "272: \ttrain loss 1.9209489822387695\tacc 0.164286\tval loss 1.9388096332550049\tacc 0.164000\n",
      "273: \ttrain loss 1.9209520816802979\tacc 0.157143\tval loss 1.9388153553009033\tacc 0.166000\n",
      "274: \ttrain loss 1.9209516048431396\tacc 0.150000\tval loss 1.9389008283615112\tacc 0.164000\n",
      "275: \ttrain loss 1.9209481477737427\tacc 0.164286\tval loss 1.9387502670288086\tacc 0.164000\n",
      "276: \ttrain loss 1.9209531545639038\tacc 0.150000\tval loss 1.9389265775680542\tacc 0.164000\n",
      "277: \ttrain loss 1.9209465980529785\tacc 0.164286\tval loss 1.938765287399292\tacc 0.164000\n",
      "278: \ttrain loss 1.9209529161453247\tacc 0.150000\tval loss 1.938880205154419\tacc 0.166000\n",
      "279: \ttrain loss 1.9209461212158203\tacc 0.164286\tval loss 1.9388213157653809\tacc 0.164000\n",
      "280: \ttrain loss 1.9209516048431396\tacc 0.157143\tval loss 1.938835859298706\tacc 0.162000\n",
      "281: \ttrain loss 1.9209468364715576\tacc 0.150000\tval loss 1.9388401508331299\tacc 0.164000\n",
      "282: \ttrain loss 1.920949935913086\tacc 0.164286\tval loss 1.9388399124145508\tacc 0.162000\n",
      "283: \ttrain loss 1.9209479093551636\tacc 0.150000\tval loss 1.9388257265090942\tacc 0.164000\n",
      "284: \ttrain loss 1.9209479093551636\tacc 0.157143\tval loss 1.938848614692688\tacc 0.166000\n",
      "285: \ttrain loss 1.9209483861923218\tacc 0.150000\tval loss 1.9388306140899658\tacc 0.164000\n",
      "286: \ttrain loss 1.9209463596343994\tacc 0.157143\tval loss 1.9388296604156494\tacc 0.164000\n",
      "287: \ttrain loss 1.9209487438201904\tacc 0.157143\tval loss 1.938856840133667\tacc 0.162000\n",
      "288: \ttrain loss 1.9209457635879517\tacc 0.150000\tval loss 1.93880295753479\tacc 0.164000\n",
      "289: \ttrain loss 1.9209489822387695\tacc 0.157143\tval loss 1.9388790130615234\tacc 0.162000\n",
      "290: \ttrain loss 1.9209448099136353\tacc 0.150000\tval loss 1.938786268234253\tacc 0.164000\n",
      "291: \ttrain loss 1.9209489822387695\tacc 0.157143\tval loss 1.938889980316162\tacc 0.162000\n",
      "292: \ttrain loss 1.9209437370300293\tacc 0.150000\tval loss 1.9387799501419067\tacc 0.164000\n",
      "293: \ttrain loss 1.9209487438201904\tacc 0.157143\tval loss 1.938891887664795\tacc 0.164000\n",
      "294: \ttrain loss 1.9209429025650024\tacc 0.150000\tval loss 1.9387791156768799\tacc 0.166000\n",
      "295: \ttrain loss 1.9209496974945068\tacc 0.157143\tval loss 1.9388976097106934\tacc 0.164000\n",
      "296: \ttrain loss 1.9209413528442383\tacc 0.164286\tval loss 1.938762903213501\tacc 0.166000\n",
      "297: \ttrain loss 1.9209507703781128\tacc 0.157143\tval loss 1.938928246498108\tacc 0.166000\n",
      "298: \ttrain loss 1.9209394454956055\tacc 0.164286\tval loss 1.938716173171997\tacc 0.166000\n",
      "299: \ttrain loss 1.9209529161453247\tacc 0.157143\tval loss 1.9389886856079102\tacc 0.164000\n",
      "300: \ttrain loss 1.9209365844726562\tacc 0.164286\tval loss 1.938642978668213\tacc 0.164000\n",
      "301: \ttrain loss 1.9209566116333008\tacc 0.157143\tval loss 1.939077377319336\tacc 0.166000\n",
      "302: \ttrain loss 1.9209318161010742\tacc 0.157143\tval loss 1.938533902168274\tacc 0.162000\n",
      "303: \ttrain loss 1.9209634065628052\tacc 0.164286\tval loss 1.939220666885376\tacc 0.162000\n",
      "304: \ttrain loss 1.9209239482879639\tacc 0.157143\tval loss 1.938344120979309\tacc 0.162000\n",
      "305: \ttrain loss 1.9209766387939453\tacc 0.178571\tval loss 1.93948233127594\tacc 0.160000\n",
      "306: \ttrain loss 1.9209113121032715\tacc 0.157143\tval loss 1.9380016326904297\tacc 0.160000\n",
      "307: \ttrain loss 1.9210036993026733\tacc 0.178571\tval loss 1.9399431943893433\tacc 0.160000\n",
      "308: \ttrain loss 1.9208940267562866\tacc 0.142857\tval loss 1.9374518394470215\tacc 0.164000\n",
      "309: \ttrain loss 1.92105233669281\tacc 0.171429\tval loss 1.9405919313430786\tacc 0.162000\n",
      "310: \ttrain loss 1.9208792448043823\tacc 0.150000\tval loss 1.9368877410888672\tacc 0.174000\n",
      "311: \ttrain loss 1.9211057424545288\tacc 0.171429\tval loss 1.9408864974975586\tacc 0.160000\n",
      "312: \ttrain loss 1.9208776950836182\tacc 0.150000\tval loss 1.9371658563613892\tacc 0.168000\n",
      "313: \ttrain loss 1.9210652112960815\tacc 0.178571\tval loss 1.9398359060287476\tacc 0.158000\n",
      "314: \ttrain loss 1.9209071397781372\tacc 0.150000\tval loss 1.9387683868408203\tacc 0.164000\n",
      "315: \ttrain loss 1.9209426641464233\tacc 0.157143\tval loss 1.9380532503128052\tacc 0.160000\n",
      "316: \ttrain loss 1.9210028648376465\tacc 0.178571\tval loss 1.9402292966842651\tacc 0.160000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317: \ttrain loss 1.920892596244812\tacc 0.150000\tval loss 1.9373570680618286\tacc 0.164000\n",
      "318: \ttrain loss 1.9210447072982788\tacc 0.178571\tval loss 1.9399652481079102\tacc 0.160000\n",
      "319: \ttrain loss 1.9209058284759521\tacc 0.142857\tval loss 1.9384664297103882\tacc 0.162000\n",
      "320: \ttrain loss 1.9209620952606201\tacc 0.157143\tval loss 1.9384260177612305\tacc 0.160000\n",
      "321: \ttrain loss 1.9209766387939453\tacc 0.178571\tval loss 1.9398232698440552\tacc 0.160000\n",
      "322: \ttrain loss 1.920906662940979\tacc 0.150000\tval loss 1.937751054763794\tacc 0.162000\n",
      "323: \ttrain loss 1.9210189580917358\tacc 0.178571\tval loss 1.9396271705627441\tacc 0.162000\n",
      "324: \ttrain loss 1.9209132194519043\tacc 0.150000\tval loss 1.9386521577835083\tacc 0.164000\n",
      "325: \ttrain loss 1.9209610223770142\tacc 0.157143\tval loss 1.938441514968872\tacc 0.162000\n",
      "326: \ttrain loss 1.9209694862365723\tacc 0.164286\tval loss 1.9396058320999146\tacc 0.162000\n",
      "327: \ttrain loss 1.9209147691726685\tacc 0.150000\tval loss 1.9380675554275513\tacc 0.160000\n",
      "328: \ttrain loss 1.9210008382797241\tacc 0.178571\tval loss 1.9393188953399658\tacc 0.160000\n",
      "329: \ttrain loss 1.9209208488464355\tacc 0.157143\tval loss 1.9388245344161987\tacc 0.164000\n",
      "330: \ttrain loss 1.9209563732147217\tacc 0.157143\tval loss 1.9384268522262573\tacc 0.162000\n",
      "331: \ttrain loss 1.9209657907485962\tacc 0.157143\tval loss 1.939478874206543\tacc 0.160000\n",
      "332: \ttrain loss 1.9209195375442505\tacc 0.157143\tval loss 1.938227891921997\tacc 0.160000\n",
      "333: \ttrain loss 1.920987844467163\tacc 0.178571\tval loss 1.9392050504684448\tacc 0.160000\n",
      "334: \ttrain loss 1.9209250211715698\tacc 0.157143\tval loss 1.938797116279602\tacc 0.162000\n",
      "335: \ttrain loss 1.9209539890289307\tacc 0.150000\tval loss 1.9385879039764404\tacc 0.164000\n",
      "336: \ttrain loss 1.920960783958435\tacc 0.157143\tval loss 1.9392242431640625\tacc 0.160000\n",
      "337: \ttrain loss 1.920924425125122\tacc 0.157143\tval loss 1.9384626150131226\tacc 0.162000\n",
      "338: \ttrain loss 1.9209775924682617\tacc 0.178571\tval loss 1.9390637874603271\tacc 0.162000\n",
      "339: \ttrain loss 1.920928716659546\tacc 0.157143\tval loss 1.9387996196746826\tacc 0.164000\n",
      "340: \ttrain loss 1.9209524393081665\tacc 0.157143\tval loss 1.9386799335479736\tacc 0.166000\n",
      "341: \ttrain loss 1.9209563732147217\tacc 0.157143\tval loss 1.939108967781067\tacc 0.162000\n",
      "342: \ttrain loss 1.9209283590316772\tacc 0.157143\tval loss 1.9385242462158203\tacc 0.164000\n",
      "343: \ttrain loss 1.9209699630737305\tacc 0.178571\tval loss 1.939083456993103\tacc 0.162000\n",
      "344: \ttrain loss 1.920930027961731\tacc 0.150000\tval loss 1.9387115240097046\tacc 0.166000\n",
      "345: \ttrain loss 1.9209520816802979\tacc 0.157143\tval loss 1.9387967586517334\tacc 0.164000\n",
      "346: \ttrain loss 1.9209502935409546\tacc 0.157143\tval loss 1.9390064477920532\tacc 0.162000\n",
      "347: \ttrain loss 1.920932650566101\tacc 0.157143\tval loss 1.9385874271392822\tacc 0.166000\n",
      "348: \ttrain loss 1.9209634065628052\tacc 0.164286\tval loss 1.9390745162963867\tacc 0.162000\n",
      "349: \ttrain loss 1.9209308624267578\tacc 0.157143\tval loss 1.938675045967102\tacc 0.166000\n",
      "350: \ttrain loss 1.9209531545639038\tacc 0.157143\tval loss 1.9388682842254639\tacc 0.162000\n",
      "351: \ttrain loss 1.9209448099136353\tacc 0.150000\tval loss 1.9389326572418213\tacc 0.166000\n",
      "352: \ttrain loss 1.920937180519104\tacc 0.164286\tval loss 1.9386383295059204\tacc 0.166000\n",
      "353: \ttrain loss 1.920957088470459\tacc 0.157143\tval loss 1.9390732049942017\tacc 0.162000\n",
      "354: \ttrain loss 1.9209320545196533\tacc 0.150000\tval loss 1.938623070716858\tacc 0.164000\n",
      "355: \ttrain loss 1.9209539890289307\tacc 0.157143\tval loss 1.9389665126800537\tacc 0.164000\n",
      "356: \ttrain loss 1.9209398031234741\tacc 0.157143\tval loss 1.9388117790222168\tacc 0.168000\n",
      "357: \ttrain loss 1.9209420680999756\tacc 0.150000\tval loss 1.9387619495391846\tacc 0.164000\n",
      "358: \ttrain loss 1.920949935913086\tacc 0.157143\tval loss 1.9389634132385254\tacc 0.162000\n",
      "359: \ttrain loss 1.9209346771240234\tacc 0.150000\tval loss 1.9387168884277344\tacc 0.166000\n",
      "360: \ttrain loss 1.9209524393081665\tacc 0.157143\tval loss 1.9388846158981323\tacc 0.164000\n",
      "361: \ttrain loss 1.920937180519104\tacc 0.150000\tval loss 1.9389044046401978\tacc 0.164000\n",
      "362: \ttrain loss 1.9209460020065308\tacc 0.178571\tval loss 1.9386252164840698\tacc 0.164000\n",
      "363: \ttrain loss 1.9209452867507935\tacc 0.150000\tval loss 1.9391967058181763\tacc 0.160000\n",
      "364: \ttrain loss 1.9209376573562622\tacc 0.178571\tval loss 1.9383262395858765\tacc 0.162000\n",
      "365: \ttrain loss 1.9209537506103516\tacc 0.150000\tval loss 1.9395015239715576\tacc 0.162000\n",
      "366: \ttrain loss 1.9209346771240234\tacc 0.178571\tval loss 1.9380104541778564\tacc 0.160000\n",
      "367: \ttrain loss 1.9209603071212769\tacc 0.150000\tval loss 1.9398244619369507\tacc 0.166000\n",
      "368: \ttrain loss 1.9209407567977905\tacc 0.192857\tval loss 1.9377657175064087\tacc 0.158000\n",
      "369: \ttrain loss 1.9209660291671753\tacc 0.150000\tval loss 1.93980872631073\tacc 0.166000\n",
      "370: \ttrain loss 1.9209476709365845\tacc 0.192857\tval loss 1.9382404088974\tacc 0.158000\n",
      "371: \ttrain loss 1.920953631401062\tacc 0.171429\tval loss 1.938869833946228\tacc 0.158000\n",
      "372: \ttrain loss 1.9209442138671875\tacc 0.178571\tval loss 1.9393362998962402\tacc 0.158000\n",
      "373: \ttrain loss 1.9209392070770264\tacc 0.171429\tval loss 1.9380621910095215\tacc 0.160000\n",
      "374: \ttrain loss 1.9209550619125366\tacc 0.150000\tval loss 1.9395164251327515\tacc 0.160000\n",
      "375: \ttrain loss 1.9209418296813965\tacc 0.185714\tval loss 1.9385687112808228\tacc 0.158000\n",
      "376: \ttrain loss 1.9209529161453247\tacc 0.164286\tval loss 1.9386030435562134\tacc 0.164000\n",
      "377: \ttrain loss 1.9209402799606323\tacc 0.157143\tval loss 1.9393928050994873\tacc 0.158000\n",
      "378: \ttrain loss 1.9209448099136353\tacc 0.164286\tval loss 1.9382948875427246\tacc 0.160000\n",
      "379: \ttrain loss 1.9209489822387695\tacc 0.150000\tval loss 1.9390679597854614\tacc 0.160000\n",
      "380: \ttrain loss 1.9209413528442383\tacc 0.171429\tval loss 1.9390113353729248\tacc 0.158000\n",
      "381: \ttrain loss 1.9209492206573486\tacc 0.164286\tval loss 1.9384024143218994\tacc 0.164000\n",
      "382: \ttrain loss 1.9209400415420532\tacc 0.150000\tval loss 1.9392502307891846\tacc 0.158000\n",
      "383: \ttrain loss 1.9209473133087158\tacc 0.164286\tval loss 1.9386882781982422\tacc 0.158000\n",
      "384: \ttrain loss 1.9209431409835815\tacc 0.157143\tval loss 1.9386398792266846\tacc 0.160000\n",
      "385: \ttrain loss 1.9209452867507935\tacc 0.164286\tval loss 1.9392555952072144\tacc 0.156000\n",
      "386: \ttrain loss 1.9209437370300293\tacc 0.164286\tval loss 1.9384287595748901\tacc 0.166000\n",
      "387: \ttrain loss 1.9209437370300293\tacc 0.150000\tval loss 1.939016342163086\tacc 0.160000\n",
      "388: \ttrain loss 1.9209442138671875\tacc 0.178571\tval loss 1.938962459564209\tacc 0.156000\n",
      "389: \ttrain loss 1.9209423065185547\tacc 0.164286\tval loss 1.9384766817092896\tacc 0.164000\n",
      "390: \ttrain loss 1.9209465980529785\tacc 0.157143\tval loss 1.9392390251159668\tacc 0.158000\n",
      "391: \ttrain loss 1.9209402799606323\tacc 0.157143\tval loss 1.9385735988616943\tacc 0.162000\n",
      "392: \ttrain loss 1.9209460020065308\tacc 0.150000\tval loss 1.9388490915298462\tacc 0.162000\n",
      "393: \ttrain loss 1.9209409952163696\tacc 0.164286\tval loss 1.9390413761138916\tacc 0.158000\n",
      "394: \ttrain loss 1.9209444522857666\tacc 0.164286\tval loss 1.9385312795639038\tacc 0.166000\n",
      "395: \ttrain loss 1.9209426641464233\tacc 0.157143\tval loss 1.939074993133545\tacc 0.160000\n",
      "396: \ttrain loss 1.9209426641464233\tacc 0.157143\tval loss 1.9387669563293457\tacc 0.162000\n",
      "397: \ttrain loss 1.9209433794021606\tacc 0.150000\tval loss 1.9387108087539673\tacc 0.162000\n",
      "398: \ttrain loss 1.9209420680999756\tacc 0.157143\tval loss 1.9390701055526733\tacc 0.158000\n",
      "399: \ttrain loss 1.9209442138671875\tacc 0.164286\tval loss 1.938613772392273\tacc 0.166000\n",
      "400: \ttrain loss 1.9209413528442383\tacc 0.157143\tval loss 1.9389278888702393\tacc 0.162000\n",
      "401: \ttrain loss 1.9209442138671875\tacc 0.164286\tval loss 1.9389127492904663\tacc 0.162000\n",
      "402: \ttrain loss 1.9209402799606323\tacc 0.150000\tval loss 1.9386239051818848\tacc 0.164000\n",
      "403: \ttrain loss 1.9209446907043457\tacc 0.157143\tval loss 1.9390807151794434\tacc 0.158000\n",
      "404: \ttrain loss 1.9209409952163696\tacc 0.157143\tval loss 1.9386601448059082\tacc 0.164000\n",
      "405: \ttrain loss 1.9209439754486084\tacc 0.157143\tval loss 1.9388744831085205\tacc 0.164000\n",
      "406: \ttrain loss 1.9209407567977905\tacc 0.157143\tval loss 1.9389277696609497\tacc 0.158000\n",
      "407: \ttrain loss 1.9209436178207397\tacc 0.150000\tval loss 1.9386707544326782\tacc 0.164000\n",
      "408: \ttrain loss 1.9209411144256592\tacc 0.157143\tval loss 1.9389846324920654\tacc 0.158000\n",
      "409: \ttrain loss 1.9209433794021606\tacc 0.150000\tval loss 1.9387695789337158\tacc 0.162000\n",
      "410: \ttrain loss 1.9209411144256592\tacc 0.157143\tval loss 1.938792109489441\tacc 0.164000\n",
      "411: \ttrain loss 1.9209426641464233\tacc 0.157143\tval loss 1.9389606714248657\tacc 0.160000\n",
      "412: \ttrain loss 1.9209415912628174\tacc 0.157143\tval loss 1.9386852979660034\tacc 0.164000\n",
      "413: \ttrain loss 1.9209424257278442\tacc 0.157143\tval loss 1.9389458894729614\tacc 0.158000\n",
      "414: \ttrain loss 1.9209418296813965\tacc 0.150000\tval loss 1.9388023614883423\tacc 0.164000\n",
      "415: \ttrain loss 1.9209420680999756\tacc 0.157143\tval loss 1.9387853145599365\tacc 0.168000\n",
      "416: \ttrain loss 1.9209415912628174\tacc 0.150000\tval loss 1.9389375448226929\tacc 0.162000\n",
      "417: \ttrain loss 1.9209418296813965\tacc 0.157143\tval loss 1.9387260675430298\tacc 0.164000\n",
      "418: \ttrain loss 1.9209420680999756\tacc 0.157143\tval loss 1.9389067888259888\tacc 0.162000\n",
      "419: \ttrain loss 1.9209415912628174\tacc 0.150000\tval loss 1.9388236999511719\tacc 0.164000\n",
      "420: \ttrain loss 1.9209418296813965\tacc 0.157143\tval loss 1.9387871026992798\tacc 0.164000\n",
      "421: \ttrain loss 1.9209415912628174\tacc 0.150000\tval loss 1.9389163255691528\tacc 0.164000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422: \ttrain loss 1.9209413528442383\tacc 0.164286\tval loss 1.9387538433074951\tacc 0.164000\n",
      "423: \ttrain loss 1.9209413528442383\tacc 0.157143\tval loss 1.9388843774795532\tacc 0.162000\n",
      "424: \ttrain loss 1.9209415912628174\tacc 0.150000\tval loss 1.9388327598571777\tacc 0.164000\n",
      "425: \ttrain loss 1.9209409952163696\tacc 0.164286\tval loss 1.938792109489441\tacc 0.164000\n",
      "426: \ttrain loss 1.9209418296813965\tacc 0.150000\tval loss 1.9389045238494873\tacc 0.164000\n",
      "427: \ttrain loss 1.9209405183792114\tacc 0.164286\tval loss 1.938762903213501\tacc 0.164000\n",
      "428: \ttrain loss 1.9209423065185547\tacc 0.157143\tval loss 1.9388878345489502\tacc 0.166000\n",
      "429: \ttrain loss 1.9209405183792114\tacc 0.150000\tval loss 1.9388115406036377\tacc 0.164000\n",
      "430: \ttrain loss 1.9209423065185547\tacc 0.157143\tval loss 1.9388306140899658\tacc 0.162000\n",
      "431: \ttrain loss 1.9209400415420532\tacc 0.150000\tval loss 1.9388535022735596\tacc 0.164000\n",
      "432: \ttrain loss 1.9209433794021606\tacc 0.164286\tval loss 1.9388208389282227\tacc 0.166000\n",
      "433: \ttrain loss 1.9209389686584473\tacc 0.150000\tval loss 1.9388244152069092\tacc 0.164000\n",
      "434: \ttrain loss 1.9209444522857666\tacc 0.157143\tval loss 1.9388847351074219\tacc 0.164000\n",
      "435: \ttrain loss 1.9209368228912354\tacc 0.164286\tval loss 1.9387357234954834\tacc 0.168000\n",
      "436: \ttrain loss 1.9209479093551636\tacc 0.150000\tval loss 1.9389890432357788\tacc 0.164000\n",
      "437: \ttrain loss 1.920932650566101\tacc 0.164286\tval loss 1.9386204481124878\tacc 0.166000\n",
      "438: \ttrain loss 1.9209542274475098\tacc 0.157143\tval loss 1.939123272895813\tacc 0.164000\n",
      "439: \ttrain loss 1.9209247827529907\tacc 0.164286\tval loss 1.9384527206420898\tacc 0.160000\n",
      "440: \ttrain loss 1.9209686517715454\tacc 0.164286\tval loss 1.939361810684204\tacc 0.162000\n",
      "441: \ttrain loss 1.9209097623825073\tacc 0.157143\tval loss 1.938110589981079\tacc 0.160000\n",
      "442: \ttrain loss 1.9210020303726196\tacc 0.178571\tval loss 1.939889907836914\tacc 0.162000\n",
      "443: \ttrain loss 1.9208868741989136\tacc 0.150000\tval loss 1.9373931884765625\tacc 0.166000\n",
      "444: \ttrain loss 1.9210807085037231\tacc 0.171429\tval loss 1.9409087896347046\tacc 0.160000\n",
      "445: \ttrain loss 1.920870065689087\tacc 0.142857\tval loss 1.9363232851028442\tacc 0.176000\n",
      "446: \ttrain loss 1.921205997467041\tacc 0.178571\tval loss 1.9418108463287354\tacc 0.152000\n",
      "447: \ttrain loss 1.9208744764328003\tacc 0.150000\tval loss 1.9362815618515015\tacc 0.172000\n",
      "448: \ttrain loss 1.921138048171997\tacc 0.171429\tval loss 1.9403672218322754\tacc 0.158000\n",
      "449: \ttrain loss 1.920906662940979\tacc 0.157143\tval loss 1.9389293193817139\tacc 0.160000\n",
      "450: \ttrain loss 1.9209136962890625\tacc 0.150000\tval loss 1.937294602394104\tacc 0.166000\n",
      "451: \ttrain loss 1.9210889339447021\tacc 0.171429\tval loss 1.9412699937820435\tacc 0.160000\n",
      "452: \ttrain loss 1.9208827018737793\tacc 0.142857\tval loss 1.9367374181747437\tacc 0.172000\n",
      "453: \ttrain loss 1.9210478067398071\tacc 0.171429\tval loss 1.939682126045227\tacc 0.156000\n",
      "454: \ttrain loss 1.920952320098877\tacc 0.157143\tval loss 1.9396953582763672\tacc 0.164000\n",
      "455: \ttrain loss 1.920902132987976\tacc 0.150000\tval loss 1.9368940591812134\tacc 0.168000\n",
      "456: \ttrain loss 1.9210708141326904\tacc 0.171429\tval loss 1.9408241510391235\tacc 0.158000\n",
      "457: \ttrain loss 1.9209086894989014\tacc 0.157143\tval loss 1.9380029439926147\tacc 0.164000\n",
      "458: \ttrain loss 1.920964241027832\tacc 0.157143\tval loss 1.9381959438323975\tacc 0.160000\n",
      "459: \ttrain loss 1.9210058450698853\tacc 0.171429\tval loss 1.940495252609253\tacc 0.160000\n",
      "460: \ttrain loss 1.920906662940979\tacc 0.157143\tval loss 1.9373228549957275\tacc 0.180000\n",
      "461: \ttrain loss 1.9210176467895508\tacc 0.164286\tval loss 1.9393383264541626\tacc 0.160000\n",
      "462: \ttrain loss 1.9209474325180054\tacc 0.178571\tval loss 1.9395630359649658\tacc 0.158000\n",
      "463: \ttrain loss 1.9209258556365967\tacc 0.157143\tval loss 1.9375630617141724\tacc 0.162000\n",
      "464: \ttrain loss 1.921021580696106\tacc 0.178571\tval loss 1.9397701025009155\tacc 0.160000\n",
      "465: \ttrain loss 1.9209219217300415\tacc 0.142857\tval loss 1.9388245344161987\tacc 0.160000\n",
      "466: \ttrain loss 1.9209576845169067\tacc 0.150000\tval loss 1.9381067752838135\tacc 0.164000\n",
      "467: \ttrain loss 1.920989751815796\tacc 0.178571\tval loss 1.9396696090698242\tacc 0.158000\n",
      "468: \ttrain loss 1.920919418334961\tacc 0.142857\tval loss 1.9385144710540771\tacc 0.166000\n",
      "469: \ttrain loss 1.9209847450256348\tacc 0.178571\tval loss 1.9385169744491577\tacc 0.162000\n",
      "470: \ttrain loss 1.9209542274475098\tacc 0.157143\tval loss 1.9394326210021973\tacc 0.162000\n",
      "471: \ttrain loss 1.9209297895431519\tacc 0.150000\tval loss 1.9384512901306152\tacc 0.162000\n",
      "472: \ttrain loss 1.9209917783737183\tacc 0.171429\tval loss 1.938751220703125\tacc 0.164000\n",
      "473: \ttrain loss 1.9209328889846802\tacc 0.150000\tval loss 1.9392303228378296\tacc 0.156000\n",
      "474: \ttrain loss 1.9209481477737427\tacc 0.164286\tval loss 1.9384623765945435\tacc 0.162000\n",
      "475: \ttrain loss 1.9209771156311035\tacc 0.178571\tval loss 1.93891441822052\tacc 0.160000\n",
      "476: \ttrain loss 1.920925498008728\tacc 0.150000\tval loss 1.9390251636505127\tacc 0.160000\n",
      "477: \ttrain loss 1.9209668636322021\tacc 0.178571\tval loss 1.93855619430542\tacc 0.166000\n",
      "478: \ttrain loss 1.9209550619125366\tacc 0.157143\tval loss 1.9389973878860474\tacc 0.166000\n",
      "479: \ttrain loss 1.920928955078125\tacc 0.157143\tval loss 1.9388214349746704\tacc 0.162000\n",
      "480: \ttrain loss 1.9209744930267334\tacc 0.171429\tval loss 1.9387574195861816\tacc 0.166000\n",
      "481: \ttrain loss 1.920937180519104\tacc 0.150000\tval loss 1.9389172792434692\tacc 0.164000\n",
      "482: \ttrain loss 1.9209424257278442\tacc 0.164286\tval loss 1.9387515783309937\tacc 0.162000\n",
      "483: \ttrain loss 1.9209673404693604\tacc 0.164286\tval loss 1.9389379024505615\tacc 0.164000\n",
      "484: \ttrain loss 1.9209294319152832\tacc 0.164286\tval loss 1.9387215375900269\tacc 0.166000\n",
      "485: \ttrain loss 1.9209566116333008\tacc 0.157143\tval loss 1.9388879537582397\tacc 0.160000\n",
      "486: \ttrain loss 1.920951247215271\tacc 0.150000\tval loss 1.9389195442199707\tacc 0.164000\n",
      "487: \ttrain loss 1.9209320545196533\tacc 0.164286\tval loss 1.938618779182434\tacc 0.166000\n",
      "488: \ttrain loss 1.9209625720977783\tacc 0.157143\tval loss 1.9390813112258911\tacc 0.162000\n",
      "489: \ttrain loss 1.9209370613098145\tacc 0.157143\tval loss 1.9387190341949463\tacc 0.162000\n",
      "490: \ttrain loss 1.9209424257278442\tacc 0.157143\tval loss 1.9387391805648804\tacc 0.164000\n",
      "491: \ttrain loss 1.9209568500518799\tacc 0.157143\tval loss 1.9391056299209595\tacc 0.162000\n",
      "492: \ttrain loss 1.9209320545196533\tacc 0.150000\tval loss 1.9385589361190796\tacc 0.166000\n",
      "493: \ttrain loss 1.920952320098877\tacc 0.157143\tval loss 1.9389584064483643\tacc 0.162000\n",
      "494: \ttrain loss 1.9209448099136353\tacc 0.157143\tval loss 1.9389394521713257\tacc 0.164000\n",
      "495: \ttrain loss 1.9209357500076294\tacc 0.150000\tval loss 1.938591480255127\tacc 0.164000\n",
      "496: \ttrain loss 1.9209542274475098\tacc 0.157143\tval loss 1.939064860343933\tacc 0.160000\n",
      "497: \ttrain loss 1.9209363460540771\tacc 0.150000\tval loss 1.9387643337249756\tacc 0.166000\n",
      "498: \ttrain loss 1.9209437370300293\tacc 0.150000\tval loss 1.9387341737747192\tacc 0.162000\n",
      "499: \ttrain loss 1.9209479093551636\tacc 0.157143\tval loss 1.9390231370925903\tacc 0.162000\n",
      "500: \ttrain loss 1.920935034751892\tacc 0.157143\tval loss 1.9387006759643555\tacc 0.164000\n",
      "501: \ttrain loss 1.9209492206573486\tacc 0.157143\tval loss 1.938842535018921\tacc 0.164000\n",
      "502: \ttrain loss 1.9209400415420532\tacc 0.157143\tval loss 1.9389421939849854\tacc 0.162000\n",
      "503: \ttrain loss 1.9209394454956055\tacc 0.150000\tval loss 1.9387080669403076\tacc 0.162000\n",
      "504: \ttrain loss 1.9209481477737427\tacc 0.157143\tval loss 1.938897728919983\tacc 0.162000\n",
      "505: \ttrain loss 1.920936107635498\tacc 0.150000\tval loss 1.9388712644577026\tacc 0.162000\n",
      "506: \ttrain loss 1.9209448099136353\tacc 0.157143\tval loss 1.9387407302856445\tacc 0.164000\n",
      "507: \ttrain loss 1.9209429025650024\tacc 0.157143\tval loss 1.9389238357543945\tacc 0.162000\n",
      "508: \ttrain loss 1.920937418937683\tacc 0.157143\tval loss 1.9388020038604736\tacc 0.164000\n",
      "509: \ttrain loss 1.9209470748901367\tacc 0.157143\tval loss 1.9388099908828735\tacc 0.164000\n",
      "510: \ttrain loss 1.9209378957748413\tacc 0.157143\tval loss 1.9388905763626099\tacc 0.164000\n",
      "511: \ttrain loss 1.9209418296813965\tacc 0.164286\tval loss 1.9387831687927246\tacc 0.166000\n",
      "512: \ttrain loss 1.9209444522857666\tacc 0.157143\tval loss 1.938866138458252\tacc 0.164000\n",
      "513: \ttrain loss 1.9209368228912354\tacc 0.157143\tval loss 1.9388219118118286\tacc 0.164000\n",
      "514: \ttrain loss 1.9209455251693726\tacc 0.157143\tval loss 1.9388383626937866\tacc 0.164000\n",
      "515: \ttrain loss 1.9209394454956055\tacc 0.157143\tval loss 1.9388377666473389\tacc 0.164000\n",
      "516: \ttrain loss 1.9209400415420532\tacc 0.157143\tval loss 1.938819169998169\tacc 0.164000\n",
      "517: \ttrain loss 1.9209442138671875\tacc 0.150000\tval loss 1.9388673305511475\tacc 0.164000\n",
      "518: \ttrain loss 1.9209376573562622\tacc 0.164286\tval loss 1.9387891292572021\tacc 0.166000\n",
      "519: \ttrain loss 1.9209436178207397\tacc 0.157143\tval loss 1.9388761520385742\tacc 0.164000\n",
      "520: \ttrain loss 1.9209405183792114\tacc 0.157143\tval loss 1.9388172626495361\tacc 0.164000\n",
      "521: \ttrain loss 1.9209394454956055\tacc 0.157143\tval loss 1.938815712928772\tacc 0.164000\n",
      "522: \ttrain loss 1.9209436178207397\tacc 0.157143\tval loss 1.9388822317123413\tacc 0.164000\n",
      "523: \ttrain loss 1.920938491821289\tacc 0.157143\tval loss 1.9387800693511963\tacc 0.164000\n",
      "524: \ttrain loss 1.9209426641464233\tacc 0.157143\tval loss 1.9388684034347534\tacc 0.164000\n",
      "525: \ttrain loss 1.9209409952163696\tacc 0.157143\tval loss 1.9388362169265747\tacc 0.164000\n",
      "526: \ttrain loss 1.9209394454956055\tacc 0.157143\tval loss 1.9388010501861572\tacc 0.164000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "527: \ttrain loss 1.9209426641464233\tacc 0.157143\tval loss 1.9388771057128906\tacc 0.162000\n",
      "528: \ttrain loss 1.9209392070770264\tacc 0.150000\tval loss 1.9388078451156616\tacc 0.164000\n",
      "529: \ttrain loss 1.9209420680999756\tacc 0.157143\tval loss 1.9388312101364136\tacc 0.164000\n",
      "530: \ttrain loss 1.9209407567977905\tacc 0.157143\tval loss 1.9388638734817505\tacc 0.164000\n",
      "531: \ttrain loss 1.9209398031234741\tacc 0.150000\tval loss 1.9387974739074707\tacc 0.164000\n",
      "532: \ttrain loss 1.9209426641464233\tacc 0.157143\tval loss 1.938858151435852\tacc 0.164000\n",
      "533: \ttrain loss 1.9209392070770264\tacc 0.150000\tval loss 1.9388357400894165\tacc 0.164000\n",
      "534: \ttrain loss 1.9209420680999756\tacc 0.157143\tval loss 1.9388116598129272\tacc 0.164000\n",
      "535: \ttrain loss 1.9209409952163696\tacc 0.157143\tval loss 1.9388666152954102\tacc 0.164000\n",
      "536: \ttrain loss 1.9209400415420532\tacc 0.157143\tval loss 1.9388080835342407\tacc 0.164000\n",
      "537: \ttrain loss 1.9209424257278442\tacc 0.157143\tval loss 1.9388476610183716\tacc 0.164000\n",
      "538: \ttrain loss 1.9209398031234741\tacc 0.157143\tval loss 1.938835859298706\tacc 0.164000\n",
      "539: \ttrain loss 1.9209420680999756\tacc 0.157143\tval loss 1.9388259649276733\tacc 0.164000\n",
      "540: \ttrain loss 1.9209411144256592\tacc 0.157143\tval loss 1.9388447999954224\tacc 0.164000\n",
      "541: \ttrain loss 1.9209402799606323\tacc 0.157143\tval loss 1.938826560974121\tacc 0.164000\n",
      "542: \ttrain loss 1.9209418296813965\tacc 0.157143\tval loss 1.9388411045074463\tacc 0.164000\n",
      "543: \ttrain loss 1.9209402799606323\tacc 0.157143\tval loss 1.9388281106948853\tacc 0.164000\n",
      "544: \ttrain loss 1.9209418296813965\tacc 0.157143\tval loss 1.9388424158096313\tacc 0.164000\n",
      "545: \ttrain loss 1.9209407567977905\tacc 0.157143\tval loss 1.9388271570205688\tacc 0.164000\n",
      "546: \ttrain loss 1.9209409952163696\tacc 0.157143\tval loss 1.9388389587402344\tacc 0.164000\n",
      "547: \ttrain loss 1.9209413528442383\tacc 0.157143\tval loss 1.938835620880127\tacc 0.164000\n",
      "548: \ttrain loss 1.9209400415420532\tacc 0.157143\tval loss 1.938828706741333\tacc 0.164000\n",
      "549: \ttrain loss 1.9209418296813965\tacc 0.157143\tval loss 1.9388421773910522\tacc 0.164000\n",
      "550: \ttrain loss 1.9209411144256592\tacc 0.157143\tval loss 1.9388301372528076\tacc 0.164000\n",
      "551: \ttrain loss 1.9209411144256592\tacc 0.157143\tval loss 1.9388325214385986\tacc 0.164000\n",
      "552: \ttrain loss 1.9209413528442383\tacc 0.157143\tval loss 1.938844084739685\tacc 0.164000\n",
      "553: \ttrain loss 1.9209405183792114\tacc 0.157143\tval loss 1.9388213157653809\tacc 0.164000\n",
      "554: \ttrain loss 1.9209413528442383\tacc 0.157143\tval loss 1.9388469457626343\tacc 0.164000\n",
      "555: \ttrain loss 1.9209407567977905\tacc 0.157143\tval loss 1.9388282299041748\tacc 0.164000\n",
      "556: \ttrain loss 1.9209415912628174\tacc 0.157143\tval loss 1.9388326406478882\tacc 0.164000\n",
      "557: \ttrain loss 1.9209411144256592\tacc 0.157143\tval loss 1.9388431310653687\tacc 0.164000\n",
      "558: \ttrain loss 1.9209409952163696\tacc 0.157143\tval loss 1.9388229846954346\tacc 0.164000\n",
      "559: \ttrain loss 1.9209415912628174\tacc 0.157143\tval loss 1.938844919204712\tacc 0.164000\n",
      "560: \ttrain loss 1.9209407567977905\tacc 0.157143\tval loss 1.9388278722763062\tacc 0.164000\n",
      "561: \ttrain loss 1.9209415912628174\tacc 0.157143\tval loss 1.938836693763733\tacc 0.164000\n",
      "562: \ttrain loss 1.9209411144256592\tacc 0.157143\tval loss 1.938835859298706\tacc 0.164000\n",
      "563: \ttrain loss 1.9209409952163696\tacc 0.157143\tval loss 1.9388325214385986\tacc 0.164000\n",
      "564: \ttrain loss 1.9209411144256592\tacc 0.157143\tval loss 1.9388353824615479\tacc 0.164000\n",
      "565: \ttrain loss 1.9209409952163696\tacc 0.157143\tval loss 1.9388365745544434\tacc 0.164000\n",
      "566: \ttrain loss 1.9209413528442383\tacc 0.157143\tval loss 1.9388306140899658\tacc 0.164000\n",
      "567: \ttrain loss 1.9209411144256592\tacc 0.157143\tval loss 1.9388401508331299\tacc 0.164000\n",
      "568: \ttrain loss 1.9209411144256592\tacc 0.157143\tval loss 1.9388281106948853\tacc 0.164000\n",
      "569: \ttrain loss 1.9209409952163696\tacc 0.157143\tval loss 1.9388426542282104\tacc 0.164000\n",
      "570: \ttrain loss 1.9209407567977905\tacc 0.157143\tval loss 1.9388251304626465\tacc 0.164000\n",
      "571: \ttrain loss 1.9209415912628174\tacc 0.157143\tval loss 1.938847541809082\tacc 0.164000\n",
      "572: \ttrain loss 1.9209409952163696\tacc 0.157143\tval loss 1.9388179779052734\tacc 0.164000\n",
      "573: \ttrain loss 1.9209418296813965\tacc 0.157143\tval loss 1.9388561248779297\tacc 0.164000\n",
      "574: \ttrain loss 1.9209407567977905\tacc 0.157143\tval loss 1.938808560371399\tacc 0.164000\n",
      "575: \ttrain loss 1.9209415912628174\tacc 0.150000\tval loss 1.9388649463653564\tacc 0.164000\n",
      "576: \ttrain loss 1.9209407567977905\tacc 0.164286\tval loss 1.938798427581787\tacc 0.164000\n",
      "577: \ttrain loss 1.9209415912628174\tacc 0.150000\tval loss 1.9388787746429443\tacc 0.164000\n",
      "578: \ttrain loss 1.9209411144256592\tacc 0.164286\tval loss 1.9387788772583008\tacc 0.164000\n",
      "579: \ttrain loss 1.9209415912628174\tacc 0.150000\tval loss 1.938907504081726\tacc 0.162000\n",
      "580: \ttrain loss 1.9209407567977905\tacc 0.164286\tval loss 1.9387372732162476\tacc 0.164000\n",
      "581: \ttrain loss 1.9209420680999756\tacc 0.150000\tval loss 1.9389655590057373\tacc 0.164000\n",
      "582: \ttrain loss 1.9209400415420532\tacc 0.164286\tval loss 1.93865966796875\tacc 0.164000\n",
      "583: \ttrain loss 1.9209429025650024\tacc 0.150000\tval loss 1.9390696287155151\tacc 0.160000\n",
      "584: \ttrain loss 1.9209394454956055\tacc 0.178571\tval loss 1.9385219812393188\tacc 0.162000\n",
      "585: \ttrain loss 1.9209455251693726\tacc 0.150000\tval loss 1.939252495765686\tacc 0.158000\n",
      "586: \ttrain loss 1.920938491821289\tacc 0.171429\tval loss 1.9382843971252441\tacc 0.162000\n",
      "587: \ttrain loss 1.9209496974945068\tacc 0.150000\tval loss 1.9395538568496704\tacc 0.160000\n",
      "588: \ttrain loss 1.920938491821289\tacc 0.185714\tval loss 1.9379324913024902\tacc 0.160000\n",
      "589: \ttrain loss 1.9209586381912231\tacc 0.150000\tval loss 1.9399110078811646\tacc 0.166000\n",
      "590: \ttrain loss 1.9209400415420532\tacc 0.192857\tval loss 1.9376853704452515\tacc 0.160000\n",
      "591: \ttrain loss 1.9209675788879395\tacc 0.150000\tval loss 1.9398925304412842\tacc 0.160000\n",
      "592: \ttrain loss 1.9209363460540771\tacc 0.185714\tval loss 1.9380888938903809\tacc 0.160000\n",
      "593: \ttrain loss 1.920961618423462\tacc 0.150000\tval loss 1.939132809638977\tacc 0.162000\n",
      "594: \ttrain loss 1.920930027961731\tacc 0.164286\tval loss 1.9389941692352295\tacc 0.158000\n",
      "595: \ttrain loss 1.920953392982483\tacc 0.178571\tval loss 1.9383628368377686\tacc 0.160000\n",
      "596: \ttrain loss 1.9209398031234741\tacc 0.150000\tval loss 1.9394077062606812\tacc 0.160000\n",
      "597: \ttrain loss 1.9209494590759277\tacc 0.178571\tval loss 1.9383915662765503\tacc 0.158000\n",
      "598: \ttrain loss 1.9209489822387695\tacc 0.157143\tval loss 1.9390147924423218\tacc 0.160000\n",
      "599: \ttrain loss 1.9209381341934204\tacc 0.178571\tval loss 1.9389292001724243\tacc 0.162000\n",
      "600: \ttrain loss 1.920951247215271\tacc 0.164286\tval loss 1.9385874271392822\tacc 0.162000\n",
      "601: \ttrain loss 1.9209355115890503\tacc 0.150000\tval loss 1.9390782117843628\tacc 0.158000\n",
      "602: \ttrain loss 1.920955777168274\tacc 0.164286\tval loss 1.938740849494934\tacc 0.158000\n",
      "603: \ttrain loss 1.9209365844726562\tacc 0.157143\tval loss 1.9387277364730835\tacc 0.160000\n",
      "604: \ttrain loss 1.9209526777267456\tacc 0.178571\tval loss 1.9391111135482788\tacc 0.158000\n",
      "605: \ttrain loss 1.9209365844726562\tacc 0.157143\tval loss 1.9384968280792236\tacc 0.162000\n",
      "606: \ttrain loss 1.9209489822387695\tacc 0.150000\tval loss 1.9391194581985474\tacc 0.160000\n",
      "607: \ttrain loss 1.9209411144256592\tacc 0.171429\tval loss 1.9386940002441406\tacc 0.160000\n",
      "608: \ttrain loss 1.9209455251693726\tacc 0.157143\tval loss 1.93880295753479\tacc 0.162000\n",
      "609: \ttrain loss 1.9209448099136353\tacc 0.164286\tval loss 1.9390100240707397\tacc 0.158000\n",
      "610: \ttrain loss 1.9209396839141846\tacc 0.150000\tval loss 1.9385888576507568\tacc 0.162000\n",
      "611: \ttrain loss 1.9209481477737427\tacc 0.150000\tval loss 1.939070701599121\tacc 0.160000\n",
      "612: \ttrain loss 1.9209376573562622\tacc 0.178571\tval loss 1.938667893409729\tacc 0.160000\n",
      "613: \ttrain loss 1.9209502935409546\tacc 0.150000\tval loss 1.9389102458953857\tacc 0.162000\n",
      "614: \ttrain loss 1.9209370613098145\tacc 0.164286\tval loss 1.9388293027877808\tacc 0.158000\n",
      "615: \ttrain loss 1.9209492206573486\tacc 0.150000\tval loss 1.9388132095336914\tacc 0.160000\n",
      "616: \ttrain loss 1.9209368228912354\tacc 0.150000\tval loss 1.9388353824615479\tacc 0.160000\n",
      "617: \ttrain loss 1.9209486246109009\tacc 0.178571\tval loss 1.9388790130615234\tacc 0.160000\n",
      "618: \ttrain loss 1.9209383726119995\tacc 0.157143\tval loss 1.9387447834014893\tacc 0.162000\n",
      "619: \ttrain loss 1.9209468364715576\tacc 0.164286\tval loss 1.9389431476593018\tacc 0.160000\n",
      "620: \ttrain loss 1.9209392070770264\tacc 0.150000\tval loss 1.93873929977417\tacc 0.164000\n",
      "621: \ttrain loss 1.9209448099136353\tacc 0.150000\tval loss 1.9388937950134277\tacc 0.162000\n",
      "622: \ttrain loss 1.9209405183792114\tacc 0.164286\tval loss 1.9388160705566406\tacc 0.158000\n",
      "623: \ttrain loss 1.9209437370300293\tacc 0.150000\tval loss 1.9388244152069092\tacc 0.160000\n",
      "624: \ttrain loss 1.9209415912628174\tacc 0.164286\tval loss 1.9388561248779297\tacc 0.162000\n",
      "625: \ttrain loss 1.9209423065185547\tacc 0.150000\tval loss 1.9388172626495361\tacc 0.164000\n",
      "626: \ttrain loss 1.9209424257278442\tacc 0.157143\tval loss 1.9388463497161865\tacc 0.164000\n",
      "627: \ttrain loss 1.9209411144256592\tacc 0.164286\tval loss 1.9388251304626465\tacc 0.160000\n",
      "628: \ttrain loss 1.9209437370300293\tacc 0.150000\tval loss 1.9388548135757446\tacc 0.162000\n",
      "629: \ttrain loss 1.9209402799606323\tacc 0.164286\tval loss 1.9387991428375244\tacc 0.162000\n",
      "630: \ttrain loss 1.9209437370300293\tacc 0.150000\tval loss 1.9388879537582397\tacc 0.164000\n",
      "631: \ttrain loss 1.9209392070770264\tacc 0.164286\tval loss 1.9387716054916382\tacc 0.164000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632: \ttrain loss 1.9209444522857666\tacc 0.157143\tval loss 1.938900113105774\tacc 0.162000\n",
      "633: \ttrain loss 1.9209381341934204\tacc 0.150000\tval loss 1.9387753009796143\tacc 0.164000\n",
      "634: \ttrain loss 1.9209457635879517\tacc 0.164286\tval loss 1.9388881921768188\tacc 0.162000\n",
      "635: \ttrain loss 1.920937180519104\tacc 0.150000\tval loss 1.9387835264205933\tacc 0.164000\n",
      "636: \ttrain loss 1.9209468364715576\tacc 0.157143\tval loss 1.9388959407806396\tacc 0.164000\n",
      "637: \ttrain loss 1.9209357500076294\tacc 0.157143\tval loss 1.938751220703125\tacc 0.164000\n",
      "638: \ttrain loss 1.9209487438201904\tacc 0.150000\tval loss 1.9389538764953613\tacc 0.164000\n",
      "639: \ttrain loss 1.9209328889846802\tacc 0.164286\tval loss 1.9386727809906006\tacc 0.162000\n",
      "640: \ttrain loss 1.9209520816802979\tacc 0.150000\tval loss 1.9390454292297363\tacc 0.164000\n",
      "641: \ttrain loss 1.9209297895431519\tacc 0.164286\tval loss 1.9385775327682495\tacc 0.162000\n",
      "642: \ttrain loss 1.920957326889038\tacc 0.150000\tval loss 1.9391409158706665\tacc 0.164000\n",
      "643: \ttrain loss 1.920924186706543\tacc 0.157143\tval loss 1.9384815692901611\tacc 0.162000\n",
      "644: \ttrain loss 1.9209657907485962\tacc 0.164286\tval loss 1.9392534494400024\tacc 0.160000\n",
      "645: \ttrain loss 1.9209160804748535\tacc 0.157143\tval loss 1.938338279724121\tacc 0.160000\n",
      "646: \ttrain loss 1.9209805727005005\tacc 0.178571\tval loss 1.9394581317901611\tacc 0.162000\n",
      "647: \ttrain loss 1.9209047555923462\tacc 0.157143\tval loss 1.9380652904510498\tacc 0.160000\n",
      "648: \ttrain loss 1.9210060834884644\tacc 0.178571\tval loss 1.939833402633667\tacc 0.162000\n",
      "649: \ttrain loss 1.9208905696868896\tacc 0.157143\tval loss 1.9376205205917358\tacc 0.164000\n",
      "650: \ttrain loss 1.9210466146469116\tacc 0.185714\tval loss 1.940362572669983\tacc 0.164000\n",
      "651: \ttrain loss 1.9208790063858032\tacc 0.164286\tval loss 1.9371241331100464\tacc 0.168000\n",
      "652: \ttrain loss 1.9210917949676514\tacc 0.171429\tval loss 1.9407637119293213\tacc 0.164000\n",
      "653: \ttrain loss 1.9208755493164062\tacc 0.157143\tval loss 1.9370067119598389\tacc 0.168000\n",
      "654: \ttrain loss 1.9210883378982544\tacc 0.171429\tval loss 1.9404375553131104\tacc 0.162000\n",
      "655: \ttrain loss 1.9208862781524658\tacc 0.142857\tval loss 1.9377989768981934\tacc 0.166000\n",
      "656: \ttrain loss 1.9210036993026733\tacc 0.178571\tval loss 1.9391849040985107\tacc 0.160000\n",
      "657: \ttrain loss 1.9209359884262085\tacc 0.157143\tval loss 1.9392393827438354\tacc 0.164000\n",
      "658: \ttrain loss 1.920921802520752\tacc 0.164286\tval loss 1.9378352165222168\tacc 0.164000\n",
      "659: \ttrain loss 1.9210131168365479\tacc 0.178571\tval loss 1.9402402639389038\tacc 0.164000\n",
      "660: \ttrain loss 1.9208955764770508\tacc 0.157143\tval loss 1.9374289512634277\tacc 0.168000\n",
      "661: \ttrain loss 1.9210339784622192\tacc 0.185714\tval loss 1.9399751424789429\tacc 0.160000\n",
      "662: \ttrain loss 1.9209060668945312\tacc 0.142857\tval loss 1.9382693767547607\tacc 0.160000\n",
      "663: \ttrain loss 1.9209778308868408\tacc 0.164286\tval loss 1.9387754201889038\tacc 0.166000\n",
      "664: \ttrain loss 1.9209518432617188\tacc 0.157143\tval loss 1.9394702911376953\tacc 0.160000\n",
      "665: \ttrain loss 1.9209232330322266\tacc 0.150000\tval loss 1.9378705024719238\tacc 0.164000\n",
      "666: \ttrain loss 1.9210026264190674\tacc 0.164286\tval loss 1.9398938417434692\tacc 0.160000\n",
      "667: \ttrain loss 1.920907974243164\tacc 0.157143\tval loss 1.9379836320877075\tacc 0.164000\n",
      "668: \ttrain loss 1.9209989309310913\tacc 0.178571\tval loss 1.9393261671066284\tacc 0.160000\n",
      "669: \ttrain loss 1.9209250211715698\tacc 0.157143\tval loss 1.938794732093811\tacc 0.166000\n",
      "670: \ttrain loss 1.920953631401062\tacc 0.157143\tval loss 1.9384799003601074\tacc 0.162000\n",
      "671: \ttrain loss 1.9209649562835693\tacc 0.157143\tval loss 1.9394590854644775\tacc 0.160000\n",
      "672: \ttrain loss 1.9209215641021729\tacc 0.157143\tval loss 1.9381258487701416\tacc 0.162000\n",
      "673: \ttrain loss 1.920989990234375\tacc 0.178571\tval loss 1.9394654035568237\tacc 0.160000\n",
      "674: \ttrain loss 1.9209181070327759\tacc 0.157143\tval loss 1.9384171962738037\tacc 0.160000\n",
      "675: \ttrain loss 1.9209734201431274\tacc 0.164286\tval loss 1.9389729499816895\tacc 0.164000\n",
      "676: \ttrain loss 1.9209387302398682\tacc 0.164286\tval loss 1.9389631748199463\tacc 0.162000\n",
      "677: \ttrain loss 1.9209402799606323\tacc 0.157143\tval loss 1.938488483428955\tacc 0.160000\n",
      "678: \ttrain loss 1.9209675788879395\tacc 0.164286\tval loss 1.93929922580719\tacc 0.160000\n",
      "679: \ttrain loss 1.9209226369857788\tacc 0.157143\tval loss 1.938349723815918\tacc 0.160000\n",
      "680: \ttrain loss 1.9209752082824707\tacc 0.164286\tval loss 1.9392364025115967\tacc 0.162000\n",
      "681: \ttrain loss 1.9209270477294922\tacc 0.157143\tval loss 1.9385873079299927\tacc 0.164000\n",
      "682: \ttrain loss 1.9209566116333008\tacc 0.157143\tval loss 1.938876986503601\tacc 0.164000\n",
      "683: \ttrain loss 1.9209457635879517\tacc 0.164286\tval loss 1.9389894008636475\tacc 0.162000\n",
      "684: \ttrain loss 1.920935034751892\tacc 0.157143\tval loss 1.9385229349136353\tacc 0.162000\n",
      "685: \ttrain loss 1.920962929725647\tacc 0.157143\tval loss 1.939225196838379\tacc 0.160000\n",
      "686: \ttrain loss 1.920926570892334\tacc 0.157143\tval loss 1.9384567737579346\tacc 0.162000\n",
      "687: \ttrain loss 1.920962929725647\tacc 0.157143\tval loss 1.9391225576400757\tacc 0.164000\n",
      "688: \ttrain loss 1.9209321737289429\tacc 0.164286\tval loss 1.938693642616272\tacc 0.166000\n",
      "689: \ttrain loss 1.9209494590759277\tacc 0.150000\tval loss 1.9388171434402466\tacc 0.164000\n",
      "690: \ttrain loss 1.9209460020065308\tacc 0.157143\tval loss 1.938997507095337\tacc 0.162000\n",
      "691: \ttrain loss 1.920934796333313\tacc 0.157143\tval loss 1.9385786056518555\tacc 0.166000\n",
      "692: \ttrain loss 1.9209563732147217\tacc 0.157143\tval loss 1.939132571220398\tacc 0.162000\n",
      "693: \ttrain loss 1.920930027961731\tacc 0.157143\tval loss 1.9385663270950317\tacc 0.162000\n",
      "694: \ttrain loss 1.920956015586853\tacc 0.157143\tval loss 1.9390336275100708\tacc 0.164000\n",
      "695: \ttrain loss 1.9209342002868652\tacc 0.164286\tval loss 1.9387434720993042\tacc 0.168000\n",
      "696: \ttrain loss 1.9209468364715576\tacc 0.150000\tval loss 1.9388213157653809\tacc 0.164000\n",
      "697: \ttrain loss 1.9209429025650024\tacc 0.157143\tval loss 1.9389433860778809\tacc 0.162000\n",
      "698: \ttrain loss 1.920937180519104\tacc 0.157143\tval loss 1.9386707544326782\tacc 0.166000\n",
      "699: \ttrain loss 1.9209502935409546\tacc 0.157143\tval loss 1.939025640487671\tacc 0.162000\n",
      "700: \ttrain loss 1.920932412147522\tacc 0.157143\tval loss 1.9386576414108276\tacc 0.166000\n",
      "701: \ttrain loss 1.9209513664245605\tacc 0.157143\tval loss 1.938981056213379\tacc 0.162000\n",
      "702: \ttrain loss 1.9209339618682861\tacc 0.164286\tval loss 1.938739538192749\tacc 0.168000\n",
      "703: \ttrain loss 1.9209465980529785\tacc 0.150000\tval loss 1.9388772249221802\tacc 0.164000\n",
      "704: \ttrain loss 1.9209398031234741\tacc 0.164286\tval loss 1.9388478994369507\tacc 0.162000\n",
      "705: \ttrain loss 1.9209400415420532\tacc 0.150000\tval loss 1.9387749433517456\tacc 0.164000\n",
      "706: \ttrain loss 1.9209455251693726\tacc 0.157143\tval loss 1.9389325380325317\tacc 0.162000\n",
      "707: \ttrain loss 1.9209352731704712\tacc 0.157143\tval loss 1.9387155771255493\tacc 0.166000\n",
      "708: \ttrain loss 1.9209479093551636\tacc 0.157143\tval loss 1.9389599561691284\tacc 0.162000\n",
      "709: \ttrain loss 1.9209346771240234\tacc 0.164286\tval loss 1.9387199878692627\tacc 0.166000\n",
      "710: \ttrain loss 1.9209463596343994\tacc 0.157143\tval loss 1.9389256238937378\tacc 0.164000\n",
      "711: \ttrain loss 1.920937180519104\tacc 0.164286\tval loss 1.9387763738632202\tacc 0.168000\n",
      "712: \ttrain loss 1.9209426641464233\tacc 0.150000\tval loss 1.9388548135757446\tacc 0.164000\n",
      "713: \ttrain loss 1.9209411144256592\tacc 0.157143\tval loss 1.938852071762085\tacc 0.162000\n",
      "714: \ttrain loss 1.9209392070770264\tacc 0.150000\tval loss 1.9387837648391724\tacc 0.164000\n",
      "715: \ttrain loss 1.9209442138671875\tacc 0.157143\tval loss 1.9389094114303589\tacc 0.166000\n",
      "716: \ttrain loss 1.9209370613098145\tacc 0.157143\tval loss 1.9387457370758057\tacc 0.166000\n",
      "717: \ttrain loss 1.9209452867507935\tacc 0.157143\tval loss 1.9389246702194214\tacc 0.164000\n",
      "718: \ttrain loss 1.9209370613098145\tacc 0.164286\tval loss 1.9387526512145996\tacc 0.166000\n",
      "719: \ttrain loss 1.9209446907043457\tacc 0.157143\tval loss 1.9388993978500366\tacc 0.164000\n",
      "720: \ttrain loss 1.9209381341934204\tacc 0.164286\tval loss 1.93878972530365\tacc 0.166000\n",
      "721: \ttrain loss 1.9209429025650024\tacc 0.150000\tval loss 1.9388574361801147\tacc 0.164000\n",
      "722: \ttrain loss 1.9209402799606323\tacc 0.157143\tval loss 1.9388313293457031\tacc 0.166000\n",
      "723: \ttrain loss 1.9209411144256592\tacc 0.150000\tval loss 1.9388208389282227\tacc 0.164000\n",
      "724: \ttrain loss 1.9209423065185547\tacc 0.157143\tval loss 1.9388612508773804\tacc 0.166000\n",
      "725: \ttrain loss 1.9209389686584473\tacc 0.150000\tval loss 1.938798189163208\tacc 0.164000\n",
      "726: \ttrain loss 1.9209433794021606\tacc 0.157143\tval loss 1.9388771057128906\tacc 0.164000\n",
      "727: \ttrain loss 1.9209383726119995\tacc 0.150000\tval loss 1.9387882947921753\tacc 0.164000\n",
      "728: \ttrain loss 1.9209437370300293\tacc 0.157143\tval loss 1.9388822317123413\tacc 0.164000\n",
      "729: \ttrain loss 1.9209383726119995\tacc 0.157143\tval loss 1.9387882947921753\tacc 0.166000\n",
      "730: \ttrain loss 1.9209433794021606\tacc 0.157143\tval loss 1.9388784170150757\tacc 0.164000\n",
      "731: \ttrain loss 1.9209392070770264\tacc 0.164286\tval loss 1.9387949705123901\tacc 0.166000\n",
      "732: \ttrain loss 1.9209426641464233\tacc 0.157143\tval loss 1.9388679265975952\tacc 0.164000\n",
      "733: \ttrain loss 1.9209398031234741\tacc 0.164286\tval loss 1.938808798789978\tacc 0.164000\n",
      "734: \ttrain loss 1.9209415912628174\tacc 0.150000\tval loss 1.9388524293899536\tacc 0.164000\n",
      "735: \ttrain loss 1.9209407567977905\tacc 0.157143\tval loss 1.9388254880905151\tacc 0.166000\n",
      "736: \ttrain loss 1.9209407567977905\tacc 0.150000\tval loss 1.9388360977172852\tacc 0.164000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "737: \ttrain loss 1.9209418296813965\tacc 0.157143\tval loss 1.938840627670288\tacc 0.166000\n",
      "738: \ttrain loss 1.9209402799606323\tacc 0.150000\tval loss 1.9388233423233032\tacc 0.164000\n",
      "739: \ttrain loss 1.9209423065185547\tacc 0.157143\tval loss 1.9388508796691895\tacc 0.166000\n",
      "740: \ttrain loss 1.9209398031234741\tacc 0.150000\tval loss 1.9388158321380615\tacc 0.164000\n",
      "741: \ttrain loss 1.9209424257278442\tacc 0.157143\tval loss 1.9388554096221924\tacc 0.166000\n",
      "742: \ttrain loss 1.9209396839141846\tacc 0.150000\tval loss 1.9388127326965332\tacc 0.164000\n",
      "743: \ttrain loss 1.9209426641464233\tacc 0.157143\tval loss 1.9388575553894043\tacc 0.164000\n",
      "744: \ttrain loss 1.9209394454956055\tacc 0.150000\tval loss 1.938811182975769\tacc 0.164000\n",
      "745: \ttrain loss 1.9209426641464233\tacc 0.157143\tval loss 1.938859462738037\tacc 0.164000\n",
      "746: \ttrain loss 1.9209394454956055\tacc 0.157143\tval loss 1.938808798789978\tacc 0.164000\n",
      "747: \ttrain loss 1.9209426641464233\tacc 0.157143\tval loss 1.9388625621795654\tacc 0.164000\n",
      "748: \ttrain loss 1.9209396839141846\tacc 0.157143\tval loss 1.9388049840927124\tacc 0.164000\n",
      "749: \ttrain loss 1.9209424257278442\tacc 0.157143\tval loss 1.9388664960861206\tacc 0.164000\n",
      "750: \ttrain loss 1.9209394454956055\tacc 0.157143\tval loss 1.9388004541397095\tacc 0.164000\n",
      "751: \ttrain loss 1.9209429025650024\tacc 0.157143\tval loss 1.9388717412948608\tacc 0.164000\n",
      "752: \ttrain loss 1.9209394454956055\tacc 0.157143\tval loss 1.9387946128845215\tacc 0.164000\n",
      "753: \ttrain loss 1.9209431409835815\tacc 0.157143\tval loss 1.9388785362243652\tacc 0.164000\n",
      "754: \ttrain loss 1.9209389686584473\tacc 0.157143\tval loss 1.938786506652832\tacc 0.164000\n",
      "755: \ttrain loss 1.9209436178207397\tacc 0.157143\tval loss 1.9388887882232666\tacc 0.164000\n",
      "756: \ttrain loss 1.9209383726119995\tacc 0.164286\tval loss 1.9387729167938232\tacc 0.166000\n",
      "757: \ttrain loss 1.9209444522857666\tacc 0.157143\tval loss 1.9389065504074097\tacc 0.164000\n",
      "758: \ttrain loss 1.920937180519104\tacc 0.164286\tval loss 1.9387505054473877\tacc 0.166000\n",
      "759: \ttrain loss 1.9209452867507935\tacc 0.157143\tval loss 1.9389344453811646\tacc 0.164000\n",
      "760: \ttrain loss 1.9209363460540771\tacc 0.164286\tval loss 1.9387153387069702\tacc 0.166000\n",
      "761: \ttrain loss 1.9209470748901367\tacc 0.157143\tval loss 1.9389795064926147\tacc 0.162000\n",
      "762: \ttrain loss 1.9209344387054443\tacc 0.164286\tval loss 1.9386588335037231\tacc 0.166000\n",
      "763: \ttrain loss 1.920949935913086\tacc 0.157143\tval loss 1.939051628112793\tacc 0.164000\n",
      "764: \ttrain loss 1.920931339263916\tacc 0.164286\tval loss 1.9385675191879272\tacc 0.162000\n",
      "765: \ttrain loss 1.9209539890289307\tacc 0.157143\tval loss 1.939168930053711\tacc 0.162000\n",
      "766: \ttrain loss 1.9209263324737549\tacc 0.164286\tval loss 1.938418984413147\tacc 0.160000\n",
      "767: \ttrain loss 1.9209623336791992\tacc 0.157143\tval loss 1.939361810684204\tacc 0.162000\n",
      "768: \ttrain loss 1.9209191799163818\tacc 0.164286\tval loss 1.9381731748580933\tacc 0.160000\n",
      "769: \ttrain loss 1.9209758043289185\tacc 0.164286\tval loss 1.9396820068359375\tacc 0.164000\n",
      "770: \ttrain loss 1.9209084510803223\tacc 0.157143\tval loss 1.937772512435913\tacc 0.162000\n",
      "771: \ttrain loss 1.9209994077682495\tacc 0.164286\tval loss 1.9401984214782715\tacc 0.166000\n",
      "772: \ttrain loss 1.9208945035934448\tacc 0.178571\tval loss 1.9371600151062012\tacc 0.170000\n",
      "773: \ttrain loss 1.9210407733917236\tacc 0.171429\tval loss 1.9409370422363281\tacc 0.166000\n",
      "774: \ttrain loss 1.9208825826644897\tacc 0.171429\tval loss 1.9364128112792969\tacc 0.170000\n",
      "775: \ttrain loss 1.9210999011993408\tacc 0.164286\tval loss 1.941623568534851\tacc 0.162000\n",
      "776: \ttrain loss 1.9208790063858032\tacc 0.178571\tval loss 1.9360804557800293\tacc 0.172000\n",
      "777: \ttrain loss 1.9211312532424927\tacc 0.171429\tval loss 1.9413676261901855\tacc 0.162000\n",
      "778: \ttrain loss 1.9208818674087524\tacc 0.171429\tval loss 1.9370700120925903\tacc 0.168000\n",
      "779: \ttrain loss 1.921053409576416\tacc 0.171429\tval loss 1.9396567344665527\tacc 0.160000\n",
      "780: \ttrain loss 1.9209141731262207\tacc 0.150000\tval loss 1.9390851259231567\tacc 0.160000\n",
      "781: \ttrain loss 1.9209411144256592\tacc 0.178571\tval loss 1.937739610671997\tacc 0.160000\n",
      "782: \ttrain loss 1.9210083484649658\tacc 0.171429\tval loss 1.9405018091201782\tacc 0.166000\n",
      "783: \ttrain loss 1.920899748802185\tacc 0.192857\tval loss 1.9371427297592163\tacc 0.166000\n",
      "784: \ttrain loss 1.9210541248321533\tacc 0.171429\tval loss 1.9402034282684326\tacc 0.166000\n",
      "785: \ttrain loss 1.9209026098251343\tacc 0.178571\tval loss 1.9381921291351318\tacc 0.160000\n",
      "786: \ttrain loss 1.92099130153656\tacc 0.178571\tval loss 1.9387338161468506\tacc 0.160000\n",
      "787: \ttrain loss 1.9209526777267456\tacc 0.157143\tval loss 1.9395825862884521\tacc 0.164000\n",
      "788: \ttrain loss 1.920928716659546\tacc 0.192857\tval loss 1.9378019571304321\tacc 0.162000\n",
      "789: \ttrain loss 1.921014428138733\tacc 0.164286\tval loss 1.9398456811904907\tacc 0.166000\n",
      "790: \ttrain loss 1.9209123849868774\tacc 0.178571\tval loss 1.9381963014602661\tacc 0.164000\n",
      "791: \ttrain loss 1.9209994077682495\tacc 0.164286\tval loss 1.9390027523040771\tacc 0.162000\n",
      "792: \ttrain loss 1.920935034751892\tacc 0.150000\tval loss 1.9391238689422607\tacc 0.160000\n",
      "793: \ttrain loss 1.9209465980529785\tacc 0.178571\tval loss 1.9382752180099487\tacc 0.162000\n",
      "794: \ttrain loss 1.9209829568862915\tacc 0.164286\tval loss 1.9394460916519165\tacc 0.164000\n",
      "795: \ttrain loss 1.920921802520752\tacc 0.171429\tval loss 1.9383896589279175\tacc 0.160000\n",
      "796: \ttrain loss 1.9209928512573242\tacc 0.164286\tval loss 1.9389994144439697\tacc 0.162000\n",
      "797: \ttrain loss 1.92093026638031\tacc 0.164286\tval loss 1.9389543533325195\tacc 0.160000\n",
      "798: \ttrain loss 1.9209553003311157\tacc 0.157143\tval loss 1.938504695892334\tacc 0.164000\n",
      "799: \ttrain loss 1.9209634065628052\tacc 0.150000\tval loss 1.9392246007919312\tacc 0.162000\n",
      "800: \ttrain loss 1.9209270477294922\tacc 0.157143\tval loss 1.9385006427764893\tacc 0.162000\n",
      "801: \ttrain loss 1.9209823608398438\tacc 0.164286\tval loss 1.9390172958374023\tacc 0.162000\n",
      "802: \ttrain loss 1.92092764377594\tacc 0.164286\tval loss 1.9388154745101929\tacc 0.160000\n",
      "803: \ttrain loss 1.9209610223770142\tacc 0.157143\tval loss 1.9386987686157227\tacc 0.164000\n",
      "804: \ttrain loss 1.9209500551223755\tacc 0.157143\tval loss 1.9390572309494019\tacc 0.164000\n",
      "805: \ttrain loss 1.9209328889846802\tacc 0.164286\tval loss 1.9385714530944824\tacc 0.164000\n",
      "806: \ttrain loss 1.9209712743759155\tacc 0.164286\tval loss 1.9390772581100464\tacc 0.162000\n",
      "807: \ttrain loss 1.920925498008728\tacc 0.164286\tval loss 1.938653826713562\tacc 0.162000\n",
      "808: \ttrain loss 1.9209644794464111\tacc 0.164286\tval loss 1.9389177560806274\tacc 0.164000\n",
      "809: \ttrain loss 1.9209389686584473\tacc 0.164286\tval loss 1.9388657808303833\tacc 0.162000\n",
      "810: \ttrain loss 1.9209409952163696\tacc 0.150000\tval loss 1.938693642616272\tacc 0.164000\n",
      "811: \ttrain loss 1.920959234237671\tacc 0.157143\tval loss 1.9390641450881958\tacc 0.166000\n",
      "812: \ttrain loss 1.92092764377594\tacc 0.164286\tval loss 1.9385740756988525\tacc 0.164000\n",
      "813: \ttrain loss 1.9209636449813843\tacc 0.157143\tval loss 1.939079761505127\tacc 0.164000\n",
      "814: \ttrain loss 1.920931100845337\tacc 0.164286\tval loss 1.9386744499206543\tacc 0.164000\n",
      "815: \ttrain loss 1.920949935913086\tacc 0.150000\tval loss 1.9388840198516846\tacc 0.164000\n",
      "816: \ttrain loss 1.9209457635879517\tacc 0.164286\tval loss 1.9389222860336304\tacc 0.164000\n",
      "817: \ttrain loss 1.9209344387054443\tacc 0.164286\tval loss 1.9386461973190308\tacc 0.162000\n",
      "818: \ttrain loss 1.9209566116333008\tacc 0.150000\tval loss 1.9390908479690552\tacc 0.164000\n",
      "819: \ttrain loss 1.9209297895431519\tacc 0.164286\tval loss 1.9385905265808105\tacc 0.164000\n",
      "820: \ttrain loss 1.920953392982483\tacc 0.150000\tval loss 1.9390181303024292\tacc 0.162000\n",
      "821: \ttrain loss 1.9209368228912354\tacc 0.164286\tval loss 1.9387658834457397\tacc 0.164000\n",
      "822: \ttrain loss 1.9209423065185547\tacc 0.157143\tval loss 1.9387904405593872\tacc 0.162000\n",
      "823: \ttrain loss 1.9209463596343994\tacc 0.150000\tval loss 1.9389781951904297\tacc 0.164000\n",
      "824: \ttrain loss 1.9209342002868652\tacc 0.164286\tval loss 1.9386485815048218\tacc 0.164000\n",
      "825: \ttrain loss 1.9209505319595337\tacc 0.150000\tval loss 1.9390153884887695\tacc 0.162000\n",
      "826: \ttrain loss 1.9209339618682861\tacc 0.164286\tval loss 1.9387123584747314\tacc 0.164000\n",
      "827: \ttrain loss 1.9209463596343994\tacc 0.150000\tval loss 1.9388768672943115\tacc 0.164000\n",
      "828: \ttrain loss 1.9209394454956055\tacc 0.157143\tval loss 1.9388760328292847\tacc 0.164000\n",
      "829: \ttrain loss 1.9209392070770264\tacc 0.164286\tval loss 1.9387327432632446\tacc 0.164000\n",
      "830: \ttrain loss 1.9209457635879517\tacc 0.150000\tval loss 1.9389632940292358\tacc 0.162000\n",
      "831: \ttrain loss 1.920935034751892\tacc 0.164286\tval loss 1.9387171268463135\tacc 0.164000\n",
      "832: \ttrain loss 1.9209465980529785\tacc 0.150000\tval loss 1.938909888267517\tacc 0.162000\n",
      "833: \ttrain loss 1.920936107635498\tacc 0.164286\tval loss 1.9388155937194824\tacc 0.164000\n",
      "834: \ttrain loss 1.9209433794021606\tacc 0.150000\tval loss 1.9387964010238647\tacc 0.164000\n",
      "835: \ttrain loss 1.9209407567977905\tacc 0.157143\tval loss 1.938913345336914\tacc 0.164000\n",
      "836: \ttrain loss 1.920938491821289\tacc 0.164286\tval loss 1.938735008239746\tacc 0.168000\n",
      "837: \ttrain loss 1.9209448099136353\tacc 0.150000\tval loss 1.9389301538467407\tacc 0.162000\n",
      "838: \ttrain loss 1.9209357500076294\tacc 0.164286\tval loss 1.9387582540512085\tacc 0.164000\n",
      "839: \ttrain loss 1.9209460020065308\tacc 0.150000\tval loss 1.9388811588287354\tacc 0.164000\n",
      "840: \ttrain loss 1.9209370613098145\tacc 0.164286\tval loss 1.9388182163238525\tacc 0.164000\n",
      "841: \ttrain loss 1.9209429025650024\tacc 0.157143\tval loss 1.9388231039047241\tacc 0.164000\n",
      "842: \ttrain loss 1.9209402799606323\tacc 0.157143\tval loss 1.9388644695281982\tacc 0.164000\n",
      "843: \ttrain loss 1.9209396839141846\tacc 0.157143\tval loss 1.9387924671173096\tacc 0.166000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "844: \ttrain loss 1.9209433794021606\tacc 0.157143\tval loss 1.9388806819915771\tacc 0.164000\n",
      "845: \ttrain loss 1.920937418937683\tacc 0.164286\tval loss 1.938788652420044\tacc 0.166000\n",
      "846: \ttrain loss 1.9209446907043457\tacc 0.157143\tval loss 1.9388762712478638\tacc 0.164000\n",
      "847: \ttrain loss 1.9209376573562622\tacc 0.164286\tval loss 1.9387989044189453\tacc 0.164000\n",
      "848: \ttrain loss 1.9209436178207397\tacc 0.157143\tval loss 1.9388628005981445\tacc 0.164000\n",
      "849: \ttrain loss 1.9209392070770264\tacc 0.157143\tval loss 1.9388154745101929\tacc 0.164000\n",
      "850: \ttrain loss 1.9209411144256592\tacc 0.157143\tval loss 1.9388434886932373\tacc 0.166000\n",
      "851: \ttrain loss 1.9209415912628174\tacc 0.150000\tval loss 1.9388368129730225\tacc 0.164000\n",
      "852: \ttrain loss 1.9209394454956055\tacc 0.157143\tval loss 1.938822865486145\tacc 0.164000\n",
      "853: \ttrain loss 1.9209426641464233\tacc 0.150000\tval loss 1.9388527870178223\tacc 0.164000\n",
      "854: \ttrain loss 1.9209389686584473\tacc 0.164286\tval loss 1.938815712928772\tacc 0.164000\n",
      "855: \ttrain loss 1.9209426641464233\tacc 0.150000\tval loss 1.9388493299484253\tacc 0.164000\n",
      "856: \ttrain loss 1.9209398031234741\tacc 0.164286\tval loss 1.9388303756713867\tacc 0.162000\n",
      "857: \ttrain loss 1.9209411144256592\tacc 0.150000\tval loss 1.9388251304626465\tacc 0.164000\n",
      "858: \ttrain loss 1.9209411144256592\tacc 0.157143\tval loss 1.9388610124588013\tacc 0.162000\n",
      "859: \ttrain loss 1.9209398031234741\tacc 0.150000\tval loss 1.938791036605835\tacc 0.164000\n",
      "860: \ttrain loss 1.9209433794021606\tacc 0.157143\tval loss 1.9388951063156128\tacc 0.162000\n",
      "861: \ttrain loss 1.9209387302398682\tacc 0.150000\tval loss 1.9387612342834473\tacc 0.164000\n",
      "862: \ttrain loss 1.9209437370300293\tacc 0.157143\tval loss 1.9389179944992065\tacc 0.162000\n",
      "863: \ttrain loss 1.9209381341934204\tacc 0.150000\tval loss 1.9387457370758057\tacc 0.164000\n",
      "864: \ttrain loss 1.9209444522857666\tacc 0.157143\tval loss 1.9389277696609497\tacc 0.162000\n",
      "865: \ttrain loss 1.9209381341934204\tacc 0.150000\tval loss 1.9387372732162476\tacc 0.164000\n",
      "866: \ttrain loss 1.9209448099136353\tacc 0.157143\tval loss 1.9389405250549316\tacc 0.158000\n",
      "867: \ttrain loss 1.9209376573562622\tacc 0.150000\tval loss 1.9387145042419434\tacc 0.164000\n",
      "868: \ttrain loss 1.9209455251693726\tacc 0.164286\tval loss 1.938976526260376\tacc 0.160000\n",
      "869: \ttrain loss 1.920937418937683\tacc 0.157143\tval loss 1.9386628866195679\tacc 0.162000\n",
      "870: \ttrain loss 1.9209473133087158\tacc 0.164286\tval loss 1.939048171043396\tacc 0.158000\n",
      "871: \ttrain loss 1.9209363460540771\tacc 0.171429\tval loss 1.938570261001587\tacc 0.162000\n",
      "872: \ttrain loss 1.9209513664245605\tacc 0.178571\tval loss 1.939164161682129\tacc 0.160000\n",
      "873: \ttrain loss 1.9209339618682861\tacc 0.157143\tval loss 1.9384363889694214\tacc 0.160000\n",
      "874: \ttrain loss 1.920958161354065\tacc 0.178571\tval loss 1.9393101930618286\tacc 0.158000\n",
      "875: \ttrain loss 1.920931339263916\tacc 0.157143\tval loss 1.9383012056350708\tacc 0.160000\n",
      "876: \ttrain loss 1.9209681749343872\tacc 0.178571\tval loss 1.9394128322601318\tacc 0.158000\n",
      "877: \ttrain loss 1.9209274053573608\tacc 0.157143\tval loss 1.9382669925689697\tacc 0.158000\n",
      "878: \ttrain loss 1.9209773540496826\tacc 0.178571\tval loss 1.9393585920333862\tacc 0.158000\n",
      "879: \ttrain loss 1.9209213256835938\tacc 0.157143\tval loss 1.9384082555770874\tacc 0.158000\n",
      "880: \ttrain loss 1.9209794998168945\tacc 0.178571\tval loss 1.9391716718673706\tacc 0.160000\n",
      "881: \ttrain loss 1.9209158420562744\tacc 0.150000\tval loss 1.9385771751403809\tacc 0.164000\n",
      "882: \ttrain loss 1.9209762811660767\tacc 0.178571\tval loss 1.939077377319336\tacc 0.162000\n",
      "883: \ttrain loss 1.9209182262420654\tacc 0.164286\tval loss 1.9385734796524048\tacc 0.162000\n",
      "884: \ttrain loss 1.9209694862365723\tacc 0.164286\tval loss 1.9391522407531738\tacc 0.162000\n",
      "885: \ttrain loss 1.9209274053573608\tacc 0.157143\tval loss 1.938485860824585\tacc 0.162000\n",
      "886: \ttrain loss 1.9209579229354858\tacc 0.157143\tval loss 1.9391734600067139\tacc 0.160000\n",
      "887: \ttrain loss 1.9209387302398682\tacc 0.171429\tval loss 1.938585638999939\tacc 0.160000\n",
      "888: \ttrain loss 1.9209446907043457\tacc 0.150000\tval loss 1.9389358758926392\tacc 0.160000\n",
      "889: \ttrain loss 1.9209494590759277\tacc 0.178571\tval loss 1.9389264583587646\tacc 0.162000\n",
      "890: \ttrain loss 1.920933485031128\tacc 0.164286\tval loss 1.938559651374817\tacc 0.162000\n",
      "891: \ttrain loss 1.9209589958190918\tacc 0.150000\tval loss 1.939262866973877\tacc 0.164000\n",
      "892: \ttrain loss 1.92092764377594\tacc 0.157143\tval loss 1.93832528591156\tacc 0.164000\n",
      "893: \ttrain loss 1.920965552330017\tacc 0.157143\tval loss 1.9393600225448608\tacc 0.164000\n",
      "894: \ttrain loss 1.9209250211715698\tacc 0.171429\tval loss 1.9383662939071655\tacc 0.160000\n",
      "895: \ttrain loss 1.9209657907485962\tacc 0.157143\tval loss 1.9392073154449463\tacc 0.162000\n",
      "896: \ttrain loss 1.9209250211715698\tacc 0.164286\tval loss 1.938578724861145\tacc 0.166000\n",
      "897: \ttrain loss 1.920962929725647\tacc 0.164286\tval loss 1.9389925003051758\tacc 0.162000\n",
      "898: \ttrain loss 1.9209271669387817\tacc 0.157143\tval loss 1.9387407302856445\tacc 0.162000\n",
      "899: \ttrain loss 1.92095947265625\tacc 0.178571\tval loss 1.9389126300811768\tacc 0.162000\n",
      "900: \ttrain loss 1.9209308624267578\tacc 0.157143\tval loss 1.9387320280075073\tacc 0.160000\n",
      "901: \ttrain loss 1.920956015586853\tacc 0.178571\tval loss 1.9389841556549072\tacc 0.162000\n",
      "902: \ttrain loss 1.9209331274032593\tacc 0.157143\tval loss 1.9386377334594727\tacc 0.164000\n",
      "903: \ttrain loss 1.9209524393081665\tacc 0.157143\tval loss 1.9390554428100586\tacc 0.160000\n",
      "904: \ttrain loss 1.920935034751892\tacc 0.157143\tval loss 1.9386191368103027\tacc 0.164000\n",
      "905: \ttrain loss 1.920949935913086\tacc 0.157143\tval loss 1.939012885093689\tacc 0.162000\n",
      "906: \ttrain loss 1.9209363460540771\tacc 0.164286\tval loss 1.9387093782424927\tacc 0.164000\n",
      "907: \ttrain loss 1.9209481477737427\tacc 0.150000\tval loss 1.9389023780822754\tacc 0.162000\n",
      "908: \ttrain loss 1.9209381341934204\tacc 0.164286\tval loss 1.938814401626587\tacc 0.160000\n",
      "909: \ttrain loss 1.9209463596343994\tacc 0.150000\tval loss 1.9388257265090942\tacc 0.160000\n",
      "910: \ttrain loss 1.9209394454956055\tacc 0.164286\tval loss 1.9388552904129028\tacc 0.160000\n",
      "911: \ttrain loss 1.9209442138671875\tacc 0.150000\tval loss 1.9388190507888794\tacc 0.162000\n",
      "912: \ttrain loss 1.9209407567977905\tacc 0.164286\tval loss 1.9388374090194702\tacc 0.162000\n",
      "913: \ttrain loss 1.9209423065185547\tacc 0.150000\tval loss 1.9388477802276611\tacc 0.164000\n",
      "914: \ttrain loss 1.9209420680999756\tacc 0.150000\tval loss 1.9388136863708496\tacc 0.164000\n",
      "915: \ttrain loss 1.9209407567977905\tacc 0.157143\tval loss 1.938857078552246\tacc 0.162000\n",
      "916: \ttrain loss 1.9209436178207397\tacc 0.150000\tval loss 1.938826084136963\tacc 0.162000\n",
      "917: \ttrain loss 1.9209400415420532\tacc 0.164286\tval loss 1.93882155418396\tacc 0.162000\n",
      "918: \ttrain loss 1.9209442138671875\tacc 0.150000\tval loss 1.9388786554336548\tacc 0.162000\n",
      "919: \ttrain loss 1.9209387302398682\tacc 0.164286\tval loss 1.9387624263763428\tacc 0.164000\n",
      "920: \ttrain loss 1.9209448099136353\tacc 0.150000\tval loss 1.9389317035675049\tacc 0.162000\n",
      "921: \ttrain loss 1.9209378957748413\tacc 0.164286\tval loss 1.938724160194397\tacc 0.166000\n",
      "922: \ttrain loss 1.9209455251693726\tacc 0.150000\tval loss 1.9389508962631226\tacc 0.164000\n",
      "923: \ttrain loss 1.9209365844726562\tacc 0.164286\tval loss 1.9387210607528687\tacc 0.166000\n",
      "924: \ttrain loss 1.9209470748901367\tacc 0.157143\tval loss 1.9389455318450928\tacc 0.162000\n",
      "925: \ttrain loss 1.920934796333313\tacc 0.150000\tval loss 1.938722014427185\tacc 0.164000\n",
      "926: \ttrain loss 1.9209496974945068\tacc 0.157143\tval loss 1.938961148262024\tacc 0.162000\n",
      "927: \ttrain loss 1.9209318161010742\tacc 0.150000\tval loss 1.9386814832687378\tacc 0.166000\n",
      "928: \ttrain loss 1.9209539890289307\tacc 0.171429\tval loss 1.9390348196029663\tacc 0.162000\n",
      "929: \ttrain loss 1.9209270477294922\tacc 0.157143\tval loss 1.938570499420166\tacc 0.166000\n",
      "930: \ttrain loss 1.9209610223770142\tacc 0.178571\tval loss 1.9391878843307495\tacc 0.160000\n",
      "931: \ttrain loss 1.9209202527999878\tacc 0.157143\tval loss 1.9383760690689087\tacc 0.160000\n",
      "932: \ttrain loss 1.9209738969802856\tacc 0.178571\tval loss 1.93943452835083\tacc 0.160000\n",
      "933: \ttrain loss 1.9209092855453491\tacc 0.157143\tval loss 1.9380824565887451\tacc 0.160000\n",
      "934: \ttrain loss 1.9209957122802734\tacc 0.178571\tval loss 1.9397987127304077\tacc 0.164000\n",
      "935: \ttrain loss 1.920896053314209\tacc 0.150000\tval loss 1.9376670122146606\tacc 0.164000\n",
      "936: \ttrain loss 1.9210329055786133\tacc 0.171429\tval loss 1.9403043985366821\tacc 0.162000\n",
      "937: \ttrain loss 1.9208827018737793\tacc 0.150000\tval loss 1.9371418952941895\tacc 0.166000\n",
      "938: \ttrain loss 1.921087384223938\tacc 0.171429\tval loss 1.9408618211746216\tacc 0.162000\n",
      "939: \ttrain loss 1.9208768606185913\tacc 0.142857\tval loss 1.936730980873108\tacc 0.174000\n",
      "940: \ttrain loss 1.9211279153823853\tacc 0.178571\tval loss 1.9410090446472168\tacc 0.162000\n",
      "941: \ttrain loss 1.9208794832229614\tacc 0.142857\tval loss 1.9370272159576416\tacc 0.166000\n",
      "942: \ttrain loss 1.9210784435272217\tacc 0.171429\tval loss 1.9401096105575562\tacc 0.158000\n",
      "943: \ttrain loss 1.9209016561508179\tacc 0.142857\tval loss 1.938376784324646\tacc 0.162000\n",
      "944: \ttrain loss 1.9209651947021484\tacc 0.157143\tval loss 1.938471794128418\tacc 0.162000\n",
      "945: \ttrain loss 1.9209781885147095\tacc 0.157143\tval loss 1.9399510622024536\tacc 0.162000\n",
      "946: \ttrain loss 1.920903205871582\tacc 0.150000\tval loss 1.9373127222061157\tacc 0.168000\n",
      "947: \ttrain loss 1.921051263809204\tacc 0.185714\tval loss 1.9404889345169067\tacc 0.160000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "948: \ttrain loss 1.9208978414535522\tacc 0.142857\tval loss 1.9375368356704712\tacc 0.164000\n",
      "949: \ttrain loss 1.9210249185562134\tacc 0.178571\tval loss 1.93954598903656\tacc 0.160000\n",
      "950: \ttrain loss 1.920926570892334\tacc 0.150000\tval loss 1.9388877153396606\tacc 0.164000\n",
      "951: \ttrain loss 1.9209486246109009\tacc 0.164286\tval loss 1.9381427764892578\tacc 0.162000\n",
      "952: \ttrain loss 1.9209891557693481\tacc 0.164286\tval loss 1.9399651288986206\tacc 0.158000\n",
      "953: \ttrain loss 1.9209128618240356\tacc 0.150000\tval loss 1.9376481771469116\tacc 0.164000\n",
      "954: \ttrain loss 1.9210199117660522\tacc 0.178571\tval loss 1.9398095607757568\tacc 0.160000\n",
      "955: \ttrain loss 1.9209152460098267\tacc 0.150000\tval loss 1.9383306503295898\tacc 0.160000\n",
      "956: \ttrain loss 1.9209810495376587\tacc 0.164286\tval loss 1.9388214349746704\tacc 0.164000\n",
      "957: \ttrain loss 1.9209502935409546\tacc 0.164286\tval loss 1.939300298690796\tacc 0.160000\n",
      "958: \ttrain loss 1.9209333658218384\tacc 0.157143\tval loss 1.9381085634231567\tacc 0.160000\n",
      "959: \ttrain loss 1.920992136001587\tacc 0.178571\tval loss 1.93960702419281\tacc 0.160000\n",
      "960: \ttrain loss 1.9209171533584595\tacc 0.150000\tval loss 1.9382272958755493\tacc 0.160000\n",
      "961: \ttrain loss 1.920989751815796\tacc 0.178571\tval loss 1.9391517639160156\tacc 0.166000\n",
      "962: \ttrain loss 1.92093026638031\tacc 0.157143\tval loss 1.938834309577942\tacc 0.162000\n",
      "963: \ttrain loss 1.9209526777267456\tacc 0.150000\tval loss 1.9385631084442139\tacc 0.164000\n",
      "964: \ttrain loss 1.920962929725647\tacc 0.157143\tval loss 1.9392530918121338\tacc 0.160000\n",
      "965: \ttrain loss 1.9209257364273071\tacc 0.157143\tval loss 1.9383870363235474\tacc 0.162000\n",
      "966: \ttrain loss 1.9209808111190796\tacc 0.178571\tval loss 1.9391955137252808\tacc 0.160000\n",
      "967: \ttrain loss 1.9209234714508057\tacc 0.157143\tval loss 1.938623309135437\tacc 0.166000\n",
      "968: \ttrain loss 1.920964241027832\tacc 0.178571\tval loss 1.9388625621795654\tacc 0.164000\n",
      "969: \ttrain loss 1.9209423065185547\tacc 0.157143\tval loss 1.938966155052185\tacc 0.164000\n",
      "970: \ttrain loss 1.9209370613098145\tacc 0.157143\tval loss 1.9385827779769897\tacc 0.166000\n",
      "971: \ttrain loss 1.9209644794464111\tacc 0.171429\tval loss 1.9391427040100098\tacc 0.162000\n",
      "972: \ttrain loss 1.9209247827529907\tacc 0.157143\tval loss 1.9385433197021484\tacc 0.166000\n",
      "973: \ttrain loss 1.9209662675857544\tacc 0.178571\tval loss 1.9390525817871094\tacc 0.162000\n",
      "974: \ttrain loss 1.920931100845337\tacc 0.157143\tval loss 1.9387418031692505\tacc 0.164000\n",
      "975: \ttrain loss 1.9209489822387695\tacc 0.157143\tval loss 1.938792109489441\tacc 0.164000\n",
      "976: \ttrain loss 1.9209476709365845\tacc 0.150000\tval loss 1.9390100240707397\tacc 0.164000\n",
      "977: \ttrain loss 1.920932412147522\tacc 0.164286\tval loss 1.9385777711868286\tacc 0.166000\n",
      "978: \ttrain loss 1.92095947265625\tacc 0.157143\tval loss 1.9391299486160278\tacc 0.162000\n",
      "979: \ttrain loss 1.9209281206130981\tacc 0.157143\tval loss 1.9385795593261719\tacc 0.166000\n",
      "980: \ttrain loss 1.9209550619125366\tacc 0.157143\tval loss 1.9390102624893188\tacc 0.160000\n",
      "981: \ttrain loss 1.9209352731704712\tacc 0.150000\tval loss 1.938786268234253\tacc 0.164000\n",
      "982: \ttrain loss 1.9209429025650024\tacc 0.157143\tval loss 1.9387634992599487\tacc 0.166000\n",
      "983: \ttrain loss 1.9209468364715576\tacc 0.157143\tval loss 1.9390150308609009\tacc 0.162000\n",
      "984: \ttrain loss 1.9209328889846802\tacc 0.157143\tval loss 1.9386028051376343\tacc 0.164000\n",
      "985: \ttrain loss 1.9209529161453247\tacc 0.157143\tval loss 1.939073920249939\tacc 0.162000\n",
      "986: \ttrain loss 1.9209308624267578\tacc 0.150000\tval loss 1.9386482238769531\tacc 0.164000\n",
      "987: \ttrain loss 1.9209494590759277\tacc 0.157143\tval loss 1.9389411211013794\tacc 0.164000\n",
      "988: \ttrain loss 1.9209370613098145\tacc 0.164286\tval loss 1.9388256072998047\tacc 0.166000\n",
      "989: \ttrain loss 1.9209409952163696\tacc 0.150000\tval loss 1.9387625455856323\tacc 0.164000\n",
      "990: \ttrain loss 1.9209444522857666\tacc 0.157143\tval loss 1.9389640092849731\tacc 0.162000\n",
      "991: \ttrain loss 1.9209342002868652\tacc 0.150000\tval loss 1.938686728477478\tacc 0.166000\n",
      "992: \ttrain loss 1.9209487438201904\tacc 0.157143\tval loss 1.9389678239822388\tacc 0.162000\n",
      "993: \ttrain loss 1.920933723449707\tacc 0.150000\tval loss 1.9387431144714355\tacc 0.166000\n",
      "994: \ttrain loss 1.9209463596343994\tacc 0.157143\tval loss 1.9388704299926758\tacc 0.166000\n",
      "995: \ttrain loss 1.920937180519104\tacc 0.150000\tval loss 1.9388532638549805\tacc 0.164000\n",
      "996: \ttrain loss 1.9209411144256592\tacc 0.157143\tval loss 1.9387696981430054\tacc 0.166000\n",
      "997: \ttrain loss 1.9209426641464233\tacc 0.157143\tval loss 1.938926100730896\tacc 0.164000\n",
      "998: \ttrain loss 1.9209363460540771\tacc 0.164286\tval loss 1.9387317895889282\tacc 0.166000\n",
      "999: \ttrain loss 1.9209461212158203\tacc 0.157143\tval loss 1.9389296770095825\tacc 0.164000\n",
      "1000: \ttrain loss 1.920935034751892\tacc 0.157143\tval loss 1.9387561082839966\tacc 0.166000\n",
      "1001: \ttrain loss 1.9209455251693726\tacc 0.157143\tval loss 1.938887119293213\tacc 0.164000\n",
      "1002: \ttrain loss 1.920937180519104\tacc 0.164286\tval loss 1.9388078451156616\tacc 0.164000\n",
      "1003: \ttrain loss 1.9209423065185547\tacc 0.157143\tval loss 1.9388335943222046\tacc 0.164000\n",
      "1004: \ttrain loss 1.9209407567977905\tacc 0.157143\tval loss 1.938857913017273\tacc 0.164000\n",
      "1005: \ttrain loss 1.9209387302398682\tacc 0.157143\tval loss 1.9387913942337036\tacc 0.164000\n",
      "1006: \ttrain loss 1.9209442138671875\tacc 0.157143\tval loss 1.938888669013977\tacc 0.164000\n",
      "1007: \ttrain loss 1.9209368228912354\tacc 0.150000\tval loss 1.9387761354446411\tacc 0.164000\n",
      "1008: \ttrain loss 1.9209446907043457\tacc 0.157143\tval loss 1.9388883113861084\tacc 0.166000\n",
      "1009: \ttrain loss 1.9209378957748413\tacc 0.150000\tval loss 1.9387927055358887\tacc 0.164000\n",
      "1010: \ttrain loss 1.9209433794021606\tacc 0.157143\tval loss 1.9388587474822998\tacc 0.164000\n",
      "1011: \ttrain loss 1.9209396839141846\tacc 0.150000\tval loss 1.9388316869735718\tacc 0.164000\n",
      "1012: \ttrain loss 1.9209407567977905\tacc 0.157143\tval loss 1.938815951347351\tacc 0.164000\n",
      "1013: \ttrain loss 1.9209423065185547\tacc 0.157143\tval loss 1.938873052597046\tacc 0.164000\n",
      "1014: \ttrain loss 1.9209389686584473\tacc 0.157143\tval loss 1.93878173828125\tacc 0.166000\n",
      "1015: \ttrain loss 1.9209436178207397\tacc 0.157143\tval loss 1.938895583152771\tacc 0.164000\n",
      "1016: \ttrain loss 1.920938491821289\tacc 0.164286\tval loss 1.9387733936309814\tacc 0.166000\n",
      "1017: \ttrain loss 1.9209433794021606\tacc 0.157143\tval loss 1.9388916492462158\tacc 0.164000\n",
      "1018: \ttrain loss 1.9209392070770264\tacc 0.164286\tval loss 1.9387866258621216\tacc 0.166000\n",
      "1019: \ttrain loss 1.9209429025650024\tacc 0.150000\tval loss 1.9388731718063354\tacc 0.164000\n",
      "1020: \ttrain loss 1.9209400415420532\tacc 0.164286\tval loss 1.9388048648834229\tacc 0.164000\n",
      "1021: \ttrain loss 1.9209418296813965\tacc 0.150000\tval loss 1.9388606548309326\tacc 0.164000\n",
      "1022: \ttrain loss 1.9209413528442383\tacc 0.164286\tval loss 1.938808798789978\tacc 0.162000\n",
      "1023: \ttrain loss 1.9209405183792114\tacc 0.150000\tval loss 1.938867449760437\tacc 0.164000\n",
      "1024: \ttrain loss 1.9209418296813965\tacc 0.164286\tval loss 1.9387890100479126\tacc 0.162000\n",
      "1025: \ttrain loss 1.9209402799606323\tacc 0.150000\tval loss 1.938901662826538\tacc 0.164000\n",
      "1026: \ttrain loss 1.9209420680999756\tacc 0.164286\tval loss 1.9387398958206177\tacc 0.162000\n",
      "1027: \ttrain loss 1.9209409952163696\tacc 0.150000\tval loss 1.9389674663543701\tacc 0.164000\n",
      "1028: \ttrain loss 1.9209415912628174\tacc 0.178571\tval loss 1.9386541843414307\tacc 0.160000\n",
      "1029: \ttrain loss 1.9209423065185547\tacc 0.150000\tval loss 1.9390761852264404\tacc 0.160000\n",
      "1030: \ttrain loss 1.9209407567977905\tacc 0.178571\tval loss 1.9385181665420532\tacc 0.160000\n",
      "1031: \ttrain loss 1.9209448099136353\tacc 0.150000\tval loss 1.9392465353012085\tacc 0.160000\n",
      "1032: \ttrain loss 1.9209402799606323\tacc 0.164286\tval loss 1.9383116960525513\tacc 0.158000\n",
      "1033: \ttrain loss 1.9209496974945068\tacc 0.150000\tval loss 1.9394892454147339\tacc 0.160000\n",
      "1034: \ttrain loss 1.9209413528442383\tacc 0.185714\tval loss 1.9380544424057007\tacc 0.158000\n",
      "1035: \ttrain loss 1.9209575653076172\tacc 0.157143\tval loss 1.9397194385528564\tacc 0.166000\n",
      "1036: \ttrain loss 1.9209442138671875\tacc 0.192857\tval loss 1.9379360675811768\tacc 0.158000\n",
      "1037: \ttrain loss 1.920964241027832\tacc 0.164286\tval loss 1.9396289587020874\tacc 0.166000\n",
      "1038: \ttrain loss 1.9209442138671875\tacc 0.192857\tval loss 1.9382987022399902\tacc 0.158000\n",
      "1039: \ttrain loss 1.920957326889038\tacc 0.164286\tval loss 1.9390252828598022\tacc 0.160000\n",
      "1040: \ttrain loss 1.9209387302398682\tacc 0.171429\tval loss 1.9389935731887817\tacc 0.158000\n",
      "1041: \ttrain loss 1.9209465980529785\tacc 0.150000\tval loss 1.9384346008300781\tacc 0.162000\n",
      "1042: \ttrain loss 1.9209429025650024\tacc 0.150000\tval loss 1.9393208026885986\tacc 0.158000\n",
      "1043: \ttrain loss 1.9209457635879517\tacc 0.171429\tval loss 1.9384363889694214\tacc 0.156000\n",
      "1044: \ttrain loss 1.920951008796692\tacc 0.164286\tval loss 1.9390329122543335\tacc 0.162000\n",
      "1045: \ttrain loss 1.9209444522857666\tacc 0.164286\tval loss 1.9388775825500488\tacc 0.156000\n",
      "1046: \ttrain loss 1.920949935913086\tacc 0.164286\tval loss 1.9386159181594849\tacc 0.162000\n",
      "1047: \ttrain loss 1.9209418296813965\tacc 0.157143\tval loss 1.9391227960586548\tacc 0.158000\n",
      "1048: \ttrain loss 1.9209461212158203\tacc 0.171429\tval loss 1.9386028051376343\tacc 0.158000\n",
      "1049: \ttrain loss 1.9209439754486084\tacc 0.150000\tval loss 1.9389350414276123\tacc 0.160000\n",
      "1050: \ttrain loss 1.9209470748901367\tacc 0.178571\tval loss 1.938895583152771\tacc 0.160000\n",
      "1051: \ttrain loss 1.9209455251693726\tacc 0.164286\tval loss 1.938651442527771\tacc 0.160000\n",
      "1052: \ttrain loss 1.9209468364715576\tacc 0.164286\tval loss 1.939073920249939\tacc 0.156000\n",
      "1053: \ttrain loss 1.9209424257278442\tacc 0.171429\tval loss 1.9386203289031982\tacc 0.168000\n",
      "1054: \ttrain loss 1.9209465980529785\tacc 0.150000\tval loss 1.9389675855636597\tacc 0.162000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1055: \ttrain loss 1.9209413528442383\tacc 0.178571\tval loss 1.9388056993484497\tacc 0.160000\n",
      "1056: \ttrain loss 1.9209474325180054\tacc 0.171429\tval loss 1.9387760162353516\tacc 0.160000\n",
      "1057: \ttrain loss 1.9209418296813965\tacc 0.164286\tval loss 1.9389350414276123\tacc 0.158000\n",
      "1058: \ttrain loss 1.9209470748901367\tacc 0.164286\tval loss 1.9387476444244385\tacc 0.162000\n",
      "1059: \ttrain loss 1.9209411144256592\tacc 0.164286\tval loss 1.9388610124588013\tacc 0.162000\n",
      "1060: \ttrain loss 1.9209450483322144\tacc 0.157143\tval loss 1.93888258934021\tacc 0.158000\n",
      "1061: \ttrain loss 1.9209415912628174\tacc 0.150000\tval loss 1.9387258291244507\tacc 0.160000\n",
      "1062: \ttrain loss 1.9209448099136353\tacc 0.164286\tval loss 1.9389628171920776\tacc 0.158000\n",
      "1063: \ttrain loss 1.9209424257278442\tacc 0.164286\tval loss 1.9387319087982178\tacc 0.160000\n",
      "1064: \ttrain loss 1.9209439754486084\tacc 0.164286\tval loss 1.938878059387207\tacc 0.162000\n",
      "1065: \ttrain loss 1.9209415912628174\tacc 0.150000\tval loss 1.9388560056686401\tacc 0.164000\n",
      "1066: \ttrain loss 1.9209433794021606\tacc 0.157143\tval loss 1.9387681484222412\tacc 0.162000\n",
      "1067: \ttrain loss 1.9209409952163696\tacc 0.157143\tval loss 1.9389084577560425\tacc 0.158000\n",
      "1068: \ttrain loss 1.9209439754486084\tacc 0.150000\tval loss 1.9387916326522827\tacc 0.160000\n",
      "1069: \ttrain loss 1.9209409952163696\tacc 0.164286\tval loss 1.9388248920440674\tacc 0.160000\n",
      "1070: \ttrain loss 1.9209437370300293\tacc 0.150000\tval loss 1.9389015436172485\tacc 0.162000\n",
      "1071: \ttrain loss 1.9209402799606323\tacc 0.164286\tval loss 1.9387307167053223\tacc 0.162000\n",
      "1072: \ttrain loss 1.9209431409835815\tacc 0.150000\tval loss 1.9389482736587524\tacc 0.162000\n",
      "1073: \ttrain loss 1.9209398031234741\tacc 0.150000\tval loss 1.9387441873550415\tacc 0.162000\n",
      "1074: \ttrain loss 1.9209433794021606\tacc 0.157143\tval loss 1.93888521194458\tacc 0.158000\n",
      "1075: \ttrain loss 1.9209400415420532\tacc 0.150000\tval loss 1.9388319253921509\tacc 0.162000\n",
      "1076: \ttrain loss 1.9209436178207397\tacc 0.164286\tval loss 1.938804268836975\tacc 0.162000\n",
      "1077: \ttrain loss 1.9209392070770264\tacc 0.150000\tval loss 1.938878059387207\tacc 0.166000\n",
      "1078: \ttrain loss 1.9209442138671875\tacc 0.164286\tval loss 1.9388092756271362\tacc 0.162000\n",
      "1079: \ttrain loss 1.9209378957748413\tacc 0.157143\tval loss 1.9388195276260376\tacc 0.164000\n",
      "1080: \ttrain loss 1.9209452867507935\tacc 0.150000\tval loss 1.938907504081726\tacc 0.162000\n",
      "1081: \ttrain loss 1.920936107635498\tacc 0.164286\tval loss 1.9387035369873047\tacc 0.164000\n",
      "1082: \ttrain loss 1.9209474325180054\tacc 0.150000\tval loss 1.9390158653259277\tacc 0.162000\n",
      "1083: \ttrain loss 1.920933723449707\tacc 0.164286\tval loss 1.9386214017868042\tacc 0.164000\n",
      "1084: \ttrain loss 1.9209502935409546\tacc 0.150000\tval loss 1.939064621925354\tacc 0.164000\n",
      "1085: \ttrain loss 1.9209308624267578\tacc 0.164286\tval loss 1.938599705696106\tacc 0.164000\n",
      "1086: \ttrain loss 1.920954942703247\tacc 0.157143\tval loss 1.9390785694122314\tacc 0.162000\n",
      "1087: \ttrain loss 1.9209258556365967\tacc 0.157143\tval loss 1.9385693073272705\tacc 0.164000\n",
      "1088: \ttrain loss 1.9209623336791992\tacc 0.178571\tval loss 1.939154028892517\tacc 0.162000\n",
      "1089: \ttrain loss 1.9209187030792236\tacc 0.157143\tval loss 1.938433051109314\tacc 0.162000\n",
      "1090: \ttrain loss 1.9209758043289185\tacc 0.178571\tval loss 1.9393720626831055\tacc 0.162000\n",
      "1091: \ttrain loss 1.9209084510803223\tacc 0.157143\tval loss 1.9381390810012817\tacc 0.160000\n",
      "1092: \ttrain loss 1.9209978580474854\tacc 0.178571\tval loss 1.9397590160369873\tacc 0.166000\n",
      "1093: \ttrain loss 1.9208952188491821\tacc 0.150000\tval loss 1.9376927614212036\tacc 0.162000\n",
      "1094: \ttrain loss 1.9210355281829834\tacc 0.178571\tval loss 1.9402894973754883\tacc 0.164000\n",
      "1095: \ttrain loss 1.9208827018737793\tacc 0.164286\tval loss 1.9371625185012817\tacc 0.166000\n",
      "1096: \ttrain loss 1.9210889339447021\tacc 0.171429\tval loss 1.9408262968063354\tacc 0.160000\n",
      "1097: \ttrain loss 1.9208773374557495\tacc 0.142857\tval loss 1.936788558959961\tacc 0.168000\n",
      "1098: \ttrain loss 1.9211251735687256\tacc 0.171429\tval loss 1.940940022468567\tacc 0.160000\n",
      "1099: \ttrain loss 1.9208799600601196\tacc 0.142857\tval loss 1.9370758533477783\tacc 0.166000\n",
      "1100: \ttrain loss 1.921077013015747\tacc 0.171429\tval loss 1.9401147365570068\tacc 0.160000\n",
      "1101: \ttrain loss 1.9209012985229492\tacc 0.142857\tval loss 1.9383037090301514\tacc 0.162000\n",
      "1102: \ttrain loss 1.920969009399414\tacc 0.157143\tval loss 1.938594102859497\tacc 0.164000\n",
      "1103: \ttrain loss 1.9209738969802856\tacc 0.157143\tval loss 1.9398213624954224\tacc 0.164000\n",
      "1104: \ttrain loss 1.9209063053131104\tacc 0.150000\tval loss 1.937391996383667\tacc 0.168000\n",
      "1105: \ttrain loss 1.921048641204834\tacc 0.171429\tval loss 1.9404990673065186\tacc 0.160000\n",
      "1106: \ttrain loss 1.9208976030349731\tacc 0.142857\tval loss 1.937424898147583\tacc 0.164000\n",
      "1107: \ttrain loss 1.9210333824157715\tacc 0.178571\tval loss 1.939741611480713\tacc 0.162000\n",
      "1108: \ttrain loss 1.9209219217300415\tacc 0.150000\tval loss 1.9386531114578247\tacc 0.164000\n",
      "1109: \ttrain loss 1.9209612607955933\tacc 0.157143\tval loss 1.9383654594421387\tacc 0.162000\n",
      "1110: \ttrain loss 1.9209741353988647\tacc 0.150000\tval loss 1.939791202545166\tacc 0.162000\n",
      "1111: \ttrain loss 1.920920729637146\tacc 0.150000\tval loss 1.9377238750457764\tacc 0.166000\n",
      "1112: \ttrain loss 1.9210124015808105\tacc 0.164286\tval loss 1.939850091934204\tacc 0.160000\n",
      "1113: \ttrain loss 1.9209147691726685\tacc 0.150000\tval loss 1.9381742477416992\tacc 0.162000\n",
      "1114: \ttrain loss 1.9209918975830078\tacc 0.164286\tval loss 1.9390524625778198\tacc 0.162000\n",
      "1115: \ttrain loss 1.9209389686584473\tacc 0.157143\tval loss 1.9390631914138794\tacc 0.164000\n",
      "1116: \ttrain loss 1.9209460020065308\tacc 0.157143\tval loss 1.9382671117782593\tacc 0.160000\n",
      "1117: \ttrain loss 1.9209778308868408\tacc 0.157143\tval loss 1.9395710229873657\tacc 0.160000\n",
      "1118: \ttrain loss 1.9209215641021729\tacc 0.150000\tval loss 1.938130259513855\tacc 0.162000\n",
      "1119: \ttrain loss 1.920990228652954\tacc 0.178571\tval loss 1.9393433332443237\tacc 0.160000\n",
      "1120: \ttrain loss 1.920924425125122\tacc 0.150000\tval loss 1.9386122226715088\tacc 0.166000\n",
      "1121: \ttrain loss 1.920965313911438\tacc 0.157143\tval loss 1.9387565851211548\tacc 0.166000\n",
      "1122: \ttrain loss 1.9209476709365845\tacc 0.157143\tval loss 1.9391323328018188\tacc 0.162000\n",
      "1123: \ttrain loss 1.9209352731704712\tacc 0.157143\tval loss 1.9384098052978516\tacc 0.164000\n",
      "1124: \ttrain loss 1.9209718704223633\tacc 0.157143\tval loss 1.939274549484253\tacc 0.160000\n",
      "1125: \ttrain loss 1.9209232330322266\tacc 0.150000\tval loss 1.938452124595642\tacc 0.162000\n",
      "1126: \ttrain loss 1.9209710359573364\tacc 0.164286\tval loss 1.9391018152236938\tacc 0.164000\n",
      "1127: \ttrain loss 1.9209297895431519\tacc 0.157143\tval loss 1.938711404800415\tacc 0.164000\n",
      "1128: \ttrain loss 1.920951008796692\tacc 0.157143\tval loss 1.9388000965118408\tacc 0.164000\n",
      "1129: \ttrain loss 1.9209489822387695\tacc 0.157143\tval loss 1.9390136003494263\tacc 0.162000\n",
      "1130: \ttrain loss 1.9209321737289429\tacc 0.157143\tval loss 1.938552975654602\tacc 0.160000\n",
      "1131: \ttrain loss 1.920961618423462\tacc 0.157143\tval loss 1.9391683340072632\tacc 0.162000\n",
      "1132: \ttrain loss 1.9209271669387817\tacc 0.157143\tval loss 1.9385254383087158\tacc 0.164000\n",
      "1133: \ttrain loss 1.9209588766098022\tacc 0.157143\tval loss 1.9390679597854614\tacc 0.164000\n",
      "1134: \ttrain loss 1.920933485031128\tacc 0.157143\tval loss 1.9387311935424805\tacc 0.166000\n",
      "1135: \ttrain loss 1.9209450483322144\tacc 0.157143\tval loss 1.9388084411621094\tacc 0.164000\n",
      "1136: \ttrain loss 1.9209460020065308\tacc 0.157143\tval loss 1.938989281654358\tacc 0.162000\n",
      "1137: \ttrain loss 1.920933485031128\tacc 0.157143\tval loss 1.9386048316955566\tacc 0.164000\n",
      "1138: \ttrain loss 1.9209537506103516\tacc 0.157143\tval loss 1.9391013383865356\tacc 0.162000\n",
      "1139: \ttrain loss 1.92093026638031\tacc 0.157143\tval loss 1.9386025667190552\tacc 0.166000\n",
      "1140: \ttrain loss 1.9209516048431396\tacc 0.157143\tval loss 1.938999056816101\tacc 0.164000\n",
      "1141: \ttrain loss 1.920934796333313\tacc 0.164286\tval loss 1.9387753009796143\tacc 0.166000\n",
      "1142: \ttrain loss 1.9209436178207397\tacc 0.157143\tval loss 1.9387969970703125\tacc 0.164000\n",
      "1143: \ttrain loss 1.9209429025650024\tacc 0.157143\tval loss 1.9389581680297852\tacc 0.162000\n",
      "1144: \ttrain loss 1.920935034751892\tacc 0.157143\tval loss 1.9386658668518066\tacc 0.164000\n",
      "1145: \ttrain loss 1.9209489822387695\tacc 0.157143\tval loss 1.9390164613723755\tacc 0.160000\n",
      "1146: \ttrain loss 1.9209320545196533\tacc 0.157143\tval loss 1.93867826461792\tacc 0.166000\n",
      "1147: \ttrain loss 1.9209481477737427\tacc 0.157143\tval loss 1.93894362449646\tacc 0.166000\n",
      "1148: \ttrain loss 1.920934796333313\tacc 0.164286\tval loss 1.9387867450714111\tacc 0.166000\n",
      "1149: \ttrain loss 1.9209433794021606\tacc 0.157143\tval loss 1.9388231039047241\tacc 0.164000\n",
      "1150: \ttrain loss 1.9209400415420532\tacc 0.157143\tval loss 1.9388896226882935\tacc 0.162000\n",
      "1151: \ttrain loss 1.9209381341934204\tacc 0.150000\tval loss 1.9387527704238892\tacc 0.166000\n",
      "1152: \ttrain loss 1.9209446907043457\tacc 0.157143\tval loss 1.9389221668243408\tacc 0.162000\n",
      "1153: \ttrain loss 1.9209352731704712\tacc 0.157143\tval loss 1.9387507438659668\tacc 0.166000\n",
      "1154: \ttrain loss 1.9209460020065308\tacc 0.157143\tval loss 1.938904881477356\tacc 0.164000\n",
      "1155: \ttrain loss 1.9209355115890503\tacc 0.157143\tval loss 1.9387775659561157\tacc 0.166000\n",
      "1156: \ttrain loss 1.9209442138671875\tacc 0.157143\tval loss 1.9388705492019653\tacc 0.164000\n",
      "1157: \ttrain loss 1.9209389686584473\tacc 0.157143\tval loss 1.9388206005096436\tacc 0.164000\n",
      "1158: \ttrain loss 1.9209402799606323\tacc 0.157143\tval loss 1.9388184547424316\tacc 0.164000\n",
      "1159: \ttrain loss 1.9209424257278442\tacc 0.157143\tval loss 1.9388760328292847\tacc 0.166000\n",
      "1160: \ttrain loss 1.920937418937683\tacc 0.150000\tval loss 1.9387730360031128\tacc 0.164000\n",
      "1161: \ttrain loss 1.9209446907043457\tacc 0.157143\tval loss 1.938901662826538\tacc 0.166000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1162: \ttrain loss 1.920937180519104\tacc 0.157143\tval loss 1.9387725591659546\tacc 0.164000\n",
      "1163: \ttrain loss 1.9209442138671875\tacc 0.157143\tval loss 1.938881516456604\tacc 0.164000\n",
      "1164: \ttrain loss 1.9209383726119995\tacc 0.150000\tval loss 1.9388030767440796\tacc 0.164000\n",
      "1165: \ttrain loss 1.9209424257278442\tacc 0.157143\tval loss 1.9388513565063477\tacc 0.164000\n",
      "1166: \ttrain loss 1.9209398031234741\tacc 0.157143\tval loss 1.938829779624939\tacc 0.164000\n",
      "1167: \ttrain loss 1.9209407567977905\tacc 0.157143\tval loss 1.9388278722763062\tacc 0.164000\n",
      "1168: \ttrain loss 1.9209415912628174\tacc 0.157143\tval loss 1.9388543367385864\tacc 0.164000\n",
      "1169: \ttrain loss 1.9209396839141846\tacc 0.150000\tval loss 1.9388024806976318\tacc 0.164000\n",
      "1170: \ttrain loss 1.9209429025650024\tacc 0.157143\tval loss 1.9388760328292847\tacc 0.166000\n",
      "1171: \ttrain loss 1.920938491821289\tacc 0.150000\tval loss 1.9387925863265991\tacc 0.164000\n",
      "1172: \ttrain loss 1.9209429025650024\tacc 0.157143\tval loss 1.938871145248413\tacc 0.164000\n",
      "1173: \ttrain loss 1.9209392070770264\tacc 0.150000\tval loss 1.9388117790222168\tacc 0.164000\n",
      "1174: \ttrain loss 1.9209424257278442\tacc 0.157143\tval loss 1.9388434886932373\tacc 0.164000\n",
      "1175: \ttrain loss 1.9209402799606323\tacc 0.157143\tval loss 1.938839077949524\tacc 0.164000\n",
      "1176: \ttrain loss 1.9209411144256592\tacc 0.157143\tval loss 1.9388216733932495\tacc 0.164000\n",
      "1177: \ttrain loss 1.9209415912628174\tacc 0.157143\tval loss 1.9388525485992432\tacc 0.164000\n",
      "1178: \ttrain loss 1.9209400415420532\tacc 0.157143\tval loss 1.9388164281845093\tacc 0.164000\n",
      "1179: \ttrain loss 1.9209423065185547\tacc 0.157143\tval loss 1.9388518333435059\tacc 0.164000\n",
      "1180: \ttrain loss 1.9209400415420532\tacc 0.157143\tval loss 1.9388200044631958\tacc 0.164000\n",
      "1181: \ttrain loss 1.9209423065185547\tacc 0.157143\tval loss 1.9388469457626343\tacc 0.164000\n",
      "1182: \ttrain loss 1.9209400415420532\tacc 0.157143\tval loss 1.93882417678833\tacc 0.164000\n",
      "1183: \ttrain loss 1.9209420680999756\tacc 0.157143\tval loss 1.938844084739685\tacc 0.164000\n",
      "1184: \ttrain loss 1.9209407567977905\tacc 0.157143\tval loss 1.9388257265090942\tacc 0.164000\n",
      "1185: \ttrain loss 1.9209420680999756\tacc 0.157143\tval loss 1.9388436079025269\tacc 0.164000\n",
      "1186: \ttrain loss 1.9209402799606323\tacc 0.157143\tval loss 1.938827633857727\tacc 0.164000\n",
      "1187: \ttrain loss 1.9209413528442383\tacc 0.157143\tval loss 1.9388375282287598\tacc 0.164000\n",
      "1188: \ttrain loss 1.9209409952163696\tacc 0.157143\tval loss 1.9388376474380493\tacc 0.164000\n",
      "1189: \ttrain loss 1.9209411144256592\tacc 0.157143\tval loss 1.9388256072998047\tacc 0.164000\n",
      "1190: \ttrain loss 1.9209418296813965\tacc 0.157143\tval loss 1.938848853111267\tacc 0.164000\n",
      "1191: \ttrain loss 1.9209402799606323\tacc 0.157143\tval loss 1.9388184547424316\tacc 0.164000\n",
      "1192: \ttrain loss 1.9209420680999756\tacc 0.157143\tval loss 1.938851237297058\tacc 0.164000\n",
      "1193: \ttrain loss 1.9209405183792114\tacc 0.157143\tval loss 1.9388209581375122\tacc 0.164000\n",
      "1194: \ttrain loss 1.9209420680999756\tacc 0.157143\tval loss 1.938844919204712\tacc 0.164000\n",
      "1195: \ttrain loss 1.9209409952163696\tacc 0.157143\tval loss 1.938827395439148\tacc 0.164000\n",
      "1196: \ttrain loss 1.9209413528442383\tacc 0.157143\tval loss 1.9388397932052612\tacc 0.164000\n",
      "1197: \ttrain loss 1.9209409952163696\tacc 0.157143\tval loss 1.9388304948806763\tacc 0.164000\n",
      "1198: \ttrain loss 1.9209413528442383\tacc 0.157143\tval loss 1.9388405084609985\tacc 0.164000\n",
      "1199: \ttrain loss 1.9209407567977905\tacc 0.157143\tval loss 1.9388272762298584\tacc 0.164000\n",
      "1200: \ttrain loss 1.9209418296813965\tacc 0.157143\tval loss 1.9388450384140015\tacc 0.164000\n",
      "1201: \ttrain loss 1.9209402799606323\tacc 0.157143\tval loss 1.9388213157653809\tacc 0.164000\n",
      "1202: \ttrain loss 1.9209415912628174\tacc 0.157143\tval loss 1.9388513565063477\tacc 0.164000\n",
      "1203: \ttrain loss 1.9209405183792114\tacc 0.157143\tval loss 1.9388163089752197\tacc 0.164000\n",
      "1204: \ttrain loss 1.9209423065185547\tacc 0.157143\tval loss 1.9388543367385864\tacc 0.164000\n",
      "1205: \ttrain loss 1.9209400415420532\tacc 0.157143\tval loss 1.9388145208358765\tacc 0.164000\n",
      "1206: \ttrain loss 1.9209420680999756\tacc 0.157143\tval loss 1.9388561248779297\tacc 0.164000\n",
      "1207: \ttrain loss 1.9209402799606323\tacc 0.157143\tval loss 1.9388110637664795\tacc 0.164000\n",
      "1208: \ttrain loss 1.9209424257278442\tacc 0.157143\tval loss 1.9388606548309326\tacc 0.164000\n",
      "1209: \ttrain loss 1.9209400415420532\tacc 0.157143\tval loss 1.938808798789978\tacc 0.164000\n",
      "1210: \ttrain loss 1.9209423065185547\tacc 0.157143\tval loss 1.9388548135757446\tacc 0.164000\n",
      "1211: \ttrain loss 1.9209407567977905\tacc 0.157143\tval loss 1.9388269186019897\tacc 0.164000\n",
      "1212: \ttrain loss 1.9209405183792114\tacc 0.157143\tval loss 1.9388254880905151\tacc 0.164000\n",
      "1213: \ttrain loss 1.9209423065185547\tacc 0.157143\tval loss 1.9388614892959595\tacc 0.164000\n",
      "1214: \ttrain loss 1.9209394454956055\tacc 0.157143\tval loss 1.9387959241867065\tacc 0.164000\n",
      "1215: \ttrain loss 1.9209431409835815\tacc 0.157143\tval loss 1.9388766288757324\tacc 0.164000\n",
      "1216: \ttrain loss 1.9209389686584473\tacc 0.150000\tval loss 1.9387962818145752\tacc 0.164000\n",
      "1217: \ttrain loss 1.9209429025650024\tacc 0.157143\tval loss 1.938867449760437\tacc 0.166000\n",
      "1218: \ttrain loss 1.9209392070770264\tacc 0.150000\tval loss 1.9388034343719482\tacc 0.164000\n",
      "1219: \ttrain loss 1.9209433794021606\tacc 0.157143\tval loss 1.9388726949691772\tacc 0.162000\n",
      "1220: \ttrain loss 1.9209378957748413\tacc 0.150000\tval loss 1.9387837648391724\tacc 0.164000\n",
      "1221: \ttrain loss 1.9209446907043457\tacc 0.157143\tval loss 1.9388991594314575\tacc 0.162000\n",
      "1222: \ttrain loss 1.9209370613098145\tacc 0.150000\tval loss 1.9387630224227905\tacc 0.164000\n",
      "1223: \ttrain loss 1.9209450483322144\tacc 0.157143\tval loss 1.9389044046401978\tacc 0.162000\n",
      "1224: \ttrain loss 1.920937418937683\tacc 0.150000\tval loss 1.9387739896774292\tacc 0.164000\n",
      "1225: \ttrain loss 1.9209455251693726\tacc 0.157143\tval loss 1.938884973526001\tacc 0.162000\n",
      "1226: \ttrain loss 1.9209365844726562\tacc 0.150000\tval loss 1.9387890100479126\tacc 0.162000\n",
      "1227: \ttrain loss 1.9209465980529785\tacc 0.164286\tval loss 1.9388850927352905\tacc 0.162000\n",
      "1228: \ttrain loss 1.9209352731704712\tacc 0.150000\tval loss 1.9387964010238647\tacc 0.166000\n",
      "1229: \ttrain loss 1.9209479093551636\tacc 0.164286\tval loss 1.9387966394424438\tacc 0.158000\n",
      "1230: \ttrain loss 1.9209439754486084\tacc 0.157143\tval loss 1.9390134811401367\tacc 0.164000\n",
      "1231: \ttrain loss 1.9209320545196533\tacc 0.178571\tval loss 1.9384530782699585\tacc 0.160000\n",
      "1232: \ttrain loss 1.92095947265625\tacc 0.150000\tval loss 1.939480185508728\tacc 0.160000\n",
      "1233: \ttrain loss 1.9209221601486206\tacc 0.178571\tval loss 1.9379065036773682\tacc 0.162000\n",
      "1234: \ttrain loss 1.9209784269332886\tacc 0.164286\tval loss 1.9401068687438965\tacc 0.166000\n",
      "1235: \ttrain loss 1.9209115505218506\tacc 0.185714\tval loss 1.9371670484542847\tacc 0.162000\n",
      "1236: \ttrain loss 1.9210333824157715\tacc 0.171429\tval loss 1.9410430192947388\tacc 0.162000\n",
      "1237: \ttrain loss 1.9208914041519165\tacc 0.185714\tval loss 1.9361793994903564\tacc 0.170000\n",
      "1238: \ttrain loss 1.9211397171020508\tacc 0.185714\tval loss 1.9419844150543213\tacc 0.158000\n",
      "1239: \ttrain loss 1.9208879470825195\tacc 0.178571\tval loss 1.9358543157577515\tacc 0.168000\n",
      "1240: \ttrain loss 1.9212151765823364\tacc 0.171429\tval loss 1.9414129257202148\tacc 0.162000\n",
      "1241: \ttrain loss 1.9208827018737793\tacc 0.164286\tval loss 1.9374011754989624\tacc 0.168000\n",
      "1242: \ttrain loss 1.9210928678512573\tacc 0.185714\tval loss 1.9392908811569214\tacc 0.158000\n",
      "1243: \ttrain loss 1.9209315776824951\tacc 0.157143\tval loss 1.9390456676483154\tacc 0.160000\n",
      "1244: \ttrain loss 1.9209762811660767\tacc 0.192857\tval loss 1.9384417533874512\tacc 0.156000\n",
      "1245: \ttrain loss 1.9210199117660522\tacc 0.164286\tval loss 1.9393330812454224\tacc 0.166000\n",
      "1246: \ttrain loss 1.9209169149398804\tacc 0.171429\tval loss 1.9382392168045044\tacc 0.162000\n",
      "1247: \ttrain loss 1.9210652112960815\tacc 0.164286\tval loss 1.9398654699325562\tacc 0.160000\n",
      "1248: \ttrain loss 1.9209076166152954\tacc 0.150000\tval loss 1.9375436305999756\tacc 0.176000\n",
      "1249: \ttrain loss 1.9210370779037476\tacc 0.164286\tval loss 1.9400132894515991\tacc 0.156000\n",
      "1250: \ttrain loss 1.9209638833999634\tacc 0.157143\tval loss 1.938476324081421\tacc 0.162000\n",
      "1251: \ttrain loss 1.920951247215271\tacc 0.185714\tval loss 1.9381366968154907\tacc 0.172000\n",
      "1252: \ttrain loss 1.9210071563720703\tacc 0.164286\tval loss 1.9403822422027588\tacc 0.160000\n",
      "1253: \ttrain loss 1.920930027961731\tacc 0.157143\tval loss 1.9372444152832031\tacc 0.162000\n",
      "1254: \ttrain loss 1.9210363626480103\tacc 0.171429\tval loss 1.939760446548462\tacc 0.160000\n",
      "1255: \ttrain loss 1.9209363460540771\tacc 0.157143\tval loss 1.9388726949691772\tacc 0.156000\n",
      "1256: \ttrain loss 1.920996069908142\tacc 0.178571\tval loss 1.9382150173187256\tacc 0.172000\n",
      "1257: \ttrain loss 1.9209516048431396\tacc 0.164286\tval loss 1.9393970966339111\tacc 0.158000\n",
      "1258: \ttrain loss 1.9209710359573364\tacc 0.157143\tval loss 1.9388033151626587\tacc 0.158000\n",
      "1259: \ttrain loss 1.9209728240966797\tacc 0.178571\tval loss 1.9383245706558228\tacc 0.170000\n",
      "1260: \ttrain loss 1.9209483861923218\tacc 0.142857\tval loss 1.939477801322937\tacc 0.154000\n",
      "1261: \ttrain loss 1.9209703207015991\tacc 0.171429\tval loss 1.9385448694229126\tacc 0.162000\n",
      "1262: \ttrain loss 1.9209586381912231\tacc 0.164286\tval loss 1.9385111331939697\tacc 0.164000\n",
      "1263: \ttrain loss 1.920958161354065\tacc 0.142857\tval loss 1.9395781755447388\tacc 0.160000\n",
      "1264: \ttrain loss 1.920952320098877\tacc 0.164286\tval loss 1.938132882118225\tacc 0.164000\n",
      "1265: \ttrain loss 1.920958399772644\tacc 0.150000\tval loss 1.9390521049499512\tacc 0.156000\n",
      "1266: \ttrain loss 1.9209518432617188\tacc 0.164286\tval loss 1.9392133951187134\tacc 0.156000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1267: \ttrain loss 1.9209492206573486\tacc 0.171429\tval loss 1.9380812644958496\tacc 0.164000\n",
      "1268: \ttrain loss 1.920958161354065\tacc 0.157143\tval loss 1.9395020008087158\tacc 0.158000\n",
      "1269: \ttrain loss 1.9209424257278442\tacc 0.157143\tval loss 1.938616156578064\tacc 0.164000\n",
      "1270: \ttrain loss 1.920953631401062\tacc 0.157143\tval loss 1.9385416507720947\tacc 0.164000\n",
      "1271: \ttrain loss 1.9209418296813965\tacc 0.150000\tval loss 1.9394012689590454\tacc 0.158000\n",
      "1272: \ttrain loss 1.9209489822387695\tacc 0.171429\tval loss 1.9383716583251953\tacc 0.178000\n",
      "1273: \ttrain loss 1.9209479093551636\tacc 0.150000\tval loss 1.9389421939849854\tacc 0.166000\n",
      "1274: \ttrain loss 1.9209383726119995\tacc 0.157143\tval loss 1.9391025304794312\tacc 0.160000\n",
      "1275: \ttrain loss 1.9209487438201904\tacc 0.171429\tval loss 1.9384411573410034\tacc 0.178000\n",
      "1276: \ttrain loss 1.9209398031234741\tacc 0.150000\tval loss 1.939096212387085\tacc 0.160000\n",
      "1277: \ttrain loss 1.9209455251693726\tacc 0.171429\tval loss 1.9388703107833862\tacc 0.162000\n",
      "1278: \ttrain loss 1.9209402799606323\tacc 0.150000\tval loss 1.9385782480239868\tacc 0.168000\n",
      "1279: \ttrain loss 1.9209402799606323\tacc 0.157143\tval loss 1.9391427040100098\tacc 0.160000\n",
      "1280: \ttrain loss 1.9209442138671875\tacc 0.171429\tval loss 1.938684105873108\tacc 0.164000\n",
      "1281: \ttrain loss 1.9209368228912354\tacc 0.150000\tval loss 1.9387717247009277\tacc 0.162000\n",
      "1282: \ttrain loss 1.9209431409835815\tacc 0.164286\tval loss 1.9390653371810913\tacc 0.160000\n",
      "1283: \ttrain loss 1.9209394454956055\tacc 0.142857\tval loss 1.938594937324524\tacc 0.166000\n",
      "1284: \ttrain loss 1.9209392070770264\tacc 0.150000\tval loss 1.938958764076233\tacc 0.160000\n",
      "1285: \ttrain loss 1.9209411144256592\tacc 0.178571\tval loss 1.938891887664795\tacc 0.160000\n",
      "1286: \ttrain loss 1.9209365844726562\tacc 0.150000\tval loss 1.938646674156189\tacc 0.164000\n",
      "1287: \ttrain loss 1.9209423065185547\tacc 0.157143\tval loss 1.9390493631362915\tacc 0.160000\n",
      "1288: \ttrain loss 1.920937180519104\tacc 0.164286\tval loss 1.9387062788009644\tacc 0.164000\n",
      "1289: \ttrain loss 1.9209405183792114\tacc 0.150000\tval loss 1.9388222694396973\tacc 0.160000\n",
      "1290: \ttrain loss 1.9209396839141846\tacc 0.164286\tval loss 1.9389625787734985\tacc 0.158000\n",
      "1291: \ttrain loss 1.9209381341934204\tacc 0.150000\tval loss 1.938671588897705\tacc 0.166000\n",
      "1292: \ttrain loss 1.9209411144256592\tacc 0.157143\tval loss 1.9389395713806152\tacc 0.160000\n",
      "1293: \ttrain loss 1.920937180519104\tacc 0.164286\tval loss 1.93882417678833\tacc 0.160000\n",
      "1294: \ttrain loss 1.9209418296813965\tacc 0.150000\tval loss 1.9387654066085815\tacc 0.164000\n",
      "1295: \ttrain loss 1.9209381341934204\tacc 0.157143\tval loss 1.938912034034729\tacc 0.164000\n",
      "1296: \ttrain loss 1.9209398031234741\tacc 0.157143\tval loss 1.9387986660003662\tacc 0.164000\n",
      "1297: \ttrain loss 1.9209405183792114\tacc 0.150000\tval loss 1.93881094455719\tacc 0.164000\n",
      "1298: \ttrain loss 1.9209383726119995\tacc 0.164286\tval loss 1.9388734102249146\tacc 0.160000\n",
      "1299: \ttrain loss 1.9209415912628174\tacc 0.150000\tval loss 1.938823938369751\tacc 0.164000\n",
      "1300: \ttrain loss 1.920938491821289\tacc 0.157143\tval loss 1.9387911558151245\tacc 0.164000\n",
      "1301: \ttrain loss 1.9209407567977905\tacc 0.157143\tval loss 1.9388988018035889\tacc 0.160000\n",
      "1302: \ttrain loss 1.9209405183792114\tacc 0.150000\tval loss 1.9387987852096558\tacc 0.164000\n",
      "1303: \ttrain loss 1.9209398031234741\tacc 0.157143\tval loss 1.9387961626052856\tacc 0.164000\n",
      "1304: \ttrain loss 1.9209429025650024\tacc 0.150000\tval loss 1.93894362449646\tacc 0.164000\n",
      "1305: \ttrain loss 1.920937418937683\tacc 0.164286\tval loss 1.9386950731277466\tacc 0.164000\n",
      "1306: \ttrain loss 1.9209465980529785\tacc 0.157143\tval loss 1.9389305114746094\tacc 0.162000\n",
      "1307: \ttrain loss 1.920938491821289\tacc 0.150000\tval loss 1.9388065338134766\tacc 0.164000\n",
      "1308: \ttrain loss 1.9209439754486084\tacc 0.157143\tval loss 1.9388093948364258\tacc 0.166000\n",
      "1309: \ttrain loss 1.9209376573562622\tacc 0.157143\tval loss 1.938875436782837\tacc 0.164000\n",
      "1310: \ttrain loss 1.9209433794021606\tacc 0.150000\tval loss 1.938818335533142\tacc 0.164000\n",
      "1311: \ttrain loss 1.9209405183792114\tacc 0.157143\tval loss 1.9388245344161987\tacc 0.164000\n",
      "1312: \ttrain loss 1.9209389686584473\tacc 0.150000\tval loss 1.9388383626937866\tacc 0.162000\n",
      "1313: \ttrain loss 1.9209465980529785\tacc 0.157143\tval loss 1.9388821125030518\tacc 0.164000\n",
      "1314: \ttrain loss 1.9209339618682861\tacc 0.164286\tval loss 1.9387236833572388\tacc 0.166000\n",
      "1315: \ttrain loss 1.9209487438201904\tacc 0.150000\tval loss 1.938999891281128\tacc 0.164000\n",
      "1316: \ttrain loss 1.9209344387054443\tacc 0.164286\tval loss 1.9386529922485352\tacc 0.166000\n",
      "1317: \ttrain loss 1.9209500551223755\tacc 0.164286\tval loss 1.938984751701355\tacc 0.162000\n",
      "1318: \ttrain loss 1.9209344387054443\tacc 0.164286\tval loss 1.938745379447937\tacc 0.164000\n",
      "1319: \ttrain loss 1.9209461212158203\tacc 0.157143\tval loss 1.9388660192489624\tacc 0.164000\n",
      "1320: \ttrain loss 1.9209383726119995\tacc 0.157143\tval loss 1.9388564825057983\tacc 0.164000\n",
      "1321: \ttrain loss 1.9209420680999756\tacc 0.157143\tval loss 1.9387773275375366\tacc 0.164000\n",
      "1322: \ttrain loss 1.9209429025650024\tacc 0.157143\tval loss 1.9389151334762573\tacc 0.164000\n",
      "1323: \ttrain loss 1.920937180519104\tacc 0.164286\tval loss 1.9387586116790771\tacc 0.166000\n",
      "1324: \ttrain loss 1.9209461212158203\tacc 0.157143\tval loss 1.9388737678527832\tacc 0.162000\n",
      "1325: \ttrain loss 1.9209398031234741\tacc 0.157143\tval loss 1.938852071762085\tacc 0.166000\n",
      "1326: \ttrain loss 1.9209398031234741\tacc 0.157143\tval loss 1.9387648105621338\tacc 0.164000\n",
      "1327: \ttrain loss 1.9209444522857666\tacc 0.157143\tval loss 1.9389359951019287\tacc 0.164000\n",
      "1328: \ttrain loss 1.9209368228912354\tacc 0.164286\tval loss 1.9387366771697998\tacc 0.166000\n",
      "1329: \ttrain loss 1.9209460020065308\tacc 0.157143\tval loss 1.9389067888259888\tacc 0.164000\n",
      "1330: \ttrain loss 1.9209368228912354\tacc 0.164286\tval loss 1.9387922286987305\tacc 0.162000\n",
      "1331: \ttrain loss 1.9209463596343994\tacc 0.157143\tval loss 1.9388625621795654\tacc 0.164000\n",
      "1332: \ttrain loss 1.9209370613098145\tacc 0.157143\tval loss 1.9388048648834229\tacc 0.162000\n",
      "1333: \ttrain loss 1.9209439754486084\tacc 0.157143\tval loss 1.9388691186904907\tacc 0.164000\n",
      "1334: \ttrain loss 1.9209402799606323\tacc 0.157143\tval loss 1.9388121366500854\tacc 0.164000\n",
      "1335: \ttrain loss 1.9209402799606323\tacc 0.157143\tval loss 1.9388251304626465\tacc 0.160000\n",
      "1336: \ttrain loss 1.9209436178207397\tacc 0.157143\tval loss 1.938887357711792\tacc 0.164000\n",
      "1337: \ttrain loss 1.9209378957748413\tacc 0.157143\tval loss 1.9387456178665161\tacc 0.166000\n",
      "1338: \ttrain loss 1.9209460020065308\tacc 0.157143\tval loss 1.9389350414276123\tacc 0.166000\n",
      "1339: \ttrain loss 1.9209368228912354\tacc 0.164286\tval loss 1.9387507438659668\tacc 0.166000\n",
      "1340: \ttrain loss 1.9209452867507935\tacc 0.157143\tval loss 1.9388874769210815\tacc 0.164000\n",
      "1341: \ttrain loss 1.9209383726119995\tacc 0.164286\tval loss 1.9388151168823242\tacc 0.164000\n",
      "1342: \ttrain loss 1.9209429025650024\tacc 0.157143\tval loss 1.9388340711593628\tacc 0.166000\n",
      "1343: \ttrain loss 1.9209405183792114\tacc 0.157143\tval loss 1.9388344287872314\tacc 0.162000\n",
      "1344: \ttrain loss 1.9209429025650024\tacc 0.157143\tval loss 1.9388407468795776\tacc 0.164000\n",
      "1345: \ttrain loss 1.9209402799606323\tacc 0.157143\tval loss 1.9388257265090942\tacc 0.166000\n",
      "1346: \ttrain loss 1.9209407567977905\tacc 0.157143\tval loss 1.9388399124145508\tacc 0.162000\n",
      "1347: \ttrain loss 1.9209426641464233\tacc 0.157143\tval loss 1.938845157623291\tacc 0.164000\n",
      "1348: \ttrain loss 1.9209400415420532\tacc 0.157143\tval loss 1.9388036727905273\tacc 0.164000\n",
      "1349: \ttrain loss 1.9209426641464233\tacc 0.157143\tval loss 1.9388864040374756\tacc 0.166000\n",
      "1350: \ttrain loss 1.9209389686584473\tacc 0.164286\tval loss 1.9387634992599487\tacc 0.166000\n",
      "1351: \ttrain loss 1.9209455251693726\tacc 0.164286\tval loss 1.9389201402664185\tacc 0.164000\n",
      "1352: \ttrain loss 1.920935034751892\tacc 0.164286\tval loss 1.938742995262146\tacc 0.162000\n",
      "1353: \ttrain loss 1.9209474325180054\tacc 0.157143\tval loss 1.9389286041259766\tacc 0.164000\n",
      "1354: \ttrain loss 1.9209355115890503\tacc 0.164286\tval loss 1.9387482404708862\tacc 0.166000\n",
      "1355: \ttrain loss 1.9209461212158203\tacc 0.157143\tval loss 1.9389033317565918\tacc 0.166000\n",
      "1356: \ttrain loss 1.920937180519104\tacc 0.164286\tval loss 1.9387933015823364\tacc 0.166000\n",
      "1357: \ttrain loss 1.9209431409835815\tacc 0.157143\tval loss 1.9388463497161865\tacc 0.164000\n",
      "1358: \ttrain loss 1.9209405183792114\tacc 0.157143\tval loss 1.9388480186462402\tacc 0.166000\n",
      "1359: \ttrain loss 1.9209405183792114\tacc 0.157143\tval loss 1.9388036727905273\tacc 0.164000\n",
      "1360: \ttrain loss 1.9209426641464233\tacc 0.157143\tval loss 1.9388787746429443\tacc 0.164000\n",
      "1361: \ttrain loss 1.920938491821289\tacc 0.164286\tval loss 1.9387805461883545\tacc 0.166000\n",
      "1362: \ttrain loss 1.9209446907043457\tacc 0.157143\tval loss 1.9388957023620605\tacc 0.166000\n",
      "1363: \ttrain loss 1.9209376573562622\tacc 0.164286\tval loss 1.9387726783752441\tacc 0.166000\n",
      "1364: \ttrain loss 1.9209448099136353\tacc 0.157143\tval loss 1.938891887664795\tacc 0.164000\n",
      "1365: \ttrain loss 1.9209381341934204\tacc 0.164286\tval loss 1.9387885332107544\tacc 0.166000\n",
      "1366: \ttrain loss 1.9209433794021606\tacc 0.157143\tval loss 1.9388668537139893\tacc 0.164000\n",
      "1367: \ttrain loss 1.9209394454956055\tacc 0.157143\tval loss 1.938818335533142\tacc 0.164000\n",
      "1368: \ttrain loss 1.9209423065185547\tacc 0.157143\tval loss 1.9388362169265747\tacc 0.164000\n",
      "1369: \ttrain loss 1.9209407567977905\tacc 0.157143\tval loss 1.9388446807861328\tacc 0.164000\n",
      "1370: \ttrain loss 1.9209405183792114\tacc 0.157143\tval loss 1.938815951347351\tacc 0.164000\n",
      "1371: \ttrain loss 1.9209423065185547\tacc 0.157143\tval loss 1.9388580322265625\tacc 0.164000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1372: \ttrain loss 1.9209396839141846\tacc 0.157143\tval loss 1.9388090372085571\tacc 0.164000\n",
      "1373: \ttrain loss 1.9209424257278442\tacc 0.157143\tval loss 1.9388600587844849\tacc 0.164000\n",
      "1374: \ttrain loss 1.9209396839141846\tacc 0.157143\tval loss 1.9388110637664795\tacc 0.164000\n",
      "1375: \ttrain loss 1.9209426641464233\tacc 0.157143\tval loss 1.9388554096221924\tacc 0.164000\n",
      "1376: \ttrain loss 1.9209398031234741\tacc 0.157143\tval loss 1.9388169050216675\tacc 0.164000\n",
      "1377: \ttrain loss 1.9209424257278442\tacc 0.157143\tval loss 1.938849687576294\tacc 0.164000\n",
      "1378: \ttrain loss 1.9209405183792114\tacc 0.157143\tval loss 1.9388221502304077\tacc 0.164000\n",
      "1379: \ttrain loss 1.9209418296813965\tacc 0.157143\tval loss 1.938844084739685\tacc 0.164000\n",
      "1380: \ttrain loss 1.9209407567977905\tacc 0.157143\tval loss 1.9388303756713867\tacc 0.164000\n",
      "1381: \ttrain loss 1.9209415912628174\tacc 0.157143\tval loss 1.9388316869735718\tacc 0.164000\n",
      "1382: \ttrain loss 1.9209418296813965\tacc 0.157143\tval loss 1.9388459920883179\tacc 0.164000\n",
      "1383: \ttrain loss 1.9209405183792114\tacc 0.157143\tval loss 1.9388166666030884\tacc 0.164000\n",
      "1384: \ttrain loss 1.9209423065185547\tacc 0.157143\tval loss 1.9388582706451416\tacc 0.164000\n",
      "1385: \ttrain loss 1.9209400415420532\tacc 0.157143\tval loss 1.9388086795806885\tacc 0.164000\n",
      "1386: \ttrain loss 1.9209424257278442\tacc 0.157143\tval loss 1.9388608932495117\tacc 0.164000\n",
      "1387: \ttrain loss 1.9209398031234741\tacc 0.157143\tval loss 1.9388099908828735\tacc 0.164000\n",
      "1388: \ttrain loss 1.9209426641464233\tacc 0.157143\tval loss 1.9388573169708252\tacc 0.164000\n",
      "1389: \ttrain loss 1.9209398031234741\tacc 0.157143\tval loss 1.9388149976730347\tacc 0.164000\n",
      "1390: \ttrain loss 1.9209420680999756\tacc 0.157143\tval loss 1.9388513565063477\tacc 0.164000\n",
      "1391: \ttrain loss 1.9209405183792114\tacc 0.157143\tval loss 1.938820719718933\tacc 0.164000\n",
      "1392: \ttrain loss 1.9209423065185547\tacc 0.157143\tval loss 1.9388456344604492\tacc 0.164000\n",
      "1393: \ttrain loss 1.9209402799606323\tacc 0.157143\tval loss 1.9388269186019897\tacc 0.164000\n",
      "1394: \ttrain loss 1.9209418296813965\tacc 0.157143\tval loss 1.9388399124145508\tacc 0.164000\n",
      "1395: \ttrain loss 1.9209409952163696\tacc 0.157143\tval loss 1.9388316869735718\tacc 0.164000\n",
      "1396: \ttrain loss 1.9209411144256592\tacc 0.157143\tval loss 1.9388359785079956\tacc 0.164000\n",
      "1397: \ttrain loss 1.9209409952163696\tacc 0.157143\tval loss 1.9388347864151\tacc 0.164000\n",
      "1398: \ttrain loss 1.9209409952163696\tacc 0.157143\tval loss 1.9388326406478882\tacc 0.164000\n",
      "1399: \ttrain loss 1.9209413528442383\tacc 0.157143\tval loss 1.938838243484497\tacc 0.164000\n",
      "1400: \ttrain loss 1.9209411144256592\tacc 0.157143\tval loss 1.9388295412063599\tacc 0.164000\n",
      "1401: \ttrain loss 1.9209418296813965\tacc 0.157143\tval loss 1.9388409852981567\tacc 0.164000\n",
      "1402: \ttrain loss 1.9209407567977905\tacc 0.157143\tval loss 1.9388270378112793\tacc 0.164000\n",
      "1403: \ttrain loss 1.9209415912628174\tacc 0.157143\tval loss 1.9388434886932373\tacc 0.164000\n",
      "1404: \ttrain loss 1.9209405183792114\tacc 0.157143\tval loss 1.93882417678833\tacc 0.164000\n",
      "1405: \ttrain loss 1.9209415912628174\tacc 0.157143\tval loss 1.9388468265533447\tacc 0.164000\n",
      "1406: \ttrain loss 1.9209405183792114\tacc 0.157143\tval loss 1.9388214349746704\tacc 0.164000\n",
      "1407: \ttrain loss 1.9209420680999756\tacc 0.157143\tval loss 1.9388489723205566\tacc 0.164000\n",
      "1408: \ttrain loss 1.9209405183792114\tacc 0.157143\tval loss 1.9388200044631958\tacc 0.164000\n",
      "1409: \ttrain loss 1.9209420680999756\tacc 0.157143\tval loss 1.9388506412506104\tacc 0.164000\n",
      "1410: \ttrain loss 1.9209400415420532\tacc 0.157143\tval loss 1.9388178586959839\tacc 0.164000\n",
      "1411: \ttrain loss 1.9209423065185547\tacc 0.157143\tval loss 1.93885338306427\tacc 0.164000\n",
      "1412: \ttrain loss 1.9209400415420532\tacc 0.157143\tval loss 1.9388132095336914\tacc 0.164000\n",
      "1413: \ttrain loss 1.9209424257278442\tacc 0.157143\tval loss 1.938858985900879\tacc 0.164000\n",
      "1414: \ttrain loss 1.9209400415420532\tacc 0.157143\tval loss 1.9388072490692139\tacc 0.164000\n",
      "1415: \ttrain loss 1.9209426641464233\tacc 0.157143\tval loss 1.938866138458252\tacc 0.164000\n",
      "1416: \ttrain loss 1.9209394454956055\tacc 0.157143\tval loss 1.9387997388839722\tacc 0.164000\n",
      "1417: \ttrain loss 1.9209433794021606\tacc 0.157143\tval loss 1.938874363899231\tacc 0.164000\n",
      "1418: \ttrain loss 1.9209387302398682\tacc 0.157143\tval loss 1.938788652420044\tacc 0.166000\n",
      "1419: \ttrain loss 1.9209439754486084\tacc 0.157143\tval loss 1.9388887882232666\tacc 0.164000\n",
      "1420: \ttrain loss 1.9209378957748413\tacc 0.164286\tval loss 1.9387707710266113\tacc 0.166000\n",
      "1421: \ttrain loss 1.9209446907043457\tacc 0.157143\tval loss 1.9389108419418335\tacc 0.164000\n",
      "1422: \ttrain loss 1.9209368228912354\tacc 0.164286\tval loss 1.9387441873550415\tacc 0.166000\n",
      "1423: \ttrain loss 1.9209465980529785\tacc 0.157143\tval loss 1.9389430284500122\tacc 0.164000\n",
      "1424: \ttrain loss 1.920934796333313\tacc 0.164286\tval loss 1.9387050867080688\tacc 0.166000\n",
      "1425: \ttrain loss 1.9209489822387695\tacc 0.157143\tval loss 1.9389920234680176\tacc 0.164000\n",
      "1426: \ttrain loss 1.9209321737289429\tacc 0.164286\tval loss 1.9386441707611084\tacc 0.164000\n",
      "1427: \ttrain loss 1.9209529161453247\tacc 0.157143\tval loss 1.9390690326690674\tacc 0.164000\n",
      "1428: \ttrain loss 1.9209281206130981\tacc 0.164286\tval loss 1.9385478496551514\tacc 0.160000\n",
      "1429: \ttrain loss 1.920959234237671\tacc 0.157143\tval loss 1.9391918182373047\tacc 0.162000\n",
      "1430: \ttrain loss 1.9209219217300415\tacc 0.164286\tval loss 1.9383962154388428\tacc 0.158000\n",
      "1431: \ttrain loss 1.9209692478179932\tacc 0.157143\tval loss 1.939386010169983\tacc 0.164000\n",
      "1432: \ttrain loss 1.9209132194519043\tacc 0.164286\tval loss 1.9381576776504517\tacc 0.160000\n",
      "1433: \ttrain loss 1.9209873676300049\tacc 0.164286\tval loss 1.9396920204162598\tacc 0.164000\n",
      "1434: \ttrain loss 1.9209016561508179\tacc 0.157143\tval loss 1.9377919435501099\tacc 0.164000\n",
      "1435: \ttrain loss 1.9210174083709717\tacc 0.171429\tval loss 1.9401544332504272\tacc 0.168000\n",
      "1436: \ttrain loss 1.9208886623382568\tacc 0.171429\tval loss 1.9372767210006714\tacc 0.170000\n",
      "1437: \ttrain loss 1.9210644960403442\tacc 0.185714\tval loss 1.940757155418396\tacc 0.164000\n",
      "1438: \ttrain loss 1.9208803176879883\tacc 0.164286\tval loss 1.9367153644561768\tacc 0.170000\n",
      "1439: \ttrain loss 1.9211194515228271\tacc 0.171429\tval loss 1.9412412643432617\tacc 0.164000\n",
      "1440: \ttrain loss 1.9208807945251465\tacc 0.164286\tval loss 1.936518669128418\tacc 0.172000\n",
      "1441: \ttrain loss 1.9211267232894897\tacc 0.171429\tval loss 1.9409852027893066\tacc 0.168000\n",
      "1442: \ttrain loss 1.9208868741989136\tacc 0.171429\tval loss 1.937280297279358\tacc 0.168000\n",
      "1443: \ttrain loss 1.9210379123687744\tacc 0.171429\tval loss 1.9396588802337646\tacc 0.166000\n",
      "1444: \ttrain loss 1.920926809310913\tacc 0.157143\tval loss 1.9388980865478516\tacc 0.160000\n",
      "1445: \ttrain loss 1.9209383726119995\tacc 0.150000\tval loss 1.9379992485046387\tacc 0.162000\n",
      "1446: \ttrain loss 1.9210126399993896\tacc 0.178571\tval loss 1.9403079748153687\tacc 0.166000\n",
      "1447: \ttrain loss 1.9209026098251343\tacc 0.164286\tval loss 1.937142014503479\tacc 0.168000\n",
      "1448: \ttrain loss 1.921058177947998\tacc 0.171429\tval loss 1.9404748678207397\tacc 0.166000\n",
      "1449: \ttrain loss 1.9209065437316895\tacc 0.171429\tval loss 1.93768310546875\tacc 0.164000\n",
      "1450: \ttrain loss 1.9210102558135986\tacc 0.164286\tval loss 1.9393401145935059\tacc 0.164000\n",
      "1451: \ttrain loss 1.9209424257278442\tacc 0.171429\tval loss 1.939066767692566\tacc 0.160000\n",
      "1452: \ttrain loss 1.9209424257278442\tacc 0.157143\tval loss 1.9380319118499756\tacc 0.160000\n",
      "1453: \ttrain loss 1.9210021495819092\tacc 0.178571\tval loss 1.940003752708435\tacc 0.158000\n",
      "1454: \ttrain loss 1.9209150075912476\tacc 0.150000\tval loss 1.9376453161239624\tacc 0.164000\n",
      "1455: \ttrain loss 1.9210209846496582\tacc 0.164286\tval loss 1.939813494682312\tacc 0.164000\n",
      "1456: \ttrain loss 1.9209200143814087\tacc 0.171429\tval loss 1.9382846355438232\tacc 0.158000\n",
      "1457: \ttrain loss 1.9209792613983154\tacc 0.157143\tval loss 1.9388991594314575\tacc 0.164000\n",
      "1458: \ttrain loss 1.9209539890289307\tacc 0.178571\tval loss 1.9392095804214478\tacc 0.160000\n",
      "1459: \ttrain loss 1.9209344387054443\tacc 0.157143\tval loss 1.9381613731384277\tacc 0.160000\n",
      "1460: \ttrain loss 1.9209915399551392\tacc 0.178571\tval loss 1.9396233558654785\tacc 0.160000\n",
      "1461: \ttrain loss 1.9209184646606445\tacc 0.150000\tval loss 1.9381194114685059\tacc 0.160000\n",
      "1462: \ttrain loss 1.920989990234375\tacc 0.164286\tval loss 1.939334750175476\tacc 0.162000\n",
      "1463: \ttrain loss 1.9209284782409668\tacc 0.164286\tval loss 1.9386167526245117\tacc 0.164000\n",
      "1464: \ttrain loss 1.9209562540054321\tacc 0.150000\tval loss 1.9387552738189697\tacc 0.162000\n",
      "1465: \ttrain loss 1.920957088470459\tacc 0.178571\tval loss 1.9391483068466187\tacc 0.160000\n",
      "1466: \ttrain loss 1.920927882194519\tacc 0.157143\tval loss 1.9383701086044312\tacc 0.160000\n",
      "1467: \ttrain loss 1.9209766387939453\tacc 0.178571\tval loss 1.9393450021743774\tacc 0.160000\n",
      "1468: \ttrain loss 1.9209208488464355\tacc 0.157143\tval loss 1.9383820295333862\tacc 0.160000\n",
      "1469: \ttrain loss 1.920967698097229\tacc 0.150000\tval loss 1.9391461610794067\tacc 0.162000\n",
      "1470: \ttrain loss 1.9209342002868652\tacc 0.164286\tval loss 1.9387186765670776\tacc 0.162000\n",
      "1471: \ttrain loss 1.9209431409835815\tacc 0.150000\tval loss 1.9387470483779907\tacc 0.162000\n",
      "1472: \ttrain loss 1.9209550619125366\tacc 0.178571\tval loss 1.9391008615493774\tacc 0.162000\n",
      "1473: \ttrain loss 1.920926570892334\tacc 0.157143\tval loss 1.9384713172912598\tacc 0.162000\n",
      "1474: \ttrain loss 1.9209644794464111\tacc 0.178571\tval loss 1.9392234086990356\tacc 0.160000\n",
      "1475: \ttrain loss 1.920925259590149\tacc 0.157143\tval loss 1.9385215044021606\tacc 0.164000\n",
      "1476: \ttrain loss 1.920954704284668\tacc 0.150000\tval loss 1.9390277862548828\tacc 0.162000\n",
      "1477: \ttrain loss 1.9209368228912354\tacc 0.164286\tval loss 1.9388028383255005\tacc 0.162000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1478: \ttrain loss 1.9209381341934204\tacc 0.150000\tval loss 1.9387308359146118\tacc 0.164000\n",
      "1479: \ttrain loss 1.920951008796692\tacc 0.171429\tval loss 1.939051628112793\tacc 0.162000\n",
      "1480: \ttrain loss 1.920928716659546\tacc 0.157143\tval loss 1.9385762214660645\tacc 0.162000\n",
      "1481: \ttrain loss 1.9209550619125366\tacc 0.157143\tval loss 1.939090609550476\tacc 0.162000\n",
      "1482: \ttrain loss 1.920929193496704\tacc 0.157143\tval loss 1.9386446475982666\tacc 0.168000\n",
      "1483: \ttrain loss 1.9209481477737427\tacc 0.150000\tval loss 1.9389375448226929\tacc 0.162000\n",
      "1484: \ttrain loss 1.9209378957748413\tacc 0.164286\tval loss 1.938834309577942\tacc 0.162000\n",
      "1485: \ttrain loss 1.9209381341934204\tacc 0.150000\tval loss 1.9387530088424683\tacc 0.166000\n",
      "1486: \ttrain loss 1.9209465980529785\tacc 0.157143\tval loss 1.938971996307373\tacc 0.162000\n",
      "1487: \ttrain loss 1.9209318161010742\tacc 0.150000\tval loss 1.9386799335479736\tacc 0.166000\n",
      "1488: \ttrain loss 1.9209500551223755\tacc 0.157143\tval loss 1.9389744997024536\tacc 0.162000\n",
      "1489: \ttrain loss 1.9209320545196533\tacc 0.150000\tval loss 1.9387307167053223\tacc 0.166000\n",
      "1490: \ttrain loss 1.9209457635879517\tacc 0.157143\tval loss 1.9388892650604248\tacc 0.164000\n",
      "1491: \ttrain loss 1.9209378957748413\tacc 0.164286\tval loss 1.9388251304626465\tacc 0.162000\n",
      "1492: \ttrain loss 1.9209389686584473\tacc 0.150000\tval loss 1.9388012886047363\tacc 0.164000\n",
      "1493: \ttrain loss 1.9209442138671875\tacc 0.164286\tval loss 1.9388940334320068\tacc 0.162000\n",
      "1494: \ttrain loss 1.9209346771240234\tacc 0.150000\tval loss 1.9387562274932861\tacc 0.164000\n",
      "1495: \ttrain loss 1.9209468364715576\tacc 0.157143\tval loss 1.938913106918335\tacc 0.162000\n",
      "1496: \ttrain loss 1.9209346771240234\tacc 0.150000\tval loss 1.9387627840042114\tacc 0.164000\n",
      "1497: \ttrain loss 1.9209450483322144\tacc 0.157143\tval loss 1.9388856887817383\tacc 0.164000\n",
      "1498: \ttrain loss 1.9209381341934204\tacc 0.164286\tval loss 1.9388058185577393\tacc 0.164000\n",
      "1499: \ttrain loss 1.9209405183792114\tacc 0.150000\tval loss 1.9388340711593628\tacc 0.164000\n",
      "1500: \ttrain loss 1.9209426641464233\tacc 0.164286\tval loss 1.9388583898544312\tacc 0.162000\n",
      "1501: \ttrain loss 1.9209370613098145\tacc 0.150000\tval loss 1.938790202140808\tacc 0.164000\n",
      "1502: \ttrain loss 1.9209452867507935\tacc 0.157143\tval loss 1.9388893842697144\tacc 0.162000\n",
      "1503: \ttrain loss 1.9209363460540771\tacc 0.150000\tval loss 1.9387789964675903\tacc 0.164000\n",
      "1504: \ttrain loss 1.9209446907043457\tacc 0.157143\tval loss 1.9388803243637085\tacc 0.162000\n",
      "1505: \ttrain loss 1.9209383726119995\tacc 0.150000\tval loss 1.9388065338134766\tacc 0.164000\n",
      "1506: \ttrain loss 1.9209420680999756\tacc 0.157143\tval loss 1.938841462135315\tacc 0.164000\n",
      "1507: \ttrain loss 1.9209411144256592\tacc 0.157143\tval loss 1.938849687576294\tacc 0.162000\n",
      "1508: \ttrain loss 1.9209396839141846\tacc 0.150000\tval loss 1.9388041496276855\tacc 0.164000\n",
      "1509: \ttrain loss 1.9209431409835815\tacc 0.157143\tval loss 1.93887460231781\tacc 0.162000\n",
      "1510: \ttrain loss 1.920938491821289\tacc 0.150000\tval loss 1.9387953281402588\tacc 0.164000\n",
      "1511: \ttrain loss 1.9209444522857666\tacc 0.157143\tval loss 1.9388681650161743\tacc 0.162000\n",
      "1512: \ttrain loss 1.9209387302398682\tacc 0.150000\tval loss 1.9388134479522705\tacc 0.164000\n",
      "1513: \ttrain loss 1.9209431409835815\tacc 0.157143\tval loss 1.9388426542282104\tacc 0.166000\n",
      "1514: \ttrain loss 1.9209405183792114\tacc 0.150000\tval loss 1.9388412237167358\tacc 0.164000\n",
      "1515: \ttrain loss 1.9209415912628174\tacc 0.157143\tval loss 1.9388177394866943\tacc 0.164000\n",
      "1516: \ttrain loss 1.9209420680999756\tacc 0.157143\tval loss 1.938859224319458\tacc 0.164000\n",
      "1517: \ttrain loss 1.9209402799606323\tacc 0.150000\tval loss 1.9388080835342407\tacc 0.164000\n",
      "1518: \ttrain loss 1.9209431409835815\tacc 0.157143\tval loss 1.9388600587844849\tacc 0.162000\n",
      "1519: \ttrain loss 1.9209394454956055\tacc 0.150000\tval loss 1.938814401626587\tacc 0.164000\n",
      "1520: \ttrain loss 1.9209433794021606\tacc 0.157143\tval loss 1.9388490915298462\tacc 0.162000\n",
      "1521: \ttrain loss 1.9209396839141846\tacc 0.150000\tval loss 1.9388272762298584\tacc 0.164000\n",
      "1522: \ttrain loss 1.9209424257278442\tacc 0.157143\tval loss 1.9388359785079956\tacc 0.166000\n",
      "1523: \ttrain loss 1.9209405183792114\tacc 0.150000\tval loss 1.9388389587402344\tacc 0.164000\n",
      "1524: \ttrain loss 1.9209413528442383\tacc 0.157143\tval loss 1.9388258457183838\tacc 0.164000\n",
      "1525: \ttrain loss 1.9209415912628174\tacc 0.157143\tval loss 1.9388481378555298\tacc 0.164000\n",
      "1526: \ttrain loss 1.9209405183792114\tacc 0.157143\tval loss 1.9388176202774048\tacc 0.164000\n",
      "1527: \ttrain loss 1.9209423065185547\tacc 0.157143\tval loss 1.938854455947876\tacc 0.164000\n",
      "1528: \ttrain loss 1.9209400415420532\tacc 0.157143\tval loss 1.93881356716156\tacc 0.164000\n",
      "1529: \ttrain loss 1.9209424257278442\tacc 0.157143\tval loss 1.9388545751571655\tacc 0.164000\n",
      "1530: \ttrain loss 1.9209400415420532\tacc 0.150000\tval loss 1.9388179779052734\tacc 0.164000\n",
      "1531: \ttrain loss 1.9209423065185547\tacc 0.157143\tval loss 1.938845157623291\tacc 0.164000\n",
      "1532: \ttrain loss 1.9209405183792114\tacc 0.150000\tval loss 1.9388318061828613\tacc 0.164000\n",
      "1533: \ttrain loss 1.9209415912628174\tacc 0.157143\tval loss 1.9388296604156494\tacc 0.164000\n",
      "1534: \ttrain loss 1.9209411144256592\tacc 0.157143\tval loss 1.9388470649719238\tacc 0.164000\n",
      "1535: \ttrain loss 1.9209411144256592\tacc 0.157143\tval loss 1.938815951347351\tacc 0.164000\n",
      "1536: \ttrain loss 1.9209418296813965\tacc 0.157143\tval loss 1.9388575553894043\tacc 0.164000\n",
      "1537: \ttrain loss 1.9209402799606323\tacc 0.157143\tval loss 1.9388102293014526\tacc 0.164000\n",
      "1538: \ttrain loss 1.9209420680999756\tacc 0.157143\tval loss 1.9388593435287476\tacc 0.164000\n",
      "1539: \ttrain loss 1.9209398031234741\tacc 0.157143\tval loss 1.93881094455719\tacc 0.164000\n",
      "1540: \ttrain loss 1.9209424257278442\tacc 0.157143\tval loss 1.938856840133667\tacc 0.164000\n",
      "1541: \ttrain loss 1.9209400415420532\tacc 0.157143\tval loss 1.9388148784637451\tacc 0.164000\n",
      "1542: \ttrain loss 1.9209423065185547\tacc 0.157143\tval loss 1.9388519525527954\tacc 0.164000\n",
      "1543: \ttrain loss 1.9209402799606323\tacc 0.157143\tval loss 1.9388196468353271\tacc 0.164000\n",
      "1544: \ttrain loss 1.9209415912628174\tacc 0.157143\tval loss 1.9388463497161865\tacc 0.164000\n",
      "1545: \ttrain loss 1.9209407567977905\tacc 0.157143\tval loss 1.9388266801834106\tacc 0.164000\n",
      "1546: \ttrain loss 1.9209413528442383\tacc 0.157143\tval loss 1.9388391971588135\tacc 0.164000\n",
      "1547: \ttrain loss 1.9209407567977905\tacc 0.157143\tval loss 1.9388335943222046\tacc 0.164000\n",
      "1548: \ttrain loss 1.9209409952163696\tacc 0.157143\tval loss 1.9388327598571777\tacc 0.164000\n",
      "1549: \ttrain loss 1.9209413528442383\tacc 0.157143\tval loss 1.938839077949524\tacc 0.164000\n",
      "1550: \ttrain loss 1.9209409952163696\tacc 0.157143\tval loss 1.9388279914855957\tacc 0.164000\n",
      "1551: \ttrain loss 1.9209413528442383\tacc 0.157143\tval loss 1.938842535018921\tacc 0.164000\n",
      "1552: \ttrain loss 1.9209407567977905\tacc 0.157143\tval loss 1.9388251304626465\tacc 0.164000\n",
      "1553: \ttrain loss 1.9209415912628174\tacc 0.157143\tval loss 1.938845157623291\tacc 0.164000\n",
      "1554: \ttrain loss 1.9209400415420532\tacc 0.157143\tval loss 1.9388234615325928\tacc 0.164000\n",
      "1555: \ttrain loss 1.9209415912628174\tacc 0.157143\tval loss 1.9388457536697388\tacc 0.164000\n",
      "1556: \ttrain loss 1.9209405183792114\tacc 0.157143\tval loss 1.9388245344161987\tacc 0.164000\n",
      "1557: \ttrain loss 1.9209413528442383\tacc 0.157143\tval loss 1.9388437271118164\tacc 0.164000\n",
      "1558: \ttrain loss 1.9209405183792114\tacc 0.157143\tval loss 1.9388269186019897\tacc 0.164000\n",
      "1559: \ttrain loss 1.9209413528442383\tacc 0.157143\tval loss 1.9388422966003418\tacc 0.164000\n",
      "1560: \ttrain loss 1.9209407567977905\tacc 0.157143\tval loss 1.9388267993927002\tacc 0.164000\n",
      "1561: \ttrain loss 1.9209413528442383\tacc 0.157143\tval loss 1.9388436079025269\tacc 0.164000\n",
      "1562: \ttrain loss 1.9209405183792114\tacc 0.157143\tval loss 1.9388248920440674\tacc 0.164000\n",
      "1563: \ttrain loss 1.9209415912628174\tacc 0.157143\tval loss 1.9388444423675537\tacc 0.164000\n",
      "1564: \ttrain loss 1.9209407567977905\tacc 0.157143\tval loss 1.9388266801834106\tacc 0.164000\n",
      "1565: \ttrain loss 1.9209411144256592\tacc 0.157143\tval loss 1.9388408660888672\tacc 0.164000\n",
      "1566: \ttrain loss 1.9209409952163696\tacc 0.157143\tval loss 1.9388301372528076\tacc 0.164000\n",
      "1567: \ttrain loss 1.9209415912628174\tacc 0.157143\tval loss 1.9388377666473389\tacc 0.164000\n",
      "1568: \ttrain loss 1.9209409952163696\tacc 0.157143\tval loss 1.93883216381073\tacc 0.164000\n",
      "1569: \ttrain loss 1.9209409952163696\tacc 0.157143\tval loss 1.9388388395309448\tacc 0.164000\n",
      "1570: \ttrain loss 1.9209411144256592\tacc 0.157143\tval loss 1.938828468322754\tacc 0.164000\n",
      "1571: \ttrain loss 1.9209409952163696\tacc 0.157143\tval loss 1.9388434886932373\tacc 0.164000\n",
      "1572: \ttrain loss 1.9209411144256592\tacc 0.157143\tval loss 1.938822865486145\tacc 0.164000\n",
      "1573: \ttrain loss 1.9209413528442383\tacc 0.150000\tval loss 1.938849687576294\tacc 0.164000\n",
      "1574: \ttrain loss 1.9209411144256592\tacc 0.157143\tval loss 1.9388164281845093\tacc 0.162000\n",
      "1575: \ttrain loss 1.9209413528442383\tacc 0.150000\tval loss 1.938856840133667\tacc 0.164000\n",
      "1576: \ttrain loss 1.9209411144256592\tacc 0.164286\tval loss 1.938807725906372\tacc 0.164000\n",
      "1577: \ttrain loss 1.9209415912628174\tacc 0.150000\tval loss 1.938869595527649\tacc 0.164000\n",
      "1578: \ttrain loss 1.9209411144256592\tacc 0.164286\tval loss 1.938788890838623\tacc 0.164000\n",
      "1579: \ttrain loss 1.9209420680999756\tacc 0.150000\tval loss 1.9388952255249023\tacc 0.162000\n",
      "1580: \ttrain loss 1.9209402799606323\tacc 0.164286\tval loss 1.9387556314468384\tacc 0.164000\n",
      "1581: \ttrain loss 1.9209429025650024\tacc 0.150000\tval loss 1.9389370679855347\tacc 0.162000\n",
      "1582: \ttrain loss 1.9209396839141846\tacc 0.164286\tval loss 1.938704013824463\tacc 0.164000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1583: \ttrain loss 1.9209437370300293\tacc 0.150000\tval loss 1.938999891281128\tacc 0.164000\n",
      "1584: \ttrain loss 1.920938491821289\tacc 0.164286\tval loss 1.9386281967163086\tacc 0.162000\n",
      "1585: \ttrain loss 1.9209452867507935\tacc 0.150000\tval loss 1.939094066619873\tacc 0.160000\n",
      "1586: \ttrain loss 1.920937418937683\tacc 0.178571\tval loss 1.938509225845337\tacc 0.158000\n",
      "1587: \ttrain loss 1.9209486246109009\tacc 0.150000\tval loss 1.9392447471618652\tacc 0.160000\n",
      "1588: \ttrain loss 1.9209357500076294\tacc 0.171429\tval loss 1.9383255243301392\tacc 0.160000\n",
      "1589: \ttrain loss 1.920953631401062\tacc 0.150000\tval loss 1.9394662380218506\tacc 0.162000\n",
      "1590: \ttrain loss 1.920935034751892\tacc 0.185714\tval loss 1.9380748271942139\tacc 0.158000\n",
      "1591: \ttrain loss 1.9209626913070679\tacc 0.157143\tval loss 1.939732313156128\tacc 0.160000\n",
      "1592: \ttrain loss 1.920935034751892\tacc 0.185714\tval loss 1.937840461730957\tacc 0.160000\n",
      "1593: \ttrain loss 1.9209762811660767\tacc 0.164286\tval loss 1.9398771524429321\tacc 0.162000\n",
      "1594: \ttrain loss 1.9209321737289429\tacc 0.185714\tval loss 1.937861442565918\tacc 0.162000\n",
      "1595: \ttrain loss 1.920986294746399\tacc 0.164286\tval loss 1.93965744972229\tacc 0.164000\n",
      "1596: \ttrain loss 1.9209210872650146\tacc 0.185714\tval loss 1.9382377862930298\tacc 0.162000\n",
      "1597: \ttrain loss 1.9209908246994019\tacc 0.157143\tval loss 1.9392696619033813\tacc 0.164000\n",
      "1598: \ttrain loss 1.9209076166152954\tacc 0.157143\tval loss 1.938470721244812\tacc 0.160000\n",
      "1599: \ttrain loss 1.9210063219070435\tacc 0.178571\tval loss 1.9393573999404907\tacc 0.162000\n",
      "1600: \ttrain loss 1.9209026098251343\tacc 0.150000\tval loss 1.9380247592926025\tacc 0.166000\n",
      "1601: \ttrain loss 1.9210368394851685\tacc 0.185714\tval loss 1.9401285648345947\tacc 0.160000\n",
      "1602: \ttrain loss 1.9208989143371582\tacc 0.157143\tval loss 1.9371498823165894\tacc 0.168000\n",
      "1603: \ttrain loss 1.9210717678070068\tacc 0.178571\tval loss 1.9408735036849976\tacc 0.160000\n",
      "1604: \ttrain loss 1.9208918809890747\tacc 0.150000\tval loss 1.9368205070495605\tacc 0.182000\n",
      "1605: \ttrain loss 1.921089768409729\tacc 0.164286\tval loss 1.9406951665878296\tacc 0.164000\n",
      "1606: \ttrain loss 1.9208892583847046\tacc 0.164286\tval loss 1.9374397993087769\tacc 0.166000\n",
      "1607: \ttrain loss 1.9210689067840576\tacc 0.171429\tval loss 1.9398226737976074\tacc 0.166000\n",
      "1608: \ttrain loss 1.9209047555923462\tacc 0.178571\tval loss 1.9383057355880737\tacc 0.162000\n",
      "1609: \ttrain loss 1.9210028648376465\tacc 0.164286\tval loss 1.9390262365341187\tacc 0.160000\n",
      "1610: \ttrain loss 1.9209433794021606\tacc 0.164286\tval loss 1.9389821290969849\tacc 0.160000\n",
      "1611: \ttrain loss 1.9209394454956055\tacc 0.150000\tval loss 1.938388466835022\tacc 0.164000\n",
      "1612: \ttrain loss 1.9209997653961182\tacc 0.164286\tval loss 1.9396244287490845\tacc 0.166000\n",
      "1613: \ttrain loss 1.9209136962890625\tacc 0.171429\tval loss 1.93782377243042\tacc 0.162000\n",
      "1614: \ttrain loss 1.9210307598114014\tacc 0.171429\tval loss 1.9399982690811157\tacc 0.166000\n",
      "1615: \ttrain loss 1.9209121465682983\tacc 0.171429\tval loss 1.9377691745758057\tacc 0.164000\n",
      "1616: \ttrain loss 1.9210100173950195\tacc 0.164286\tval loss 1.9396430253982544\tacc 0.158000\n",
      "1617: \ttrain loss 1.920929193496704\tacc 0.142857\tval loss 1.9384608268737793\tacc 0.164000\n",
      "1618: \ttrain loss 1.9209660291671753\tacc 0.157143\tval loss 1.9387238025665283\tacc 0.156000\n",
      "1619: \ttrain loss 1.920963168144226\tacc 0.157143\tval loss 1.9394054412841797\tacc 0.164000\n",
      "1620: \ttrain loss 1.920931339263916\tacc 0.157143\tval loss 1.937950611114502\tacc 0.160000\n",
      "1621: \ttrain loss 1.920993447303772\tacc 0.164286\tval loss 1.939847469329834\tacc 0.162000\n",
      "1622: \ttrain loss 1.9209184646606445\tacc 0.164286\tval loss 1.9379339218139648\tacc 0.166000\n",
      "1623: \ttrain loss 1.9209952354431152\tacc 0.164286\tval loss 1.9394468069076538\tacc 0.160000\n",
      "1624: \ttrain loss 1.9209237098693848\tacc 0.150000\tval loss 1.9386093616485596\tacc 0.162000\n",
      "1625: \ttrain loss 1.9209712743759155\tacc 0.178571\tval loss 1.9387096166610718\tacc 0.164000\n",
      "1626: \ttrain loss 1.9209405183792114\tacc 0.150000\tval loss 1.9391671419143677\tacc 0.158000\n",
      "1627: \ttrain loss 1.9209463596343994\tacc 0.178571\tval loss 1.9384560585021973\tacc 0.162000\n",
      "1628: \ttrain loss 1.9209575653076172\tacc 0.150000\tval loss 1.9391356706619263\tacc 0.162000\n",
      "1629: \ttrain loss 1.9209297895431519\tacc 0.157143\tval loss 1.9386441707611084\tacc 0.162000\n",
      "1630: \ttrain loss 1.9209681749343872\tacc 0.178571\tval loss 1.9389574527740479\tacc 0.162000\n",
      "1631: \ttrain loss 1.920925498008728\tacc 0.157143\tval loss 1.938708782196045\tacc 0.162000\n",
      "1632: \ttrain loss 1.920964002609253\tacc 0.178571\tval loss 1.9390125274658203\tacc 0.162000\n",
      "1633: \ttrain loss 1.920930027961731\tacc 0.157143\tval loss 1.9386200904846191\tacc 0.166000\n",
      "1634: \ttrain loss 1.9209524393081665\tacc 0.157143\tval loss 1.9390320777893066\tacc 0.160000\n",
      "1635: \ttrain loss 1.9209394454956055\tacc 0.164286\tval loss 1.9387292861938477\tacc 0.164000\n",
      "1636: \ttrain loss 1.9209394454956055\tacc 0.150000\tval loss 1.9388173818588257\tacc 0.162000\n",
      "1637: \ttrain loss 1.9209494590759277\tacc 0.178571\tval loss 1.9389833211898804\tacc 0.162000\n",
      "1638: \ttrain loss 1.9209318161010742\tacc 0.157143\tval loss 1.938592791557312\tacc 0.166000\n",
      "1639: \ttrain loss 1.9209537506103516\tacc 0.157143\tval loss 1.9391372203826904\tacc 0.162000\n",
      "1640: \ttrain loss 1.9209281206130981\tacc 0.150000\tval loss 1.938535213470459\tacc 0.160000\n",
      "1641: \ttrain loss 1.9209539890289307\tacc 0.157143\tval loss 1.9390968084335327\tacc 0.162000\n",
      "1642: \ttrain loss 1.9209305047988892\tacc 0.164286\tval loss 1.9386601448059082\tacc 0.162000\n",
      "1643: \ttrain loss 1.9209470748901367\tacc 0.150000\tval loss 1.9389041662216187\tacc 0.162000\n",
      "1644: \ttrain loss 1.9209376573562622\tacc 0.164286\tval loss 1.9388853311538696\tacc 0.162000\n",
      "1645: \ttrain loss 1.9209383726119995\tacc 0.150000\tval loss 1.9386889934539795\tacc 0.164000\n",
      "1646: \ttrain loss 1.9209448099136353\tacc 0.157143\tval loss 1.9390403032302856\tacc 0.164000\n",
      "1647: \ttrain loss 1.920932412147522\tacc 0.164286\tval loss 1.9386223554611206\tacc 0.166000\n",
      "1648: \ttrain loss 1.9209500551223755\tacc 0.150000\tval loss 1.9390214681625366\tacc 0.164000\n",
      "1649: \ttrain loss 1.920930027961731\tacc 0.164286\tval loss 1.9386905431747437\tacc 0.162000\n",
      "1650: \ttrain loss 1.920949935913086\tacc 0.150000\tval loss 1.9389417171478271\tacc 0.162000\n",
      "1651: \ttrain loss 1.9209320545196533\tacc 0.164286\tval loss 1.9387519359588623\tacc 0.164000\n",
      "1652: \ttrain loss 1.9209461212158203\tacc 0.157143\tval loss 1.9388980865478516\tacc 0.166000\n",
      "1653: \ttrain loss 1.9209365844726562\tacc 0.150000\tval loss 1.9387900829315186\tacc 0.164000\n",
      "1654: \ttrain loss 1.9209411144256592\tacc 0.157143\tval loss 1.9388457536697388\tacc 0.162000\n",
      "1655: \ttrain loss 1.9209407567977905\tacc 0.150000\tval loss 1.9388630390167236\tacc 0.164000\n",
      "1656: \ttrain loss 1.920937418937683\tacc 0.164286\tval loss 1.9387606382369995\tacc 0.164000\n",
      "1657: \ttrain loss 1.9209444522857666\tacc 0.150000\tval loss 1.938941240310669\tacc 0.162000\n",
      "1658: \ttrain loss 1.9209357500076294\tacc 0.164286\tval loss 1.9387078285217285\tacc 0.166000\n",
      "1659: \ttrain loss 1.9209460020065308\tacc 0.157143\tval loss 1.9389556646347046\tacc 0.162000\n",
      "1660: \ttrain loss 1.9209357500076294\tacc 0.157143\tval loss 1.9387348890304565\tacc 0.166000\n",
      "1661: \ttrain loss 1.9209455251693726\tacc 0.157143\tval loss 1.9388971328735352\tacc 0.162000\n",
      "1662: \ttrain loss 1.920937418937683\tacc 0.150000\tval loss 1.9388091564178467\tacc 0.164000\n",
      "1663: \ttrain loss 1.9209431409835815\tacc 0.157143\tval loss 1.938825249671936\tacc 0.162000\n",
      "1664: \ttrain loss 1.9209398031234741\tacc 0.150000\tval loss 1.938866138458252\tacc 0.164000\n",
      "1665: \ttrain loss 1.9209407567977905\tacc 0.157143\tval loss 1.938791275024414\tacc 0.164000\n",
      "1666: \ttrain loss 1.9209424257278442\tacc 0.157143\tval loss 1.938879370689392\tacc 0.166000\n",
      "1667: \ttrain loss 1.9209387302398682\tacc 0.150000\tval loss 1.9387919902801514\tacc 0.164000\n",
      "1668: \ttrain loss 1.9209446907043457\tacc 0.157143\tval loss 1.9388774633407593\tacc 0.162000\n",
      "1669: \ttrain loss 1.920937418937683\tacc 0.150000\tval loss 1.9387867450714111\tacc 0.164000\n",
      "1670: \ttrain loss 1.9209452867507935\tacc 0.157143\tval loss 1.9388937950134277\tacc 0.162000\n",
      "1671: \ttrain loss 1.9209368228912354\tacc 0.150000\tval loss 1.9387657642364502\tacc 0.166000\n",
      "1672: \ttrain loss 1.9209455251693726\tacc 0.157143\tval loss 1.9389113187789917\tacc 0.164000\n",
      "1673: \ttrain loss 1.9209376573562622\tacc 0.164286\tval loss 1.938759684562683\tacc 0.166000\n",
      "1674: \ttrain loss 1.9209446907043457\tacc 0.157143\tval loss 1.9389005899429321\tacc 0.164000\n",
      "1675: \ttrain loss 1.9209387302398682\tacc 0.164286\tval loss 1.9387866258621216\tacc 0.166000\n",
      "1676: \ttrain loss 1.9209429025650024\tacc 0.150000\tval loss 1.9388620853424072\tacc 0.164000\n",
      "1677: \ttrain loss 1.9209409952163696\tacc 0.157143\tval loss 1.9388306140899658\tacc 0.164000\n",
      "1678: \ttrain loss 1.9209413528442383\tacc 0.157143\tval loss 1.9388192892074585\tacc 0.164000\n",
      "1679: \ttrain loss 1.9209420680999756\tacc 0.157143\tval loss 1.9388666152954102\tacc 0.164000\n",
      "1680: \ttrain loss 1.9209402799606323\tacc 0.157143\tval loss 1.9387929439544678\tacc 0.164000\n",
      "1681: \ttrain loss 1.9209429025650024\tacc 0.157143\tval loss 1.9388810396194458\tacc 0.164000\n",
      "1682: \ttrain loss 1.9209396839141846\tacc 0.164286\tval loss 1.9387905597686768\tacc 0.166000\n",
      "1683: \ttrain loss 1.9209433794021606\tacc 0.157143\tval loss 1.9388751983642578\tacc 0.164000\n",
      "1684: \ttrain loss 1.9209394454956055\tacc 0.164286\tval loss 1.9388002157211304\tacc 0.164000\n",
      "1685: \ttrain loss 1.9209431409835815\tacc 0.157143\tval loss 1.938865303993225\tacc 0.164000\n",
      "1686: \ttrain loss 1.9209389686584473\tacc 0.157143\tval loss 1.9388052225112915\tacc 0.164000\n",
      "1687: \ttrain loss 1.9209436178207397\tacc 0.157143\tval loss 1.938865065574646\tacc 0.164000\n",
      "1688: \ttrain loss 1.9209394454956055\tacc 0.157143\tval loss 1.9388024806976318\tacc 0.164000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1689: \ttrain loss 1.9209431409835815\tacc 0.157143\tval loss 1.938866376876831\tacc 0.164000\n",
      "1690: \ttrain loss 1.9209396839141846\tacc 0.157143\tval loss 1.9388062953948975\tacc 0.164000\n",
      "1691: \ttrain loss 1.9209426641464233\tacc 0.157143\tval loss 1.9388577938079834\tacc 0.164000\n",
      "1692: \ttrain loss 1.9209402799606323\tacc 0.157143\tval loss 1.938818335533142\tacc 0.164000\n",
      "1693: \ttrain loss 1.9209420680999756\tacc 0.157143\tval loss 1.9388447999954224\tacc 0.164000\n",
      "1694: \ttrain loss 1.9209409952163696\tacc 0.157143\tval loss 1.9388290643692017\tacc 0.164000\n",
      "1695: \ttrain loss 1.9209413528442383\tacc 0.157143\tval loss 1.9388371706008911\tacc 0.164000\n",
      "1696: \ttrain loss 1.9209409952163696\tacc 0.157143\tval loss 1.9388344287872314\tacc 0.164000\n",
      "1697: \ttrain loss 1.9209413528442383\tacc 0.157143\tval loss 1.9388333559036255\tacc 0.164000\n",
      "1698: \ttrain loss 1.9209411144256592\tacc 0.157143\tval loss 1.9388384819030762\tacc 0.164000\n",
      "1699: \ttrain loss 1.9209409952163696\tacc 0.157143\tval loss 1.9388294219970703\tacc 0.164000\n",
      "1700: \ttrain loss 1.9209415912628174\tacc 0.157143\tval loss 1.9388415813446045\tacc 0.164000\n",
      "1701: \ttrain loss 1.9209405183792114\tacc 0.157143\tval loss 1.9388257265090942\tacc 0.164000\n",
      "1702: \ttrain loss 1.9209418296813965\tacc 0.157143\tval loss 1.9388461112976074\tacc 0.164000\n",
      "1703: \ttrain loss 1.9209402799606323\tacc 0.157143\tval loss 1.9388201236724854\tacc 0.164000\n",
      "1704: \ttrain loss 1.9209424257278442\tacc 0.157143\tval loss 1.93885338306427\tacc 0.164000\n",
      "1705: \ttrain loss 1.9209398031234741\tacc 0.157143\tval loss 1.9388121366500854\tacc 0.164000\n",
      "1706: \ttrain loss 1.9209423065185547\tacc 0.157143\tval loss 1.938859462738037\tacc 0.164000\n",
      "1707: \ttrain loss 1.9209400415420532\tacc 0.157143\tval loss 1.9388107061386108\tacc 0.164000\n",
      "1708: \ttrain loss 1.9209420680999756\tacc 0.157143\tval loss 1.938855767250061\tacc 0.164000\n",
      "1709: \ttrain loss 1.9209405183792114\tacc 0.157143\tval loss 1.9388190507888794\tacc 0.164000\n",
      "1710: \ttrain loss 1.9209418296813965\tacc 0.157143\tval loss 1.9388442039489746\tacc 0.164000\n",
      "1711: \ttrain loss 1.9209405183792114\tacc 0.157143\tval loss 1.9388302564620972\tacc 0.164000\n",
      "1712: \ttrain loss 1.9209415912628174\tacc 0.157143\tval loss 1.9388360977172852\tacc 0.164000\n",
      "1713: \ttrain loss 1.9209407567977905\tacc 0.157143\tval loss 1.9388335943222046\tacc 0.164000\n",
      "1714: \ttrain loss 1.9209411144256592\tacc 0.157143\tval loss 1.9388411045074463\tacc 0.164000\n",
      "1715: \ttrain loss 1.9209402799606323\tacc 0.157143\tval loss 1.9388149976730347\tacc 0.164000\n",
      "1716: \ttrain loss 1.9209429025650024\tacc 0.157143\tval loss 1.9388749599456787\tacc 0.164000\n",
      "1717: \ttrain loss 1.9209381341934204\tacc 0.157143\tval loss 1.938767671585083\tacc 0.166000\n",
      "1718: \ttrain loss 1.9209452867507935\tacc 0.157143\tval loss 1.9389327764511108\tacc 0.164000\n",
      "1719: \ttrain loss 1.920936107635498\tacc 0.164286\tval loss 1.9387072324752808\tacc 0.166000\n",
      "1720: \ttrain loss 1.9209474325180054\tacc 0.157143\tval loss 1.9389859437942505\tacc 0.162000\n",
      "1721: \ttrain loss 1.9209342002868652\tacc 0.157143\tval loss 1.938664197921753\tacc 0.166000\n",
      "1722: \ttrain loss 1.9209494590759277\tacc 0.157143\tval loss 1.93902587890625\tacc 0.166000\n",
      "1723: \ttrain loss 1.9209315776824951\tacc 0.157143\tval loss 1.938617467880249\tacc 0.162000\n",
      "1724: \ttrain loss 1.920953392982483\tacc 0.157143\tval loss 1.9390919208526611\tacc 0.162000\n",
      "1725: \ttrain loss 1.92092764377594\tacc 0.157143\tval loss 1.9385241270065308\tacc 0.160000\n",
      "1726: \ttrain loss 1.920959711074829\tacc 0.157143\tval loss 1.9392215013504028\tacc 0.160000\n",
      "1727: \ttrain loss 1.9209223985671997\tacc 0.150000\tval loss 1.9383575916290283\tacc 0.162000\n",
      "1728: \ttrain loss 1.9209699630737305\tacc 0.171429\tval loss 1.93943452835083\tacc 0.160000\n",
      "1729: \ttrain loss 1.9209132194519043\tacc 0.157143\tval loss 1.9380992650985718\tacc 0.160000\n",
      "1730: \ttrain loss 1.9209882020950317\tacc 0.178571\tval loss 1.9397636651992798\tacc 0.162000\n",
      "1731: \ttrain loss 1.9209012985229492\tacc 0.150000\tval loss 1.9377074241638184\tacc 0.164000\n",
      "1732: \ttrain loss 1.9210189580917358\tacc 0.178571\tval loss 1.940256953239441\tacc 0.162000\n",
      "1733: \ttrain loss 1.9208897352218628\tacc 0.150000\tval loss 1.9371544122695923\tacc 0.166000\n",
      "1734: \ttrain loss 1.9210678339004517\tacc 0.171429\tval loss 1.940908432006836\tacc 0.162000\n",
      "1735: \ttrain loss 1.9208821058273315\tacc 0.142857\tval loss 1.9365490674972534\tacc 0.168000\n",
      "1736: \ttrain loss 1.9211277961730957\tacc 0.171429\tval loss 1.9414247274398804\tacc 0.156000\n",
      "1737: \ttrain loss 1.9208837747573853\tacc 0.142857\tval loss 1.9363588094711304\tacc 0.172000\n",
      "1738: \ttrain loss 1.921138882637024\tacc 0.171429\tval loss 1.9411271810531616\tacc 0.160000\n",
      "1739: \ttrain loss 1.920890212059021\tacc 0.142857\tval loss 1.937125563621521\tacc 0.166000\n",
      "1740: \ttrain loss 1.9210610389709473\tacc 0.178571\tval loss 1.9399738311767578\tacc 0.164000\n",
      "1741: \ttrain loss 1.9209076166152954\tacc 0.164286\tval loss 1.9383745193481445\tacc 0.158000\n",
      "1742: \ttrain loss 1.9209836721420288\tacc 0.164286\tval loss 1.938731074333191\tacc 0.166000\n",
      "1743: \ttrain loss 1.9209651947021484\tacc 0.185714\tval loss 1.9394632577896118\tacc 0.162000\n",
      "1744: \ttrain loss 1.920925498008728\tacc 0.142857\tval loss 1.9378561973571777\tacc 0.160000\n",
      "1745: \ttrain loss 1.921026587486267\tacc 0.185714\tval loss 1.9400842189788818\tacc 0.158000\n",
      "1746: \ttrain loss 1.9209126234054565\tacc 0.142857\tval loss 1.9376354217529297\tacc 0.166000\n",
      "1747: \ttrain loss 1.9210270643234253\tacc 0.178571\tval loss 1.939770221710205\tacc 0.164000\n",
      "1748: \ttrain loss 1.920927882194519\tacc 0.150000\tval loss 1.9384350776672363\tacc 0.166000\n",
      "1749: \ttrain loss 1.9209702014923096\tacc 0.157143\tval loss 1.9387295246124268\tacc 0.166000\n",
      "1750: \ttrain loss 1.920965552330017\tacc 0.178571\tval loss 1.9393346309661865\tacc 0.156000\n",
      "1751: \ttrain loss 1.9209439754486084\tacc 0.150000\tval loss 1.9380980730056763\tacc 0.164000\n",
      "1752: \ttrain loss 1.9210041761398315\tacc 0.178571\tval loss 1.939731240272522\tacc 0.162000\n",
      "1753: \ttrain loss 1.9209105968475342\tacc 0.150000\tval loss 1.9378793239593506\tacc 0.160000\n",
      "1754: \ttrain loss 1.9210351705551147\tacc 0.185714\tval loss 1.9398423433303833\tacc 0.160000\n",
      "1755: \ttrain loss 1.9209113121032715\tacc 0.157143\tval loss 1.9378851652145386\tacc 0.162000\n",
      "1756: \ttrain loss 1.9210010766983032\tacc 0.164286\tval loss 1.939639925956726\tacc 0.162000\n",
      "1757: \ttrain loss 1.92093026638031\tacc 0.164286\tval loss 1.9381475448608398\tacc 0.160000\n",
      "1758: \ttrain loss 1.9209779500961304\tacc 0.157143\tval loss 1.939635157585144\tacc 0.168000\n",
      "1759: \ttrain loss 1.9209092855453491\tacc 0.178571\tval loss 1.9376386404037476\tacc 0.174000\n",
      "1760: \ttrain loss 1.921048641204834\tacc 0.171429\tval loss 1.9408437013626099\tacc 0.162000\n",
      "1761: \ttrain loss 1.920900583267212\tacc 0.178571\tval loss 1.9357088804244995\tacc 0.204000\n",
      "1762: \ttrain loss 1.9213252067565918\tacc 0.200000\tval loss 1.9449902772903442\tacc 0.160000\n",
      "1763: \ttrain loss 1.9210249185562134\tacc 0.150000\tval loss 1.929200530052185\tacc 0.212000\n",
      "1764: \ttrain loss 1.9160367250442505\tacc 0.200000\tval loss 1.849687933921814\tacc 0.258000\n",
      "1765: \ttrain loss 1.776165246963501\tacc 0.292857\tval loss 1.787642002105713\tacc 0.308000\n",
      "1766: \ttrain loss 1.634831190109253\tacc 0.285714\tval loss 2.036356210708618\tacc 0.156000\n",
      "1767: \ttrain loss 2.1006526947021484\tacc 0.142857\tval loss 2.0267648696899414\tacc 0.156000\n",
      "1768: \ttrain loss 2.0934998989105225\tacc 0.142857\tval loss 2.005156993865967\tacc 0.158000\n",
      "1769: \ttrain loss 2.0116498470306396\tacc 0.150000\tval loss 2.2095389366149902\tacc 0.072000\n",
      "1770: \ttrain loss 2.089988946914673\tacc 0.150000\tval loss 1.9184002876281738\tacc 0.186000\n",
      "1771: \ttrain loss 1.9471995830535889\tacc 0.128571\tval loss 1.9127026796340942\tacc 0.162000\n",
      "1772: \ttrain loss 1.971367359161377\tacc 0.135714\tval loss 1.9047425985336304\tacc 0.174000\n",
      "1773: \ttrain loss 1.9660097360610962\tacc 0.135714\tval loss 1.8647029399871826\tacc 0.172000\n",
      "1774: \ttrain loss 1.915960431098938\tacc 0.200000\tval loss 1.8230078220367432\tacc 0.214000\n",
      "1775: \ttrain loss 1.8199477195739746\tacc 0.271429\tval loss 1.8628568649291992\tacc 0.250000\n",
      "1776: \ttrain loss 1.7492505311965942\tacc 0.307143\tval loss 1.7993638515472412\tacc 0.224000\n",
      "1777: \ttrain loss 1.751164197921753\tacc 0.300000\tval loss 1.716268539428711\tacc 0.334000\n",
      "1778: \ttrain loss 1.624680757522583\tacc 0.292857\tval loss 1.6747376918792725\tacc 0.350000\n",
      "1779: \ttrain loss 1.5549691915512085\tacc 0.335714\tval loss 1.7384016513824463\tacc 0.282000\n",
      "1780: \ttrain loss 1.6320178508758545\tacc 0.350000\tval loss 1.64047110080719\tacc 0.386000\n",
      "1781: \ttrain loss 1.5039291381835938\tacc 0.421429\tval loss 1.6564550399780273\tacc 0.430000\n",
      "1782: \ttrain loss 1.4635615348815918\tacc 0.400000\tval loss 1.7105624675750732\tacc 0.284000\n",
      "1783: \ttrain loss 1.532268762588501\tacc 0.392857\tval loss 2.1680386066436768\tacc 0.228000\n",
      "1784: \ttrain loss 1.6727886199951172\tacc 0.292857\tval loss 1.695905327796936\tacc 0.324000\n",
      "1785: \ttrain loss 1.506854772567749\tacc 0.492857\tval loss 1.737958550453186\tacc 0.194000\n",
      "1786: \ttrain loss 1.5190969705581665\tacc 0.328571\tval loss 1.5273101329803467\tacc 0.438000\n",
      "1787: \ttrain loss 1.2501212358474731\tacc 0.550000\tval loss 1.6432849168777466\tacc 0.338000\n",
      "1788: \ttrain loss 1.2112928628921509\tacc 0.478571\tval loss 1.3803542852401733\tacc 0.552000\n",
      "1789: \ttrain loss 0.9754534959793091\tacc 0.678571\tval loss 1.3740612268447876\tacc 0.536000\n",
      "1790: \ttrain loss 0.8988662362098694\tacc 0.664286\tval loss 1.3595545291900635\tacc 0.538000\n",
      "1791: \ttrain loss 0.7453454732894897\tacc 0.692857\tval loss 1.5291776657104492\tacc 0.574000\n",
      "1792: \ttrain loss 0.6893016695976257\tacc 0.657143\tval loss 2.2822930812835693\tacc 0.448000\n",
      "1793: \ttrain loss 1.6130274534225464\tacc 0.435714\tval loss 2.6453754901885986\tacc 0.346000\n",
      "1794: \ttrain loss 1.3877599239349365\tacc 0.528571\tval loss 1.8250089883804321\tacc 0.448000\n",
      "1795: \ttrain loss 0.7768504023551941\tacc 0.692857\tval loss 1.7213284969329834\tacc 0.460000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1796: \ttrain loss 0.7850291728973389\tacc 0.678571\tval loss 1.7498022317886353\tacc 0.428000\n",
      "1797: \ttrain loss 0.8363560438156128\tacc 0.657143\tval loss 1.5522099733352661\tacc 0.442000\n",
      "1798: \ttrain loss 0.7002217173576355\tacc 0.707143\tval loss 1.4805734157562256\tacc 0.420000\n",
      "1799: \ttrain loss 0.6583678722381592\tacc 0.707143\tval loss 1.620752215385437\tacc 0.384000\n",
      "1800: \ttrain loss 0.6846782565116882\tacc 0.642857\tval loss 1.3400845527648926\tacc 0.420000\n",
      "1801: \ttrain loss 0.5784755349159241\tacc 0.721429\tval loss 1.2768789529800415\tacc 0.478000\n",
      "1802: \ttrain loss 0.5614075064659119\tacc 0.728571\tval loss 1.2571698427200317\tacc 0.638000\n",
      "1803: \ttrain loss 0.5250402688980103\tacc 0.892857\tval loss 1.26291024684906\tacc 0.638000\n",
      "1804: \ttrain loss 0.460785448551178\tacc 0.864286\tval loss 1.1709113121032715\tacc 0.648000\n",
      "1805: \ttrain loss 0.38128504157066345\tacc 0.857143\tval loss 1.1454107761383057\tacc 0.628000\n",
      "1806: \ttrain loss 0.31692254543304443\tacc 0.842857\tval loss 1.159679889678955\tacc 0.626000\n",
      "1807: \ttrain loss 0.2614804804325104\tacc 0.835714\tval loss 1.166748285293579\tacc 0.714000\n",
      "1808: \ttrain loss 0.22090646624565125\tacc 0.942857\tval loss 1.2253955602645874\tacc 0.696000\n",
      "1809: \ttrain loss 0.17369693517684937\tacc 0.964286\tval loss 1.223929762840271\tacc 0.718000\n",
      "1810: \ttrain loss 0.12264654785394669\tacc 0.978571\tval loss 1.4891157150268555\tacc 0.702000\n",
      "1811: \ttrain loss 0.24718593060970306\tacc 0.892857\tval loss 4.259403228759766\tacc 0.330000\n",
      "1812: \ttrain loss 2.3173320293426514\tacc 0.528571\tval loss 7.413336753845215\tacc 0.350000\n",
      "1813: \ttrain loss 3.2796759605407715\tacc 0.614286\tval loss 2.6805646419525146\tacc 0.448000\n",
      "1814: \ttrain loss 0.7492877840995789\tacc 0.678571\tval loss 1.5325359106063843\tacc 0.612000\n",
      "1815: \ttrain loss 0.629043698310852\tacc 0.800000\tval loss 1.317407488822937\tacc 0.672000\n",
      "1816: \ttrain loss 0.6119311451911926\tacc 0.835714\tval loss 1.2356799840927124\tacc 0.620000\n",
      "1817: \ttrain loss 0.6302407383918762\tacc 0.742857\tval loss 1.1376351118087769\tacc 0.646000\n",
      "1818: \ttrain loss 0.5549224019050598\tacc 0.792857\tval loss 1.0350064039230347\tacc 0.692000\n",
      "1819: \ttrain loss 0.41632404923439026\tacc 0.871429\tval loss 0.9723373055458069\tacc 0.734000\n",
      "1820: \ttrain loss 0.29636725783348083\tacc 0.942857\tval loss 1.0205327272415161\tacc 0.724000\n",
      "1821: \ttrain loss 0.22950711846351624\tacc 0.942857\tval loss 1.1155601739883423\tacc 0.722000\n",
      "1822: \ttrain loss 0.22050856053829193\tacc 0.942857\tval loss 1.0095504522323608\tacc 0.774000\n",
      "1823: \ttrain loss 0.16730357706546783\tacc 0.950000\tval loss 0.953921377658844\tacc 0.784000\n",
      "1824: \ttrain loss 0.13268828392028809\tacc 0.964286\tval loss 0.9362107515335083\tacc 0.792000\n",
      "1825: \ttrain loss 0.10812504589557648\tacc 0.964286\tval loss 0.9478771090507507\tacc 0.774000\n",
      "1826: \ttrain loss 0.08772128820419312\tacc 0.971429\tval loss 0.9938113689422607\tacc 0.772000\n",
      "1827: \ttrain loss 0.0755242109298706\tacc 0.978571\tval loss 1.0271927118301392\tacc 0.772000\n",
      "1828: \ttrain loss 0.06151558831334114\tacc 0.992857\tval loss 1.0470854043960571\tacc 0.770000\n",
      "1829: \ttrain loss 0.04721524193882942\tacc 0.985714\tval loss 1.0695894956588745\tacc 0.778000\n",
      "1830: \ttrain loss 0.036457501351833344\tacc 1.000000\tval loss 1.0891999006271362\tacc 0.788000\n",
      "1831: \ttrain loss 0.02645621821284294\tacc 1.000000\tval loss 1.1275662183761597\tacc 0.790000\n",
      "1832: \ttrain loss 0.021454351022839546\tacc 1.000000\tval loss 1.1622493267059326\tacc 0.780000\n",
      "1833: \ttrain loss 0.017924878746271133\tacc 1.000000\tval loss 1.1803382635116577\tacc 0.782000\n",
      "1834: \ttrain loss 0.01586425118148327\tacc 1.000000\tval loss 1.2200852632522583\tacc 0.778000\n",
      "1835: \ttrain loss 0.016140351071953773\tacc 1.000000\tval loss 1.2144454717636108\tacc 0.770000\n",
      "1836: \ttrain loss 0.01481117308139801\tacc 1.000000\tval loss 1.1680545806884766\tacc 0.780000\n",
      "1837: \ttrain loss 0.013932866044342518\tacc 1.000000\tval loss 1.1763249635696411\tacc 0.770000\n",
      "1838: \ttrain loss 0.015046806074678898\tacc 1.000000\tval loss 1.14877188205719\tacc 0.778000\n",
      "1839: \ttrain loss 0.016146788373589516\tacc 1.000000\tval loss 1.142076015472412\tacc 0.778000\n",
      "1840: \ttrain loss 0.017599374055862427\tacc 1.000000\tval loss 1.1585023403167725\tacc 0.778000\n",
      "1841: \ttrain loss 0.0182041022926569\tacc 1.000000\tval loss 1.1212782859802246\tacc 0.784000\n",
      "1842: \ttrain loss 0.01897350884974003\tacc 1.000000\tval loss 1.136810302734375\tacc 0.784000\n",
      "1843: \ttrain loss 0.019685858860611916\tacc 1.000000\tval loss 1.1272671222686768\tacc 0.784000\n",
      "1844: \ttrain loss 0.019872702658176422\tacc 1.000000\tval loss 1.1238677501678467\tacc 0.782000\n",
      "1845: \ttrain loss 0.02053777314722538\tacc 1.000000\tval loss 1.102770209312439\tacc 0.780000\n",
      "1846: \ttrain loss 0.020615337416529655\tacc 1.000000\tval loss 1.086226463317871\tacc 0.776000\n",
      "1847: \ttrain loss 0.021228570491075516\tacc 1.000000\tval loss 1.0954692363739014\tacc 0.784000\n",
      "1848: \ttrain loss 0.021301107481122017\tacc 1.000000\tval loss 1.0852301120758057\tacc 0.786000\n",
      "1849: \ttrain loss 0.021745238453149796\tacc 1.000000\tval loss 1.0850390195846558\tacc 0.784000\n",
      "1850: \ttrain loss 0.02195115201175213\tacc 1.000000\tval loss 1.032233476638794\tacc 0.786000\n",
      "1851: \ttrain loss 0.022768579423427582\tacc 1.000000\tval loss 1.1860610246658325\tacc 0.770000\n",
      "1852: \ttrain loss 0.0284279678016901\tacc 1.000000\tval loss 1.0076887607574463\tacc 0.768000\n",
      "1853: \ttrain loss 0.09202117472887039\tacc 0.964286\tval loss 2.804460048675537\tacc 0.496000\n",
      "1854: \ttrain loss 0.8877959251403809\tacc 0.742857\tval loss 2.103044271469116\tacc 0.536000\n",
      "1855: \ttrain loss 0.949047327041626\tacc 0.721429\tval loss 1.0637859106063843\tacc 0.730000\n",
      "1856: \ttrain loss 0.19930069148540497\tacc 0.935714\tval loss 0.9174187183380127\tacc 0.750000\n",
      "1857: \ttrain loss 0.14105559885501862\tacc 0.950000\tval loss 0.9527769684791565\tacc 0.746000\n",
      "1858: \ttrain loss 0.14124874770641327\tacc 0.964286\tval loss 1.0158045291900635\tacc 0.738000\n",
      "1859: \ttrain loss 0.14760881662368774\tacc 0.957143\tval loss 1.0501165390014648\tacc 0.730000\n",
      "1860: \ttrain loss 0.14378753304481506\tacc 0.971429\tval loss 1.0595027208328247\tacc 0.724000\n",
      "1861: \ttrain loss 0.13806334137916565\tacc 0.971429\tval loss 1.01786208152771\tacc 0.732000\n",
      "1862: \ttrain loss 0.12440712749958038\tacc 0.978571\tval loss 0.9065529108047485\tacc 0.752000\n",
      "1863: \ttrain loss 0.08937393128871918\tacc 0.992857\tval loss 0.8206072449684143\tacc 0.768000\n",
      "1864: \ttrain loss 0.06865435093641281\tacc 1.000000\tval loss 0.7886046767234802\tacc 0.768000\n",
      "1865: \ttrain loss 0.06309831142425537\tacc 0.992857\tval loss 0.7885300517082214\tacc 0.782000\n",
      "1866: \ttrain loss 0.06195808947086334\tacc 0.992857\tval loss 0.8009172677993774\tacc 0.784000\n",
      "1867: \ttrain loss 0.059040676802396774\tacc 0.992857\tval loss 0.8183615803718567\tacc 0.790000\n",
      "1868: \ttrain loss 0.05281566455960274\tacc 0.992857\tval loss 0.8414543271064758\tacc 0.774000\n",
      "1869: \ttrain loss 0.04503603279590607\tacc 1.000000\tval loss 0.8722566366195679\tacc 0.768000\n",
      "1870: \ttrain loss 0.0381004698574543\tacc 1.000000\tval loss 0.9096015095710754\tacc 0.766000\n",
      "1871: \ttrain loss 0.0340137779712677\tacc 1.000000\tval loss 0.9437718391418457\tacc 0.762000\n",
      "1872: \ttrain loss 0.03205784410238266\tacc 1.000000\tval loss 0.9639755487442017\tacc 0.760000\n",
      "1873: \ttrain loss 0.029468396678566933\tacc 1.000000\tval loss 0.9683590531349182\tacc 0.768000\n",
      "1874: \ttrain loss 0.025798974558711052\tacc 1.000000\tval loss 0.9649124145507812\tacc 0.772000\n",
      "1875: \ttrain loss 0.02349700778722763\tacc 1.000000\tval loss 0.9597975611686707\tacc 0.772000\n",
      "1876: \ttrain loss 0.023316897451877594\tacc 1.000000\tval loss 0.9516087174415588\tacc 0.772000\n",
      "1877: \ttrain loss 0.023437675088644028\tacc 1.000000\tval loss 0.9416073560714722\tacc 0.770000\n",
      "1878: \ttrain loss 0.02195938117802143\tacc 1.000000\tval loss 0.9334685802459717\tacc 0.772000\n",
      "1879: \ttrain loss 0.02014702744781971\tacc 1.000000\tval loss 0.9317030310630798\tacc 0.772000\n",
      "1880: \ttrain loss 0.019819701090455055\tacc 1.000000\tval loss 0.9346767663955688\tacc 0.776000\n",
      "1881: \ttrain loss 0.02104094624519348\tacc 1.000000\tval loss 0.9317615032196045\tacc 0.776000\n",
      "1882: \ttrain loss 0.021767396479845047\tacc 1.000000\tval loss 0.9212327003479004\tacc 0.778000\n",
      "1883: \ttrain loss 0.021647408604621887\tacc 1.000000\tval loss 0.9101254940032959\tacc 0.778000\n",
      "1884: \ttrain loss 0.02194284461438656\tacc 1.000000\tval loss 0.9029002785682678\tacc 0.782000\n",
      "1885: \ttrain loss 0.022776855155825615\tacc 1.000000\tval loss 0.9002166390419006\tacc 0.780000\n",
      "1886: \ttrain loss 0.023519091308116913\tacc 1.000000\tval loss 0.9022002816200256\tacc 0.780000\n",
      "1887: \ttrain loss 0.023832203820347786\tacc 1.000000\tval loss 0.9084419012069702\tacc 0.782000\n",
      "1888: \ttrain loss 0.024156810715794563\tacc 1.000000\tval loss 0.9149077534675598\tacc 0.782000\n",
      "1889: \ttrain loss 0.02486797235906124\tacc 1.000000\tval loss 0.9149489998817444\tacc 0.782000\n",
      "1890: \ttrain loss 0.025382550433278084\tacc 1.000000\tval loss 0.9088199138641357\tacc 0.778000\n",
      "1891: \ttrain loss 0.025706693530082703\tacc 1.000000\tval loss 0.9053527116775513\tacc 0.780000\n",
      "1892: \ttrain loss 0.02633695863187313\tacc 1.000000\tval loss 0.9097399711608887\tacc 0.780000\n",
      "1893: \ttrain loss 0.02674952708184719\tacc 1.000000\tval loss 0.9175848960876465\tacc 0.782000\n",
      "1894: \ttrain loss 0.02707008272409439\tacc 1.000000\tval loss 0.9175114631652832\tacc 0.782000\n",
      "1895: \ttrain loss 0.0273700263351202\tacc 1.000000\tval loss 0.907322883605957\tacc 0.782000\n",
      "1896: \ttrain loss 0.027381764724850655\tacc 1.000000\tval loss 0.9017577767372131\tacc 0.782000\n",
      "1897: \ttrain loss 0.027585085481405258\tacc 1.000000\tval loss 0.9072900414466858\tacc 0.782000\n",
      "1898: \ttrain loss 0.02762092649936676\tacc 1.000000\tval loss 0.9124578833580017\tacc 0.780000\n",
      "1899: \ttrain loss 0.02779000625014305\tacc 1.000000\tval loss 0.9049309492111206\tacc 0.782000\n",
      "1900: \ttrain loss 0.02774650603532791\tacc 1.000000\tval loss 0.8936288952827454\tacc 0.786000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1901: \ttrain loss 0.027763497084379196\tacc 1.000000\tval loss 0.8939884305000305\tacc 0.784000\n",
      "1902: \ttrain loss 0.027807816863059998\tacc 1.000000\tval loss 0.9024693965911865\tacc 0.784000\n",
      "1903: \ttrain loss 0.02783001773059368\tacc 1.000000\tval loss 0.9041697382926941\tacc 0.784000\n",
      "1904: \ttrain loss 0.027899429202079773\tacc 1.000000\tval loss 0.894679605960846\tacc 0.788000\n",
      "1905: \ttrain loss 0.027760833501815796\tacc 1.000000\tval loss 0.8878391981124878\tacc 0.788000\n",
      "1906: \ttrain loss 0.027755821123719215\tacc 1.000000\tval loss 0.8916568756103516\tacc 0.788000\n",
      "1907: \ttrain loss 0.027640972286462784\tacc 1.000000\tval loss 0.8963243365287781\tacc 0.786000\n",
      "1908: \ttrain loss 0.02765490859746933\tacc 1.000000\tval loss 0.8907273411750793\tacc 0.786000\n",
      "1909: \ttrain loss 0.027465688064694405\tacc 1.000000\tval loss 0.8855894804000854\tacc 0.786000\n",
      "1910: \ttrain loss 0.027398880571126938\tacc 1.000000\tval loss 0.8902792930603027\tacc 0.786000\n",
      "1911: \ttrain loss 0.027265677228569984\tacc 1.000000\tval loss 0.8941858410835266\tacc 0.786000\n",
      "1912: \ttrain loss 0.02723797969520092\tacc 1.000000\tval loss 0.8883134126663208\tacc 0.786000\n",
      "1913: \ttrain loss 0.027063582092523575\tacc 1.000000\tval loss 0.8845438957214355\tacc 0.786000\n",
      "1914: \ttrain loss 0.026978706941008568\tacc 1.000000\tval loss 0.8895720839500427\tacc 0.786000\n",
      "1915: \ttrain loss 0.026877138763666153\tacc 1.000000\tval loss 0.8920475840568542\tacc 0.786000\n",
      "1916: \ttrain loss 0.026837985962629318\tacc 1.000000\tval loss 0.886683464050293\tacc 0.786000\n",
      "1917: \ttrain loss 0.026699451729655266\tacc 1.000000\tval loss 0.8849035501480103\tacc 0.786000\n",
      "1918: \ttrain loss 0.02663463167846203\tacc 1.000000\tval loss 0.8892382383346558\tacc 0.786000\n",
      "1919: \ttrain loss 0.02659611776471138\tacc 1.000000\tval loss 0.8893843293190002\tacc 0.786000\n",
      "1920: \ttrain loss 0.02655896358191967\tacc 1.000000\tval loss 0.88519686460495\tacc 0.786000\n",
      "1921: \ttrain loss 0.02648773416876793\tacc 1.000000\tval loss 0.8861512541770935\tacc 0.786000\n",
      "1922: \ttrain loss 0.026451094076037407\tacc 1.000000\tval loss 0.8894734978675842\tacc 0.784000\n",
      "1923: \ttrain loss 0.026463106274604797\tacc 1.000000\tval loss 0.886917233467102\tacc 0.784000\n",
      "1924: \ttrain loss 0.026400236412882805\tacc 1.000000\tval loss 0.8837657570838928\tacc 0.784000\n",
      "1925: \ttrain loss 0.026366818696260452\tacc 1.000000\tval loss 0.886342465877533\tacc 0.784000\n",
      "1926: \ttrain loss 0.02635461650788784\tacc 1.000000\tval loss 0.8881387710571289\tacc 0.784000\n",
      "1927: \ttrain loss 0.026339104399085045\tacc 1.000000\tval loss 0.8842345476150513\tacc 0.784000\n",
      "1928: \ttrain loss 0.02629183605313301\tacc 1.000000\tval loss 0.8844475150108337\tacc 0.784000\n",
      "1929: \ttrain loss 0.02628283016383648\tacc 1.000000\tval loss 0.8869063854217529\tacc 0.784000\n",
      "1930: \ttrain loss 0.026299677789211273\tacc 1.000000\tval loss 0.8822885751724243\tacc 0.784000\n",
      "1931: \ttrain loss 0.026260659098625183\tacc 1.000000\tval loss 0.8835519552230835\tacc 0.782000\n",
      "1932: \ttrain loss 0.026227062568068504\tacc 1.000000\tval loss 0.8847767114639282\tacc 0.782000\n",
      "1933: \ttrain loss 0.026213226839900017\tacc 1.000000\tval loss 0.8832646608352661\tacc 0.782000\n",
      "1934: \ttrain loss 0.02616015449166298\tacc 1.000000\tval loss 0.882594883441925\tacc 0.782000\n",
      "1935: \ttrain loss 0.026104383170604706\tacc 1.000000\tval loss 0.8827335834503174\tacc 0.782000\n",
      "1936: \ttrain loss 0.026071401312947273\tacc 1.000000\tval loss 0.8840450048446655\tacc 0.780000\n",
      "1937: \ttrain loss 0.02604096569120884\tacc 1.000000\tval loss 0.8810202479362488\tacc 0.782000\n",
      "1938: \ttrain loss 0.025982016697525978\tacc 1.000000\tval loss 0.8822358846664429\tacc 0.782000\n",
      "1939: \ttrain loss 0.02594275027513504\tacc 1.000000\tval loss 0.8813120722770691\tacc 0.780000\n",
      "1940: \ttrain loss 0.025922631844878197\tacc 1.000000\tval loss 0.8826701641082764\tacc 0.780000\n",
      "1941: \ttrain loss 0.025882581248879433\tacc 1.000000\tval loss 0.8769586086273193\tacc 0.780000\n",
      "1942: \ttrain loss 0.025872979313135147\tacc 1.000000\tval loss 0.8874844908714294\tacc 0.784000\n",
      "1943: \ttrain loss 0.025957560166716576\tacc 1.000000\tval loss 0.8735337257385254\tacc 0.780000\n",
      "1944: \ttrain loss 0.02605360560119152\tacc 1.000000\tval loss 0.8907711505889893\tacc 0.782000\n",
      "1945: \ttrain loss 0.026230523362755775\tacc 1.000000\tval loss 0.8724216818809509\tacc 0.780000\n",
      "1946: \ttrain loss 0.026014085859060287\tacc 1.000000\tval loss 0.881663978099823\tacc 0.784000\n",
      "1947: \ttrain loss 0.025792114436626434\tacc 1.000000\tval loss 0.8829666972160339\tacc 0.782000\n",
      "1948: \ttrain loss 0.02584048919379711\tacc 1.000000\tval loss 0.8715156316757202\tacc 0.782000\n",
      "1949: \ttrain loss 0.025930698961019516\tacc 1.000000\tval loss 0.8836080431938171\tacc 0.782000\n",
      "1950: \ttrain loss 0.025876637548208237\tacc 1.000000\tval loss 0.8770296573638916\tacc 0.784000\n",
      "1951: \ttrain loss 0.025712724775075912\tacc 1.000000\tval loss 0.8715060949325562\tacc 0.782000\n",
      "1952: \ttrain loss 0.025791391730308533\tacc 1.000000\tval loss 0.8840612769126892\tacc 0.782000\n",
      "1953: \ttrain loss 0.02590549923479557\tacc 1.000000\tval loss 0.8735740184783936\tacc 0.778000\n",
      "1954: \ttrain loss 0.025734374299645424\tacc 1.000000\tval loss 0.8727678656578064\tacc 0.780000\n",
      "1955: \ttrain loss 0.025676192715764046\tacc 1.000000\tval loss 0.8791881203651428\tacc 0.784000\n",
      "1956: \ttrain loss 0.025817103683948517\tacc 1.000000\tval loss 0.8703300952911377\tacc 0.784000\n",
      "1957: \ttrain loss 0.025790326297283173\tacc 1.000000\tval loss 0.8759786486625671\tacc 0.782000\n",
      "1958: \ttrain loss 0.02571185864508152\tacc 1.000000\tval loss 0.873263955116272\tacc 0.782000\n",
      "1959: \ttrain loss 0.025687847286462784\tacc 1.000000\tval loss 0.8676016926765442\tacc 0.780000\n",
      "1960: \ttrain loss 0.025748327374458313\tacc 1.000000\tval loss 0.8764894008636475\tacc 0.782000\n",
      "1961: \ttrain loss 0.02580062858760357\tacc 1.000000\tval loss 0.8685206174850464\tacc 0.776000\n",
      "1962: \ttrain loss 0.025683831423521042\tacc 1.000000\tval loss 0.8679733276367188\tacc 0.776000\n",
      "1963: \ttrain loss 0.025672702118754387\tacc 1.000000\tval loss 0.8739907741546631\tacc 0.780000\n",
      "1964: \ttrain loss 0.025762761011719704\tacc 1.000000\tval loss 0.8663333654403687\tacc 0.782000\n",
      "1965: \ttrain loss 0.025734540075063705\tacc 1.000000\tval loss 0.8695947527885437\tacc 0.782000\n",
      "1966: \ttrain loss 0.02569073997437954\tacc 1.000000\tval loss 0.8679975867271423\tacc 0.780000\n",
      "1967: \ttrain loss 0.025666866451501846\tacc 1.000000\tval loss 0.8654814958572388\tacc 0.778000\n",
      "1968: \ttrain loss 0.02568911761045456\tacc 1.000000\tval loss 0.8700303435325623\tacc 0.778000\n",
      "1969: \ttrain loss 0.025728613138198853\tacc 1.000000\tval loss 0.8631986975669861\tacc 0.780000\n",
      "1970: \ttrain loss 0.025669021531939507\tacc 1.000000\tval loss 0.8666540384292603\tacc 0.780000\n",
      "1971: \ttrain loss 0.025649795308709145\tacc 1.000000\tval loss 0.8656901717185974\tacc 0.780000\n",
      "1972: \ttrain loss 0.02563077211380005\tacc 1.000000\tval loss 0.8622642159461975\tacc 0.774000\n",
      "1973: \ttrain loss 0.025622673332691193\tacc 1.000000\tval loss 0.8660100102424622\tacc 0.778000\n",
      "1974: \ttrain loss 0.025649884715676308\tacc 1.000000\tval loss 0.8616769313812256\tacc 0.782000\n",
      "1975: \ttrain loss 0.025628715753555298\tacc 1.000000\tval loss 0.8648839592933655\tacc 0.778000\n",
      "1976: \ttrain loss 0.025616712868213654\tacc 1.000000\tval loss 0.8611534833908081\tacc 0.780000\n",
      "1977: \ttrain loss 0.025576015934348106\tacc 1.000000\tval loss 0.862228512763977\tacc 0.778000\n",
      "1978: \ttrain loss 0.0255724024027586\tacc 1.000000\tval loss 0.8618708848953247\tacc 0.778000\n",
      "1979: \ttrain loss 0.025565894320607185\tacc 1.000000\tval loss 0.8592076301574707\tacc 0.782000\n",
      "1980: \ttrain loss 0.02555679902434349\tacc 1.000000\tval loss 0.8626936078071594\tacc 0.778000\n",
      "1981: \ttrain loss 0.02558388188481331\tacc 1.000000\tval loss 0.8577107191085815\tacc 0.782000\n",
      "1982: \ttrain loss 0.02555709145963192\tacc 1.000000\tval loss 0.8613601922988892\tacc 0.778000\n",
      "1983: \ttrain loss 0.025566289201378822\tacc 1.000000\tval loss 0.8562394976615906\tacc 0.782000\n",
      "1984: \ttrain loss 0.025528663769364357\tacc 1.000000\tval loss 0.8598436713218689\tacc 0.778000\n",
      "1985: \ttrain loss 0.025528689846396446\tacc 1.000000\tval loss 0.8564902544021606\tacc 0.782000\n",
      "1986: \ttrain loss 0.025490961968898773\tacc 1.000000\tval loss 0.856539785861969\tacc 0.782000\n",
      "1987: \ttrain loss 0.02548559196293354\tacc 1.000000\tval loss 0.8570305109024048\tacc 0.780000\n",
      "1988: \ttrain loss 0.025486944243311882\tacc 1.000000\tval loss 0.8544397950172424\tacc 0.786000\n",
      "1989: \ttrain loss 0.025475570932030678\tacc 1.000000\tval loss 0.8585618138313293\tacc 0.778000\n",
      "1990: \ttrain loss 0.025509903207421303\tacc 1.000000\tval loss 0.8526090383529663\tacc 0.788000\n",
      "1991: \ttrain loss 0.025487447157502174\tacc 1.000000\tval loss 0.8574203848838806\tacc 0.778000\n",
      "1992: \ttrain loss 0.025518784299492836\tacc 1.000000\tval loss 0.8511918783187866\tacc 0.792000\n",
      "1993: \ttrain loss 0.025476867333054543\tacc 1.000000\tval loss 0.8573319315910339\tacc 0.778000\n",
      "1994: \ttrain loss 0.025499878451228142\tacc 1.000000\tval loss 0.8507878184318542\tacc 0.788000\n",
      "1995: \ttrain loss 0.025436295196413994\tacc 1.000000\tval loss 0.8533658981323242\tacc 0.780000\n",
      "1996: \ttrain loss 0.02542942389845848\tacc 1.000000\tval loss 0.8515284061431885\tacc 0.786000\n",
      "1997: \ttrain loss 0.025401491671800613\tacc 1.000000\tval loss 0.851496696472168\tacc 0.786000\n",
      "1998: \ttrain loss 0.025393683463335037\tacc 1.000000\tval loss 0.8525828719139099\tacc 0.780000\n",
      "1999: \ttrain loss 0.025399954989552498\tacc 1.000000\tval loss 0.8484190106391907\tacc 0.788000\n",
      "2000: \ttrain loss 0.02538667991757393\tacc 1.000000\tval loss 0.8527677059173584\tacc 0.780000\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "num_epochs = parameters['num_epochs']\n",
    "A = A.to(device)\n",
    "model = Net(parameters['features'], parameters['body'], parameters['classes'], 4, F.relu, bias=True).to(device)\n",
    "input_features = data.x.to(device)\n",
    "train_labels = train_labels.to(device)\n",
    "val_labels = val_labels.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "train_mask = data.train_mask.to(device)\n",
    "val_mask = data.val_mask.to(device)\n",
    "test_mask = data.test_mask.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=parameters['learning_rate'], weight_decay=parameters['weight_decay'])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    train_pred = model(input_features, A)\n",
    "    train_loss = criterion(train_pred, train_labels)\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    train_acc = masked_accuracy(train_pred, train_labels, train_mask)\n",
    "    \n",
    "    model.eval()\n",
    "    val_pred = model(input_features, A)\n",
    "    val_loss = criterion(val_pred, val_labels)\n",
    "    val_acc = masked_accuracy(val_pred, val_labels, val_mask)\n",
    "    print(\"{}: \\ttrain loss {}\\tacc {:2f}\\tval loss {}\\tacc {:2f}\".format(epoch, train_loss, train_acc, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.789\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_pred = model(input_features, A)\n",
    "test_acc = masked_accuracy(test_pred, test_labels, test_mask)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9981912556264169"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A==0).sum().item() / torch.numel(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = (data.y[data.train_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_mask.sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Device 67df'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2236, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
