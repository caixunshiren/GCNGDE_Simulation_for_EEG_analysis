{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make boxes window width. \n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd.functional import vjp\n",
    "import time\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Block, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.bnorm = torch.nn.BatchNorm2d(in_channels)\n",
    "    def forward(self, x, t, net_params):\n",
    "        size = x.size()\n",
    "        x = self.bnorm(x)\n",
    "        x = F.relu(F.conv2d(x, net_params[0:9*size[1]*size[1]].view(size[1],size[1],3,3), padding=1))\n",
    "        x = F.conv2d(x, net_params[9*size[1]*size[1]:18*size[1]*size[1]].view(size[1],size[1],3,3), padding=1)\n",
    "        return x #self.bnorm(x)\n",
    "    def num_params(self):\n",
    "        num_conv = self.in_channels * self.in_channels * 9 * 2\n",
    "        return num_conv\n",
    "    \n",
    "class BigBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(BigBlock, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "    def forward(self, x, t, net_params):\n",
    "        bsize = x.size(1)\n",
    "        tk = 9 * bsize * bsize\n",
    "        \n",
    "        # First resnet block\n",
    "        x1 = F.relu(F.conv2d(x, net_params[0:1*tk].view(bsize,bsize,3,3), padding=1))\n",
    "        x2 = x + F.relu(F.conv2d(x1, net_params[1*tk:2*tk].view(bsize,bsize,3,3), padding=1))\n",
    "        \n",
    "        x1 = F.relu(F.conv2d(x, net_params[2*tk:3*tk].view(bsize,bsize,3,3), padding=1))\n",
    "        x2 = x2 + F.relu(F.conv2d(x1, net_params[3*tk:4*tk].view(bsize,bsize,3,3), padding=1))\n",
    "        \n",
    "        x1 = F.relu(F.conv2d(x, net_params[4*tk:5*tk].view(bsize,bsize,3,3), padding=1))\n",
    "        x2 = x2 + F.relu(F.conv2d(x1, net_params[5*tk:6*tk].view(bsize,bsize,3,3), padding=1))\n",
    "        \n",
    "        x1 = F.relu(F.conv2d(x, net_params[6*tk:7*tk].view(bsize,bsize,3,3), padding=1))\n",
    "        x2 = x2 + F.relu(F.conv2d(x1, net_params[7*tk:8*tk].view(bsize,bsize,3,3), padding=1))\n",
    "        \n",
    "        return x2\n",
    "    \n",
    "    def num_params(self):\n",
    "        return self.in_channels * self.in_channels * 9 * 8\n",
    " \n",
    "\n",
    "class BigBlockClone(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(BigBlockClone, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        \n",
    "    def forward(self, x, t, net_params):\n",
    "        size = x.size()\n",
    "        x1 = F.relu(self.conv1(x))\n",
    "        x2 = x + F.relu(self.conv2(x1))\n",
    "        x3 = F.relu(self.conv3(x2))\n",
    "        x4 = x2 + F.relu(self.conv4(x3))\n",
    "        \n",
    "        return x4\n",
    "    \n",
    "    def num_params(self):\n",
    "        return self.in_channels * self.in_channels * 9 * 4\n",
    "    \n",
    "    \n",
    "class DepthWise(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DepthWise, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def forward(self, x, t, net_params):\n",
    "        size = x.size()\n",
    "        x1 = F.conv2d(x, net_params[0:1*9*size[1]*1].view(size[1],1,3,3), padding=1, groups=size[1])\n",
    "        x1 = F.relu(F.conv2d(x, net_params[4*9*size[1]*1:4*9*size[1]*1 + size[1]*size[1]].view(size[1],size[1],1,1), padding=0))\n",
    "        \n",
    "        x2 = F.conv2d(x1, net_params[1*9*size[1]*1:2*9*size[1]*1].view(size[1],1,3,3), padding=1, groups=size[1])\n",
    "        x2 = x + F.relu(F.conv2d(x2, net_params[4*9*size[1]*1 + size[1]*size[1]: 4*9*size[1]*1 + size[1]*size[1]*2].view(size[1],size[1],1,1), padding=0))\n",
    "        \n",
    "        x3 = F.conv2d(x2, net_params[2*9*size[1]*1:3*9*size[1]*1].view(size[1],1,3,3), padding=1, groups=size[1])\n",
    "        x3 = F.relu(F.conv2d(x3, net_params[4*9*size[1]*1 + size[1]*size[1]*2:4*9*size[1]*1 + size[1]*size[1]*3].view(size[1],size[1],1,1), padding=0))\n",
    "        \n",
    "        x4 = F.conv2d(x3, net_params[3*9*size[1]*1:4*9*size[1]*1].view(size[1],1,3,3), padding=1, groups=size[1])\n",
    "        x4 = x2 + F.relu(F.conv2d(x4, net_params[4*9*size[1]*1 + size[1]*size[1]*3:4*9*size[1]*1 + size[1]*size[1]*4].view(size[1],size[1],1,1), padding=0))\n",
    "        return x4\n",
    "    def num_params(self):\n",
    "        return(self.in_channels * 9 * 4 + self.in_channels * self.in_channels * 1 * 4)\n",
    "        \n",
    "class DepthwiseClone(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DepthwiseClone, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.conv1a = nn.Conv2d(in_channels, in_channels, 3, groups=in_channels, padding=1)\n",
    "        self.conv1b = nn.Conv2d(in_channels, in_channels, 1)\n",
    "        \n",
    "        self.conv2a = nn.Conv2d(in_channels, in_channels, 3, groups=in_channels, padding=1)\n",
    "        self.conv2b = nn.Conv2d(in_channels, in_channels, 1)\n",
    "        \n",
    "        self.conv3a = nn.Conv2d(in_channels, in_channels, 3, groups=in_channels, padding=1)\n",
    "        self.conv3b = nn.Conv2d(in_channels, in_channels, 1)\n",
    "        \n",
    "        self.conv4a = nn.Conv2d(in_channels, in_channels, 3, groups=in_channels, padding=1)\n",
    "        self.conv4b = nn.Conv2d(in_channels, in_channels, 1)\n",
    "        \n",
    "    def forward(self, x, t, net_params):\n",
    "        \n",
    "        x1 = F.relu(self.conv1b(self.conv1a(x)))\n",
    "        x2 = x + F.relu(self.conv2b(self.conv2a(x1)))\n",
    "        \n",
    "        x3 = F.relu(self.conv3b(self.conv3a(x2)))\n",
    "        x4 = x2 + F.relu(self.conv4b(self.conv4a(x3)))\n",
    "        \n",
    "        return x4\n",
    "    \n",
    "    def num_params(self):\n",
    "        return(self.in_channels * 9 * 4 + self.in_channels * self.in_channels * 1 * 4)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RK4 = ((  0,),\n",
    "       (1/2, 1/2,),\n",
    "       (1/2,   0,  1/2,),\n",
    "       (  1,   0,    0,   1,),\n",
    "       (1/6, 1/3, 1/3, 1/6,))\n",
    "\n",
    "EF = ((0,),\n",
    "      (1,))\n",
    "\n",
    "\"\"\"\n",
    "General Runge-Kutta Solver.\n",
    "https://en.wikipedia.org/wiki/Rungeâ€“Kutta_methods\n",
    "\n",
    "b_tableau, nested tuple, contains weights of integration. \n",
    "f, function, is the function to iterate. Should only be a function of x, t. \n",
    "x0, torch.Tensor, is the intial condition.\n",
    "t0, torch.Tensor, is the start time of integration.\n",
    "t1, torch.Tensor, is the end time of integration.\n",
    "N, int, is the desired number of timesteps.\n",
    "\n",
    "returns x, torch.Tensor, estimated solution of dy/dx = f(x,t) at time t1. \n",
    "\"\"\"\n",
    "\n",
    "def explicit_RK(b_tableau, f, x0, t0, t1, N):        \n",
    "    h = (t1 - t0) / float(N) # calculate step size\n",
    "    x = x0 # initialize saved dynamics\n",
    "    mesh = (t0 + h * i for i in range(N)) # generator of time values\n",
    "    for time in mesh:\n",
    "        \n",
    "        k = [f(x, time + h*b_tableau[0][0])] # Covers the first row of the Butcher tableau. \n",
    "        for i, row in enumerate(b_tableau[1:-1]): # Covers the middle rows of the Butcher tableau.\n",
    "            k.append(f(x + sum(w * k[idx] * h for idx, w in enumerate(row[1:])), time + row[0] * h)) # calculate k's. \n",
    "        x = x + sum(w * k_i * h for k_i, w in zip(k, b_tableau[-1])) # calculate timestep \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenience tuple -> tensor function\n",
    "def flatten(*args):\n",
    "    return(torch.cat(tuple(torch.flatten(arg) for arg in args), dim=0).view(1,-1))\n",
    "\n",
    "# Convenience tensor -> tuple function\n",
    "def unflatten(x, n_e, sizes):\n",
    "    return (x[0, 0:n_e[0]].view(sizes[0]),\n",
    "            x[0, n_e[0]:n_e[0] + n_e[1]].view(sizes[1]),\n",
    "            x[0, (n_e[0] + n_e[1]):(n_e[0] + n_e[1] + n_e[2])].view(sizes[2]),\n",
    "            x[0, (n_e[0] + n_e[1] + n_e[2]):].view(sizes[3]),\n",
    "            )\n",
    "\n",
    "class Integrate(torch.autograd.Function):\n",
    "    def __deepcopy__(self, memo):\n",
    "        return Integrate(copy.deepcopy(memo))\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, Integrator, f, x0, t0, t1, N, net_params):\n",
    "                \n",
    "        solution = Integrator(EF, lambda x, t: f(x, t, net_params), x0, t0, t1, N)\n",
    "            \n",
    "        # Save for jacobian calculations in backward()\n",
    "        ctx.save_for_backward(x0,t0,t1,net_params)\n",
    "        ctx.solution = solution\n",
    "        ctx.Integrator = Integrator\n",
    "        ctx.N = N\n",
    "        ctx.f = f\n",
    "        \n",
    "        return solution\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, dL_dz1):\n",
    "        # Get all saved context\n",
    "        z0, t0, t1, net_params = ctx.saved_tensors\n",
    "        z1 = ctx.solution\n",
    "        N = ctx.N\n",
    "        f = ctx.f\n",
    "        \n",
    "        # Convenience sizes\n",
    "        batch_size = z0.size()[0]\n",
    "        img_len = int(z0.numel() / batch_size)\n",
    "\n",
    "        # Compute derivative w.r.t. to end time of integration\n",
    "        dL_dt1 = dL_dz1.view(batch_size,1,-1).bmm(f(z1, t1, net_params).view(batch_size,-1,1))  # Derivative of loss w.r.t t1\n",
    "        \n",
    "        #print(\"dL_dt1\", dL_dt1)\n",
    "        \n",
    "        # Initial Condition\n",
    "        num_elements = (z1.numel(), dL_dz1.numel(), batch_size * net_params.numel(), dL_dt1.numel())\n",
    "        sizes = (z1.size(), dL_dz1.size(), (batch_size, net_params.numel()), dL_dt1.size())\n",
    "        s0 = flatten(z1, dL_dz1, torch.zeros((batch_size, net_params.numel()), dtype=torch.float32), -dL_dt1) # initial augmented state\n",
    "        \n",
    "        # augmented dynamics function\n",
    "        def aug_dynamics(s, t, theta):\n",
    "            s = unflatten(s, num_elements, sizes)\n",
    "            \n",
    "            with torch.enable_grad(): \n",
    "                gradients = [vjp(f, \n",
    "                                 (s[0][i].unsqueeze(0), t, theta), \n",
    "                                  v=-s[1][i].unsqueeze(0),\n",
    "                                 )[1] for i in range(batch_size)]\n",
    "                \n",
    "            return flatten(f(s[0],t,theta),\n",
    "                    torch.cat([gradient[0] for gradient in gradients], dim=0), \n",
    "                    torch.cat([gradient[2].unsqueeze(0) for gradient in gradients], dim=0), \n",
    "                    torch.cat([gradient[1].reshape(1,1) for gradient in gradients], dim=0),\n",
    "                   )#.unsqueeze(2)\n",
    "\n",
    "        # Integrate backwards\n",
    "        with torch.enable_grad():\n",
    "            s = ctx.Integrator(EF, lambda x, t: aug_dynamics(x, t, net_params), s0, t1, t0, N)\n",
    "        \n",
    "        # Extract derivatives\n",
    "        _, dL_dz0, dL_dtheta, dL_dt0 = unflatten(s, num_elements, sizes)\n",
    "        \n",
    "        # must return something for every input to forward, None for non-tensors\n",
    "        return None, None, dL_dz0, dL_dt0, dL_dt1, None, dL_dtheta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODENet(nn.Module):\n",
    "    def __init__(self, solver, f, in_channels, body_channels, solver_params):\n",
    "        super(ODENet, self).__init__()\n",
    "                \n",
    "        # Controls amount of parameters\n",
    "        self.body_channels = body_channels\n",
    "        \n",
    "        # Head, used to mix stuff around and improve accuracy\n",
    "        mid_channels = body_channels // 2 if body_channels // 2 > in_channels else body_channels\n",
    "        self.conv1 = nn.Conv2d(in_channels, mid_channels, 5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(mid_channels, self.body_channels, 5, padding=2)\n",
    "        \n",
    "        self.f = f(body_channels, body_channels)\n",
    "        \n",
    "        # Body\n",
    "        self.int_f = solver\n",
    "        self.Integrate = Integrate\n",
    "        self.solver_params = solver_params\n",
    "        self.N = solver_params[\"N\"]\n",
    "        self.h = (solver_params[\"t1\"] - solver_params[\"t0\"]) / solver_params[\"N\"]\n",
    "        self.t0 = torch.tensor(float(solver_params[\"t0\"]), requires_grad=True)\n",
    "        self.t1 = torch.tensor(float(solver_params[\"t1\"]), requires_grad=True)\n",
    "        \n",
    "        self.net_params = torch.nn.parameter.Parameter(torch.Tensor(self.f.num_params()).normal_(mean=0, std=0.1,generator=None), requires_grad=True)\n",
    "\n",
    "        # Tails\n",
    "        \n",
    "        #self.avg_pool = torch.nn.MaxPool2d(2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(int(img_size*img_size* self.body_channels), 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv2(F.relu(self.conv1(x))) #initial dimensionality expansion\n",
    "        x = self.Integrate.apply(self.int_f, self.f, x, self.t0, self.t1, self.N, self.net_params) # Vanilla RK4\n",
    "        #x = self.avg_pool(x)\n",
    "        x = x.view(-1, int(img_size * img_size * self.body_channels)) ##/ 4))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_loader, test_loader, hyperparameters):\n",
    "    \n",
    "    lr = hyperparameters[\"lr\"]\n",
    "    n_epochs = hyperparameters[\"n_epochs\"]\n",
    "    momentum = hyperparameters[\"momentum\"]\n",
    "    weight_decay = hyperparameters[\"weight_decay\"]\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    \n",
    "    losses = []\n",
    "    for i in range(n_epochs):\n",
    "        \n",
    "        # Train\n",
    "        net.train()\n",
    "        train_losses = []\n",
    "        train_num_correct = 0\n",
    "        for j, (data, label) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #data = torch.cat((data, torch.zeros(data.size()), torch.zeros(data.size())), dim=1)\n",
    "            output = net(data) #augmented nodes\n",
    "            loss = F.nll_loss(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "            train_num_correct += label.eq(torch.max(output, 1, keepdim=False, out=None).indices).sum()        \n",
    "        \n",
    "        \n",
    "        num_correct, test_losses = test(net, test_loader)\n",
    "        losses.append([train_losses, test_losses])\n",
    "        \n",
    "        # Report\n",
    "        print(\n",
    "          \"Avg Train Loss\", sum(train_losses)/len(train_losses), \"\\n\",\n",
    "        \"Train Accuracy\", (train_num_correct / float(len(train_loader.dataset)) * 100).item(), \"%\\n\",\n",
    "          \"Avg Test Loss\", sum(test_losses)/len(test_losses), \"\\n\",\n",
    "          \"Test Accuracy\", (num_correct / float(len(test_loader.dataset)) * 100).item(), \"%\"\n",
    "         )\n",
    "        print(\"----------------------------------------\")\n",
    "        \n",
    "    return losses    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, test_loader):\n",
    "    # Test\n",
    "    net.eval()\n",
    "    test_losses = []\n",
    "    num_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for j, (data, label) in enumerate(test_loader):\n",
    "            #data = torch.cat((data, torch.zeros(data.size()), torch.zeros(data.size())), dim=1)\n",
    "            output = net(data)\n",
    "            loss = F.nll_loss(output, label)\n",
    "            test_losses.append(loss.item())\n",
    "            num_correct += label.eq(torch.max(output, 1, keepdim=False, out=None).indices).sum()\n",
    "\n",
    "    \n",
    "    return num_correct, test_losses "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the dataset can be loaded. I am pretty sure that this script will work for any image dataset. Make sure to change the batch sizes and image sizes to avoid running out of memory. On my computer, this script takes 8 gigs of my actual memory and 20 gigs swap, which is huge, but I have experienced vanishing gradients with 1-batch size training runs. I will do a hyperparameter search, and am working on that script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbatch_size_train = 64\\nbatch_size_test = 64\\nimg_size = 32\\nimg_len = 32 * 32\\n\\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True,\\n                                        download=True, transform=torchvision.transforms.Compose([\\n                                            torchvision.transforms.Pad(4),\\n                                            torchvision.transforms.RandomCrop(32),\\n                                            torchvision.transforms.RandomHorizontalFlip(p=0.5),\\n                                            torchvision.transforms.ToTensor(),\\n                                            torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\\n\\ntrain_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size_train, shuffle=True, num_workers=2)\\n\\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False,\\n                                       download=True, transform=torchvision.transforms.Compose([\\n                                           torchvision.transforms.ToTensor(),\\n                                           torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\\n\\ntest_loader = torch.utils.data.DataLoader(testset, batch_size= batch_size_test, shuffle=False, num_workers=2)\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "img_size = 28\n",
    "img_len = 784\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/Users/louis/Desktop/neuralODE/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/Users/louis/Desktop/neuralODE/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)\n",
    "\"\"\"\n",
    "batch_size_train = 64\n",
    "batch_size_test = 64\n",
    "img_size = 32\n",
    "img_len = 32 * 32\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=torchvision.transforms.Compose([\n",
    "                                            torchvision.transforms.Pad(4),\n",
    "                                            torchvision.transforms.RandomCrop(32),\n",
    "                                            torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                            torchvision.transforms.ToTensor(),\n",
    "                                            torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size_train, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=torchvision.transforms.Compose([\n",
    "                                           torchvision.transforms.ToTensor(),\n",
    "                                           torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size= batch_size_test, shuffle=False, num_workers=2)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where the hyperparameters for training are controlled, and the solver parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"lr\":  0.01,\n",
    "    \"n_epochs\": 30,\n",
    "    \"momentum\": 0.5,\n",
    "    \"weight_decay\": 0.0,\n",
    "}\n",
    "\n",
    "solver_params = {\n",
    "    \"t0\": 0,\n",
    "    \"t1\": 1,\n",
    "    \"N\": 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss nan \n",
      " Train Accuracy 9.873333930969238 %\n",
      " Avg Test Loss nan \n",
      " Test Accuracy 9.800000190734863 %\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-dec2ea61cf3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mTestNetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mODENet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexplicit_RK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBigBlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTestNetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTestNetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"testgensolver2.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-27bee8ab658d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_loader, test_loader, hyperparameters)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#augmented nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TestNetwork = ODENet(explicit_RK, BigBlock, 1, 64, solver_params).to(device)\n",
    "losses = train(TestNetwork, train_loader, test_loader, hyperparameters)\n",
    "torch.save(TestNetwork.state_dict(), \"testgensolver2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "TestNetwork2 = ODENet(explicit_RK, Block, 1, 3, solver_params).to(device)\n",
    "#TestNetwork.load_state_dict(torch.load(\"testgensolver.pth\"))\n",
    "print(\"ODENet\", count_parameters(TestNetwork2), \"parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I convert the Block module from above into one that uses convolutions from the torch.nn package. Since most external packages are made to work with torch.nn, this is convenient for working with MemTorch or torch.nn.quantized. After you make this switch, the backwards pass code will no longer work, so this only works for inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Conversion to something MemTorch & Pytorch's quantization can handle. \n",
    "\"\"\"\n",
    "\n",
    "class Block_nn(nn.Module):\n",
    "    def __init__(self, in_channels, body_channels):\n",
    "        super(Block_nn, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.conv1 = nn.Conv2d(TestNetwork.body_channels, TestNetwork.body_channels, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(TestNetwork.body_channels, TestNetwork.body_channels, 3, padding=1)\n",
    "    def forward(self, x, t, net_params):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        return x\n",
    "    def num_params(self):\n",
    "        return self.in_channels * self.in_channels * 9 * 2\n",
    "\n",
    "qnet = ODENet(explicit_RK, Block_nn, 1, 3, solver_params)\n",
    "sz = qnet.body_channels\n",
    "qnet.f.conv1.weight = nn.Parameter(TestNetwork.net_params[0:9*sz*sz].view(sz,sz,3,3))\n",
    "qnet.f.conv2.weight = nn.Parameter(TestNetwork.net_params[9*sz*sz:18*sz*sz].view(sz,sz,3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memtorch.mn.Module import patch_model\n",
    "from memtorch.map.Parameter import naive_map\n",
    "from memtorch.bh.crossbar.Program import naive_program\n",
    "from memtorch.bh.nonideality.NonIdeality import apply_nonidealities\n",
    "import memtorch\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_memristor = memtorch.bh.memristor.VTEAM\n",
    "reference_memristor_params = {'time_series_resolution': 1e-10, \n",
    "                              'r_off': memtorch.bh.StochasticParameter(200, std=20, min=2),\n",
    "                              'r_on': memtorch.bh.StochasticParameter(100, std=10, min=1)}\n",
    "memristor = reference_memristor(**reference_memristor_params)\n",
    "memristor.plot_hysteresis_loop()\n",
    "\n",
    "patched_model = patch_model(copy.deepcopy(TestNetwork),\n",
    "                          memristor_model=reference_memristor,\n",
    "                          memristor_model_params=reference_memristor_params,\n",
    "                          module_parameters_to_patch=[torch.nn.Linear, torch.nn.Conv2d],\n",
    "                          mapping_routine=naive_map,\n",
    "                          transistor=True,\n",
    "                          programming_routine=None)\n",
    "\n",
    "patched_model.tune_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "for i in range(250, 10, -20):\n",
    "    model = apply_nonidealities(copy.deepcopy(patched_model),\n",
    "                                      non_idealities=[memtorch.bh.nonideality.NonIdeality.FiniteConductanceStates],\n",
    "                                      conductance_states = i)\n",
    "    accuracy.append((test(model, test_loader)[0] / float(len(test_loader.dataset))).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(250, 10, -20)), accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = apply_nonidealities(copy.deepcopy(patched_model),\n",
    "                                      non_idealities=[memtorch.bh.nonideality.NonIdeality.FiniteConductanceStates],\n",
    "                                      conductance_states = 1024)\n",
    "print((test(model, test_loader)[0] / float(len(test_loader.dataset))).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
