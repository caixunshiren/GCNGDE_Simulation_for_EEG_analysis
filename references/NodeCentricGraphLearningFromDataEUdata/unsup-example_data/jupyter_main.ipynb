{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "    edf loading settings. Offset: 2996.000000, Length:s 40.000000\n",
      "    win_len_sec: 2.500000 , num_windows: 2399\n",
      "    edf loading settings. Offset: 1467.000000, Length:s 27.000000\n",
      "    win_len_sec: 2.500000 , num_windows: 2399\n",
      "    edf loading settings. Offset: 1732.000000, Length:s 40.000000\n",
      "    win_len_sec: 2.500000 , num_windows: 2399\n",
      "    edf loading settings. Offset: 1015.000000, Length:s 51.000000\n",
      "    win_len_sec: 2.500000 , num_windows: 2399\n",
      "    edf loading settings. Offset: 1720.000000, Length:s 90.000000\n",
      "    win_len_sec: 2.500000 , num_windows: 2399\n",
      "    edf loading settings. Offset: 199.000000, Length:s 93.000000\n",
      "    win_len_sec: 2.500000 , num_windows: 2399\n",
      "    edf loading settings. Offset: 966.000000, Length:s 101.000000\n",
      "    win_len_sec: 2.500000 , num_windows: 1549\n",
      "    X (15943, 23, 381) y (15943,)\n",
      "    time elapsed:  69.41600012779236\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import namedtuple\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from graphsage.Graph_Learning_utils import Hybrid_Rep_Feat\n",
    "from supervised_tasks import FFT, data_load\n",
    "import gc\n",
    "\n",
    "\n",
    "\n",
    "TaskCore = namedtuple('TaskCore', ['data_dir', 'target', 'classifier', 'normalize', 'cv_ratio'])\n",
    "\n",
    "GraphLCore = namedtuple('GraphLCore', ['model_size', 'num_nodes', 'dim', 'fixed_params','aggregator_type',\\\n",
    "                                       'concat','num_layers', 'coordinate_gradient', 'projected_gradient',\\\n",
    "                                       'conv_sizes'])\n",
    "ClassifCore = namedtuple('ClassifCore', ['num_samples','classifier','epochs','learning_rate', 'n_hidden_1','n_hidden_2', \\\n",
    "                                         'num_classes','max_total_steps','print_every','batch_size','loss_type', 'A_proj_th'])\n",
    "LoadCore = namedtuple('ClassifCore', ['howmany_to_load', 'num_windows', 'sampling_freq', 'data_conversions',\\\n",
    "                                       'num_classes', 'train_test', 'start_num', 'concat', 'down_sampl_ratio',\n",
    "                                       'freq_bands', 'initial_freq_band', 'only_seizures', 'welchs_win_len','welchs_stride'])\n",
    "\n",
    "with open('SETTINGS.json') as f:\n",
    "    settings = json.load(f)\n",
    "\n",
    "data_dir = str(settings['data-dir'])\n",
    "target = 'chb01'\n",
    "cv_ratio = 0.5\n",
    "\n",
    "def should_normalize(classifier):\n",
    "    clazzes = [LogisticRegression]\n",
    "    return np.any(np.array([isinstance(classifier, clazz) for clazz in clazzes]) == True)\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=3000, min_samples_split=1, bootstrap=False, n_jobs=4, random_state=0)\n",
    "task_core = TaskCore(data_dir=data_dir, target=target, classifier=classifier, \n",
    "                     normalize=should_normalize(classifier), cv_ratio=cv_ratio)\n",
    "\n",
    "\n",
    "\n",
    "train_num_sample = 8\n",
    "test_num_sample = 4\n",
    "weight_losses = 1\n",
    "num_classes = 2\n",
    "epochs = 10\n",
    "learning_rate = 0.01\n",
    "batch_size = 100\n",
    "\n",
    "num_windows = None\n",
    "down_sampl_ratio = None\n",
    "\n",
    "welchs_win_len = 1\n",
    "welchs_stride = 0.75\n",
    "\n",
    "data_conversions = [FFT()] \n",
    "initial_freq_band = 1\n",
    "freq_bands = [4,8,12,30,400] \n",
    "only_seizures=True\n",
    "loss_type = 'softmax'\n",
    "\n",
    "load_Core = LoadCore(howmany_to_load=train_num_sample, num_windows=num_windows, sampling_freq=256,\\\n",
    "                      data_conversions=data_conversions, down_sampl_ratio=down_sampl_ratio,\\\n",
    "                      num_classes=num_classes, start_num=0, train_test=False, concat=True, \n",
    "                      freq_bands=freq_bands, initial_freq_band=initial_freq_band, only_seizures=only_seizures,\n",
    "                      welchs_win_len=welchs_win_len, welchs_stride=welchs_stride) \n",
    "\n",
    "X, y, num_nodes, dim, conv_sizes = data_load(task_core).run(load_Core) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ..\n"
     ]
    },
    {
     "ename": "UnrecognizedFlagError",
     "evalue": "Unknown command line flag 'f'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnrecognizedFlagError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d435ac1fa092>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclassification_core\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mClassifCore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtask_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m                                   \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m                                  \u001b[0mn_hidden_1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_hidden_2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_total_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e10\u001b[0m\u001b[1;33m,\u001b[0m                                   \u001b[0mprint_every\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_proj_th\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfeature_extraction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHybrid_Rep_Feat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraphL_core\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassification_core\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_losses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\2018 Jupyter Files\\graphL_rep_feat_class\\graphsage\\Graph_Learning_utils.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_seconds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassif_minibatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminiBatchIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraphL_minibatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassif_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[1;31m#config = tf.ConfigProto(log_device_placement=FLAGS.log_device_placement)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m         \u001b[1;31m#config.gpu_options.allow_growth = True\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;31m#config.gpu_options.per_process_gpu_memory_fraction = GPU_MEM_FRACTION\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\platform\\flags.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;31m# a flag.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_parsed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m       \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\absl\\flags\\_flagvalues.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, argv, known_only)\u001b[0m\n\u001b[0;32m    628\u001b[0m       \u001b[0msuggestions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_helpers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_flag_suggestions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m       raise _exceptions.UnrecognizedFlagError(\n\u001b[1;32m--> 630\u001b[1;33m           name, value, suggestions=suggestions)\n\u001b[0m\u001b[0;32m    631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmark_as_parsed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnrecognizedFlagError\u001b[0m: Unknown command line flag 'f'"
     ]
    }
   ],
   "source": [
    "graphL_core = GraphLCore(model_size='small', num_nodes=num_nodes, dim=dim, fixed_params=False, aggregator_type='mean',\\\n",
    "                        concat=False, num_layers=2, coordinate_gradient=False, projected_gradient=True, conv_sizes=conv_sizes)\n",
    "classification_core = ClassifCore(num_samples=X.shape[0], classifier=task_core.classifier, \\\n",
    "                                  epochs=epochs, learning_rate=learning_rate,\\\n",
    "                                  n_hidden_1=10, n_hidden_2=10, num_classes=num_classes, max_total_steps=1e10, \\\n",
    "                                  print_every=10, batch_size=batch_size, loss_type=loss_type, A_proj_th=5)\n",
    "feature_extraction = Hybrid_Rep_Feat(graphL_core, classification_core, weight_losses)\n",
    "feature_extraction.train(X, y)\n",
    "del X, y\n",
    "gc.collect()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_num = 0\n",
    "load_Core = LoadCore(howmany_to_load=train_num_sample, num_windows=num_windows, sampling_freq=256,\\\n",
    "                      data_conversions=data_conversions, down_sampl_ratio=down_sampl_ratio,\\\n",
    "                      num_classes=num_classes, start_num=start_num, train_test=True, concat=False, \n",
    "                      freq_bands=freq_bands, initial_freq_band=initial_freq_band, only_seizures=only_seizures,\n",
    "                      welchs_win_len=welchs_win_len, welchs_stride=welchs_stride) \n",
    "X, y, num_nodes, dim, conv_sizes = data_load(task_core).run(load_Core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction.test(X, y, show_plots=True, bias_name=start_num, training_samples='training')\n",
    "del X, y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_num = train_num_sample\n",
    "load_Core = LoadCore(howmany_to_load=test_num_sample, num_windows=num_windows, sampling_freq=256,\\\n",
    "                      data_conversions=data_conversions, down_sampl_ratio=down_sampl_ratio,\\\n",
    "                      num_classes=num_classes, start_num=start_num, train_test=True, concat=False, \n",
    "                      freq_bands=freq_bands, initial_freq_band=initial_freq_band, only_seizures=only_seizures,\n",
    "                      welchs_win_len=welchs_win_len, welchs_stride=welchs_stride) \n",
    "X, y, num_nodes, dim, conv_sizes = data_load(task_core).run(load_Core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction.test(X, y, show_plots=True, bias_name=start_num, training_samples='testing')\n",
    "del X, y\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
