{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf830
{\fonttbl\f0\fnil\fcharset0 Monaco;\f1\fnil\fcharset0 Menlo-Regular;\f2\fnil\fcharset0 HelveticaNeue;
\f3\fnil\fcharset0 Menlo-Bold;\f4\fmodern\fcharset0 Courier;\f5\fswiss\fcharset0 Helvetica;
}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red255\green255\blue255;\red28\green0\blue207;
\red0\green0\blue0;\red14\green110\blue109;\red14\green110\blue109;}
{\*\expandedcolortbl;;\csgenericrgb\c0\c0\c0;\csgenericrgb\c100000\c100000\c100000\c85000;\csgenericrgb\c11000\c0\c81000;
\cssrgb\c0\c0\c0;\csgenericrgb\c5490\c43137\c42745;\csgenericrgb\c5490\c43137\c42745;}
\margl1440\margr1440\vieww10800\viewh12280\viewkind0
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f0\fs20 \cf2 \cb3 \CocoaLigature0 **** Download szr times as html file \
Go to the patient\'92s home page, then select \'93all seizures\'94 from the menu tab with the patient\'92s name on it. You should get a page like this:\
\
http://epilepsiae.uniklinik-freiburg.de/patients/FR_1073/seizures\
\
Then save the html file, rename it all_szrs_FR_*.html (where *=patient code #), and move the file to: \
/Users/davidgroppe/PycharmProjects/SZR_ANT/EU_METADATA/ALL_SZR_HTML/\
\
\
***** Look at data to see if there are any bad time periods that should be ignored by running the script: plot_all_data_strat_plot.py\
\
by doing something like this:\
 python plot_all_data_strat_plot.py 1096\
\
Images are saved to:\
/Users/davidgroppe/PycharmProjects/SZR_ANT/EU_CODE/PNG\
\
Move any figures illustrating potentially bad time points to the patients ONGOING/EU_DATA/*/EXTREME_DATA file\
\
\
***** Convert seizure onset times (both clinical and subclinical) to dataframe and csv file via:\
szr_onset2df.py\
\
By doing something like this:\
 python szr_onset2df.py 1146\
\
The html file needs to be here:\
/Users/davidgroppe/PycharmProjects/SZR_ANT/EU_METADATA/ALL_SZR_HTML/\
\
The dataframe is output to here:\
\pard\tx543\pardeftab543\pardirnatural\partightenfactor0

\f1\fs22 \cf4 \cb1 /Users/davidgroppe/Dropbox/TWH_INFO/EU_METADATA/szr_on_off_FR_*.pkl??
\f0\fs20 \cf2 \cb3 \
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0
\cf2 \cb3 \
The csv file is output to here:\
\pard\tx543\pardeftab543\pardirnatural\partightenfactor0

\f1\fs22 \cf4 \cb1 /Users/davidgroppe/Dropbox/TWH_INFO/EU_METADATA/szr_on_off_FR_*.csv??
\f0\fs20 \cf2 \cb3 \
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0
\cf2 \cb3 \
\
***** Convert eeg *.data onset times to csv via:\
export_EU_data_times.py\
\
By doing something like this:\
 python export_EU_data_times.py 1096\
\
The csv file contains onset and offset in seconds relative to Jan 1, 2000 and also the original string indicating file onset (e.g., 
\f2 \cf5 \cb1 \expnd0\expndtw0\kerning0
\CocoaLigature1 2009-06-18 11:54:01.000
\f0 \cf2 \cb3 \kerning1\expnd0\expndtw0 \CocoaLigature0 )\
\
This gets header information from\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f3\b\fs24 \cf6 \cb1 \CocoaLigature1 /Users/davidgroppe/PycharmProjects/SZR_ANT/EU_METADATA/IEEG_HEADERS/'
\f1\b0 \cf0 +sub+
\f3\b \cf6 '_headers/'\
\pard\tx543\pardeftab543\pardirnatural\partightenfactor0

\f1\b0\fs22 \cf4 \CocoaLigature0 #/Users/davidgroppe/Dropbox/TWH_INFO/EU_METADATA/'\cf2 +sub+\cf4 '_headers/'
\f0\fs20 \cf2 \cb3 \
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0
\cf2 \cb3 \
And outputs files to:\
\pard\tx543\pardeftab543\pardirnatural\partightenfactor0

\f1\fs22 \cf4 \cb1 #\'92/Users/davidgroppe/Dropbox/TWH_INFO/EU_METADATA/data_on_off_FR_'\cf2 +str(sub)+\cf4 '.csv'
\f0\fs20 \cf2 \cb3 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f3\b\fs24 \cf7 \cb1 \CocoaLigature1 /Users/davidgroppe/PycharmProjects/SZR_ANT/EU_METADATA/IEEG_ON_OFF/
\f0\b0\fs20 \cf2 \cb3 \CocoaLigature0 \
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0
\cf2 \
***** Split data into training, validation, & testing:\
Run the script: split_testing_valid_training.py\
By doing something like this:\
  python split_testing_valid_training.py 1096\
\
First time window that contains first 3 clinical szrs is TRAIN\
Next time window that contains the next 2 clinical szrs is VALIDATION\
All the rest of the data is TESTING\
6 is the minimum # of clinical seizures, but most patients have more \
\
Lists of filenames are stored in 
\f1\fs22 \cf4 \cb1 /Users/davidgroppe/Dropbox/TWH_INFO/EU_METADATA/
\f4\fs24 \cf5 \expnd0\expndtw0\kerning0
\CocoaLigature1 data_splits_FR_*.pkl via a dict\
\
train_files, valid_files, test_files=list of train, valid, & test files respectively\
 \
train_szr_files, valid_szr_files, test_szr_files=list of train, valid, & test files that contain seizures respectively\

\f0\fs20 \cf2 \cb3 \kerning1\expnd0\expndtw0 \CocoaLigature0 \
\
***** Compute data features\
compute_hilbert_mag_lag_ftrs_EU.py: Band-limited magnitude\
compute_szr_anticipate_class_EU.py: Class labels focusing on peri-onset\
\
\
***** Compute normalization factors from training interictal data\
Do something like this\
python compute_ftr_mn_sd.py 1096 EU_MAG_LAG\
\
Trimmed mean and SD of training data non-ictal time windows are stored in the file ftr_nrms.npz in the feature directory. For example:\
 /Users/davidgroppe/PycharmProjects/SZR_ANT/FTRS/EU_MAG_LAG0/1096/ftr_nrms.npz\
\
The npz also contains the feature labels and the list of files used to compute the trimmed mn and sd\
\
\
***** Search gamma and C parameters:\
train_classifier_src_gamma_C.py 
\f5\fs24 \cf0 \cb1 \CocoaLigature1 srch_gamma_C_marr.json
\f0\fs20 \cf2 \cb3 \CocoaLigature0 \
\
\
***** Train a model on one pair of gamma and C parameters:\
train_classifier.py\
\
\
***** Try various thresholds for consecutive detecions \
\
\
***** \
2. Load in all szr data from training\
3. Randomly sample an equal # of interictal observations\
4. Train classifier\
5. Apply classifier to all (or subset?) of validation data}