{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf830
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 I tried to subsample the data with kmeans to see if I could speed up SVM training. To figure out how much redundancy was in the data, I computed the variance accounted for the by the resulting cluster centroids. \
\
For non-szr data, even just a few clusters do not well approximate the full data. For example, reducing the sample size by third accounts for only 75% of the variance:\
\'97\'97\
Non szr_data\
Dec fact, VA\
10. 43%\
3, 75%\
2, ?\
\
\
Using kmeans on the szr data works better, but I\'92m not sure if it\'92s work the effort of re-writing the code:\
Szr data,\
10, \
6,\
3, 98%\
2, 99% }