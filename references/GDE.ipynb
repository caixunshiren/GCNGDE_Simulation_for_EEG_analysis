{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd.functional import vjp\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import time\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GDE network makes use of the generic GCN layer to compute the 'head' and 'tail' layers, since the dimensions each hidden state cannot change within the ODE network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic GCN for head and tail layers\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, A, in_features, out_features, bias=False):\n",
    "        super(GCN, self).__init__()\n",
    "        \n",
    "        self.A = A\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.Tensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ',' \\\n",
    "               + str(self.out_features) + ')'\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / self.weight.size(1) ** 1/2\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "    \n",
    "    # H, feature matrix\n",
    "    # A, precomputed adj matrix\n",
    "    def forward(self, H):\n",
    "        n = torch.mm(self.A, torch.mm(H, self.weight))\n",
    "        if self.bias is not None:\n",
    "            return n + self.bias\n",
    "        else:\n",
    "            return n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a generic GCN block with a dyanmic number of layers. Note that when using, we wish to keep this number small (probably 1), since the ODE solver will effectively increase the number of layers here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCN Block for body layers\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, A, features, activation, num_layers):\n",
    "        super(Block, self).__init__()\n",
    "        self.features = features\n",
    "        self.activation = activation\n",
    "        self.num_layers = num_layers\n",
    "        self.A = A\n",
    "\n",
    "    def forward(self, x, t, net_params):\n",
    "        weights = net_params.view(self.num_layers, self.features, self.features)\n",
    "        \n",
    "        x = x.view(self.A.size(1), self.features)\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.A.mm(x).mm(weights[i,:,:])\n",
    "            x = self.activation(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def num_params(self):\n",
    "        return self.features * self.features * self.num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RK4 = ((  0,),\n",
    "       (1/2, 1/2,),\n",
    "       (1/2,   0,  1/2,),\n",
    "       (  1,   0,    0,   1,),\n",
    "       (1/6, 1/3, 1/3, 1/6,))\n",
    "\n",
    "EF = ((0,),\n",
    "      (1,))\n",
    "\n",
    "\"\"\"\n",
    "General Runge-Kutta Solver.\n",
    "https://en.wikipedia.org/wiki/Rungeâ€“Kutta_methods\n",
    "\n",
    "b_tableau, nested tuple, contains weights of integration. \n",
    "f, function, is the function to iterate. Should only be a function of x, t. \n",
    "x0, torch.Tensor, is the intial condition.\n",
    "t0, torch.Tensor, is the start time of integration.\n",
    "t1, torch.Tensor, is the end time of integration.\n",
    "N, int, is the desired number of timesteps.\n",
    "\n",
    "returns x, torch.Tensor, estimated solution of dy/dx = f(x,t) at time t1. \n",
    "\"\"\"\n",
    "\n",
    "def explicit_RK(b_tableau, f, x0, t0, t1, N):\n",
    "    h = (t1 - t0) / float(N) # calculate step size\n",
    "    x = x0 # initialize saved dynamics\n",
    "    mesh = (t0 + h * i for i in range(N)) # generator of time values\n",
    "    for time in mesh:\n",
    "        \n",
    "        k = [f(x, time + h*b_tableau[0][0])] # Covers the first row of the Butcher tableau. \n",
    "        for i, row in enumerate(b_tableau[1:-1]): # Covers the middle rows of the Butcher tableau.\n",
    "            k.append(f(x + sum(w * k[idx] * h for idx, w in enumerate(row[1:])), time + row[0] * h)) # calculate k's. \n",
    "        x = x + sum(w * k_i * h for k_i, w in zip(k, b_tableau[-1])) # calculate timestep \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenience tuple -> tensor function\n",
    "def flatten(*args):\n",
    "    return(torch.cat(tuple(torch.flatten(arg) for arg in args), dim=0).view(1,-1))\n",
    "\n",
    "# Convenience tensor -> tuple function\n",
    "def unflatten(x, n_e, sizes):\n",
    "    return (x[0, 0:n_e[0]].view(sizes[0]),\n",
    "            x[0, n_e[0]:n_e[0] + n_e[1]].view(sizes[1]),\n",
    "            x[0, (n_e[0] + n_e[1]):(n_e[0] + n_e[1] + n_e[2])].view(sizes[2]),\n",
    "            x[0, (n_e[0] + n_e[1] + n_e[2]):].view(sizes[3]),\n",
    "            )\n",
    "\n",
    "class Integrate(torch.autograd.Function):\n",
    "    def __deepcopy__(self, memo):\n",
    "        return Integrate(copy.deepcopy(memo))\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, Integrator, f, x0, t0, t1, N, net_params):\n",
    "        solution = Integrator(EF, lambda x, t: f(x, t, net_params), x0, t0, t1, N)\n",
    "\n",
    "        # Save for jacobian calculations in backward()\n",
    "        ctx.save_for_backward(x0,t0,t1,net_params)\n",
    "        ctx.solution = solution\n",
    "        ctx.Integrator = Integrator\n",
    "        ctx.N = N\n",
    "        ctx.f = f\n",
    "        \n",
    "        return solution\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, dL_dz1):\n",
    "        # Get all saved context\n",
    "        z0, t0, t1, net_params = ctx.saved_tensors\n",
    "        z1 = ctx.solution\n",
    "        N = ctx.N\n",
    "        f = ctx.f\n",
    "        \n",
    "        # Convenience sizes\n",
    "        batch_size = z0.size()[0]\n",
    "        img_len = int(z0.numel() / batch_size)\n",
    "\n",
    "        # Compute derivative w.r.t. to end time of integration\n",
    "        dL_dt1 = dL_dz1.view(batch_size,1,-1).bmm(f(z1, t1, net_params).view(batch_size,-1,1))  # Derivative of loss w.r.t t1\n",
    "        \n",
    "        #print(\"dL_dt1\", dL_dt1)\n",
    "        \n",
    "        # Initial Condition\n",
    "        num_elements = (z1.numel(), dL_dz1.numel(), batch_size * net_params.numel(), dL_dt1.numel())\n",
    "        sizes = (z1.size(), dL_dz1.size(), (batch_size, net_params.numel()), dL_dt1.size())\n",
    "        s0 = flatten(z1, dL_dz1, torch.zeros((batch_size, net_params.numel()), dtype=torch.float32, device=z1.device), -dL_dt1) # initial augmented state\n",
    "    \n",
    "        # augmented dynamics function\n",
    "        def aug_dynamics(s, t, theta):\n",
    "            s = unflatten(s, num_elements, sizes)\n",
    "            \n",
    "            with torch.enable_grad(): \n",
    "#                 gradients = [vjp(f, \n",
    "#                                  (s[0][i].unsqueeze(0), t, theta), \n",
    "#                                   v=-s[1][i].unsqueeze(0),\n",
    "#                                  )[1] for i in range(batch_size)]\n",
    "                gradients = vjp(f, \n",
    "                                 (s[0], t, theta), \n",
    "                                  v=-s[1],\n",
    "                                 )[1]\n",
    "                \n",
    "            return flatten(f(s[0],t,theta),\n",
    "                    torch.cat([gradients[0]], dim=0), \n",
    "                    torch.cat([gradients[2].unsqueeze(0) for i in range(batch_size)], dim=0), \n",
    "                    torch.cat([gradients[1].reshape(1,1) for i in range(batch_size)], dim=0),\n",
    "                   )#.unsqueeze(2)\n",
    "#             return flatten(f(s[0],t,theta),\n",
    "#                     torch.cat([gradient[0] for gradient in gradients], dim=0), \n",
    "#                     torch.cat([gradient[2].unsqueeze(0) for gradient in gradients], dim=0), \n",
    "#                     torch.cat([gradient[1].reshape(1,1) for gradient in gradients], dim=0),\n",
    "#                    )#.unsqueeze(2)\n",
    "\n",
    "        # Integrate backwards\n",
    "        with torch.enable_grad():\n",
    "            s = ctx.Integrator(EF, lambda x, t: aug_dynamics(x, t, net_params), s0, t1, t0, N)\n",
    "        \n",
    "        # Extract derivatives\n",
    "        _, dL_dz0, dL_dtheta, dL_dt0 = unflatten(s, num_elements, sizes)\n",
    "                \n",
    "        # must return something for every input to forward, None for non-tensors\n",
    "        return None, None, dL_dz0, dL_dt0, dL_dt1, None, dL_dtheta "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ODENet module instantiates the ODE network. You can think of it as replacing the GCNNet in the traditional non-ODE version of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODENet(nn.Module):\n",
    "    def __init__(self, solver, f, in_channels, body_channels, out_channels, hidden_layers, A, solver_params):\n",
    "        super(ODENet, self).__init__()\n",
    "        \n",
    "        # Graph Laplacian\n",
    "        self.A = A\n",
    "        \n",
    "        # Controls amount of parameters\n",
    "        self.body_channels = body_channels\n",
    "        self.f = f(A, body_channels, F.relu, hidden_layers)\n",
    "        \n",
    "        # Head\n",
    "        self.head = GCN(A, in_channels, body_channels)\n",
    "        \n",
    "        # Body\n",
    "        self.int_f = solver\n",
    "        self.Integrate = Integrate\n",
    "        self.solver_params = solver_params\n",
    "        self.N = solver_params[\"N\"]\n",
    "        self.h = (solver_params[\"t1\"] - solver_params[\"t0\"]) / solver_params[\"N\"]\n",
    "        self.t0 = torch.tensor(float(solver_params[\"t0\"]), requires_grad=True)\n",
    "        self.t1 = torch.tensor(float(solver_params[\"t1\"]), requires_grad=True)\n",
    "        \n",
    "        self.net_params = torch.nn.parameter.Parameter(torch.Tensor(self.f.num_params()).normal_(mean=0, std=0.1,generator=None), requires_grad=True)\n",
    "\n",
    "        # Tail\n",
    "        self.tail = GCN(A, body_channels, out_channels)\n",
    "    \n",
    "    def _apply(self, fn):\n",
    "        super(ODENet, self)._apply(fn)\n",
    "        self.t0 = fn(self.t0)\n",
    "        self.t1 = fn(self.t1)\n",
    "        return self\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.head(x))\n",
    "        x = self.Integrate.apply(self.int_f, self.f, x, self.t0, self.t1, self.N, self.net_params) # Vanilla RK4\n",
    "        x = self.tail(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_A(data):\n",
    "    adj = torch.eye(data.num_nodes, data.num_nodes)\n",
    "    adj[data.edge_index[0,:], data.edge_index[1,:]] += 1\n",
    "    deg = adj.sum(dim=1) ** (-1/2)\n",
    "    D = torch.diag(deg)\n",
    "    return D.mm(adj).mm(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_accuracy(pred, labels, mask):\n",
    "    return (pred.argmax(dim=1) == labels)[mask].sum().item() / mask.sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training samples:  140\n",
      "validation samples:  500\n",
      "test samples:  1000\n"
     ]
    }
   ],
   "source": [
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "\n",
    "A = create_A(data)\n",
    "\n",
    "train_labels = torch.where(data.train_mask, data.y, torch.tensor(-100))\n",
    "val_labels = torch.where(data.val_mask, data.y, torch.tensor(-100))\n",
    "test_labels = torch.where(data.test_mask, data.y, torch.tensor(-100))\n",
    "\n",
    "print('training samples: ', data.train_mask.sum().item())\n",
    "print('validation samples: ', data.val_mask.sum().item())\n",
    "print('test samples: ', data.test_mask.sum().item())\n",
    "\n",
    "A = A.to(device)\n",
    "input_features = data.x.to(device)\n",
    "train_labels = train_labels.to(device)\n",
    "val_labels = val_labels.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "train_mask = data.train_mask.to(device)\n",
    "val_mask = data.val_mask.to(device)\n",
    "test_mask = data.test_mask.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'features': dataset.num_features,\n",
    "    'body': 64,\n",
    "    'classes': dataset.num_classes,\n",
    "    'num_epochs': 100,\n",
    "    'learning_rate': 1e-2,\n",
    "    'weight_decay': 5e-3\n",
    "}\n",
    "\n",
    "solver_params = {\n",
    "    \"t0\": 0,\n",
    "    \"t1\": 1,\n",
    "    \"N\": 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-e755928b5034>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchsummary\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchsummary\\torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# batch_size of 2 for batchnorm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0min_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0min_size\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m     \u001b[1;31m# print(type(x[0]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "num_epochs = parameters['num_epochs']\n",
    "model = ODENet(explicit_RK, Block, parameters['features'], parameters['body'], parameters['classes'], 2, A, solver_params).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=parameters['learning_rate'], weight_decay=parameters['weight_decay'])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    train_pred = model(input_features)\n",
    "    train_loss = criterion(train_pred, train_labels)\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    train_acc = masked_accuracy(train_pred, train_labels, train_mask)\n",
    "    \n",
    "    model.eval()\n",
    "    val_pred = model(input_features)\n",
    "    val_loss = criterion(val_pred, val_labels)\n",
    "    val_acc = masked_accuracy(val_pred, val_labels, val_mask)\n",
    "    print(\"{}: \\ttrain loss {}\\tacc {:2f}\\tval loss {}\\tacc {:2f}\".format(epoch, train_loss, train_acc, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.784\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_pred = model(input_features)\n",
    "test_acc = masked_accuracy(test_pred, test_labels, test_mask)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where the hyperparameters for training are controlled, and the solver parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
